# 分布式集群

## 基础知识

```shell
    1. Kubernetes（k8s）[kubə’netis]是自动化容器操作的开源平台，这些操作包括部署，调度和节点集群间扩展
    2. SOA : Service Oriented Architecture ,面向服务架构, 
              SOA 架构是构造分布式计算应用程序的方法。它将 应用程序功能作为服务 发送给最终用户或者其他服务
    3. CDN(Content delivery network):内容分发网络,内容分发网络会指派较近、较顺畅的服务器节点将数据传输给用户,
       提高用户访问的响应速度和成功率
       
    4.
        弹力设计篇
            认识故障和弹力设计
            隔离设计 Bulkheads
            异步通讯设计 Asynchronous
            幂等性设计 Idempotency
            服务的状态 State
            补偿事务 Compensating Transaction
            重试设计 Retry
            熔断设计 Circuit Breaker
            限流设计 Throttle
            降级设计 degradation
            弹力设计总结
        管理设计篇
            分布式锁 Distributed Lock
            配置中心 Configuration Management
            边车模式 Sidecar
            服务网格 Service Mesh
            网关模式 Gateway
            部署升级策略
        性能设计篇
            缓存 Cache
            异步处理 Asynchronous
            数据库扩展
            秒杀 Flash Sales
            边缘计算 Edge Computing
            
    5. 
```

## 集群

- 两大特性

``` shell

    1.可扩展性: 集群的性能是由多个相同服务实体构成的,新的服务实体可以动态地加入到集群,从而增强集群的性能
    2.高可用性: 集群通过服务实体冗余使客户端免于轻易遇到out of service的警告.即如果一台服务器崩溃了,可以切换到另外一台
                服务器,使得客户端的功能请求可以正常.
                	
```

- 两大能力

``` shell

    为了具有可扩展性和高可用性特点,集群的必须具备以下两大能力：
    
    1.负载均衡: 把任务比较均衡地分布到集群环境下的服务实体
    2.错误恢复: 由于某种原因,执行某个任务的资源出现故障,另一服务实体中执行同一任务的资源接着完成任务.
               这种由于一个实体中的资源不能工作，另一个实体中的资源透明的继续完成任务的过程叫错误恢复.
                	
```

- 两大技术

``` shell

   1.集群地址:客户端通过访问集群的集群地址获取集群内部各服务实体的功能.具有单一集群地址(也叫单一影像)是集群的一个基本特征.
             维护集群地址的设置被称为负载均衡器.负载均衡器内部负责管理各个服务实体的加入和退出,
             外部负责集群地址向内部服务实体地址的转换.
             
   2. 内部通信 : 为了能协同工作、实现负载均衡和错误恢复,集群各实体间必须时常通信,比如负载均衡器对服务实体心跳测试信息,
                服务实体间任务执行上下文信息的通信.
                
   具有同一个集群地址使得客户端能访问集群提供的计算服务,一个集群地址下隐藏了各个服务实体的内部地址,
   使得客户要求的计算服务能在各个服务实体之间分布.内部通信是集群能正常运转的基础,它使得集群具有均衡负载和错误恢复的能力.
                	
```

## 负载均衡

``` shell

     1.LB(Load Balance负载均衡器)
            LB负责分发设备的 MQTT连接与消息到 EMQ 集群,LB 提高 EMQ 集群可用性、实现负载平衡以及动态扩容.
            负载均衡器可以将来自多个公网地址的访问流量分发到多台主机上,并支持自动检测并隔离不可用的主机,
            从而提高业务的服务能力和可用性.你还可以随时通过添加或删减主机来调整你的服务能力,而且这些操作不会影响业务的正常访问.
            负载均衡器支持HTTP/HTTPS/TCP 三种监听模式,并支持透明代理,可以让后端主机不做任何更改就可以直接获取客户端真实IP.
            负载均衡器还支持灵活配置多种转发策略,实现高级的自定义转发控制功能.
            
            (1)均衡方式
                轮询：依据后端服务器的权重,将请求轮流发送给后端服务器,常用于短连接服务，例如 HTTP 等服务。
                
                最少连接：优先将请求发给拥有最少连接数的后端服务器,常用于长连接服务，例如数据库连接等服务。
                
                源地址：将请求的源地址进行hash运算,并结合后端的服务器的权重派发请求至某匹配的服务器,
                        这可以使得同一个客户端IP的请求始终被派发至某特定的服务器.该方式适合负载均衡无cookie功能的TCP协议.
                        
            (2)会话保持
            
                ip_hash实现tcp会话保持
                          
                会话保持可以将来自同一个客户端的请求始终发给同一个后端服务器,是通过 cookie 的方式来实现的.
                    植入cookie：由负载均衡器向客户端植入 cookie，这时你需要指定 cookie 的过期时间,不指定默认为不过期。
                    改写cookie：cookie 由你的后端业务来植入和管理,负载均衡器会通过改写该 cookie 的值来实现会话保持,
                                改写cookie对后端服务是透明的,不会影响后端服务的正常运行；
                                这时你需要指定需要改写的 cookie 名称.
                            
            (3)健康检查
                开启健康检测后,负载均衡器会根据你的配置定期检查后端服务的运行状态,当某个后端服务出现异常时,会自动隔离该后端服务,
                并将请求转发给其他健康的后端服务,实现高可用性。
            
                健康检查方式：
            
                    TCP：通过向后端服务器发送 TCP 包来检测后端服务
            
                    HTTP：通过向后端服务器发送HTTP请求来检测后端服务,你可以指定需要检测的URI.
                          负载均衡器会通过HTTP返回值是否为200来判断服务是否正常.
            
                健康检查选项：
            
                    检查间隔：连续两次健康检查之间的时间间隔，单位为秒，范围为 2 - 60s
            
                    超时时间：等待健康检查请求返回的超时时间，检查超时将会被判定为一次检查失败，单位为秒，范围为 5 - 300s
            
                    不健康阈值：多少次连续检查失败之后，可以将后端服务屏蔽，范围为 2 - 10次
            
                    健康阈值：多少次连续检查成功之后，可以将后端服务恢复，范围为 2 - 10次
                    
            (4)后端服务器权重
                当均衡方式为 “轮询” 时,你可以通过设置后端服务器的权重来让负载均衡器进行权重转发.权重的范围为 1 - 100,
                数值越大权重越高.
                
     2.四层、七层负载均衡
        四层就是基于IP+端口的负载均衡,七层就是基于URL等应用层信息的负载均衡,基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡
        所谓的四到七层负载均衡,就是在对后台的服务器进行负载均衡时,依据四层的信息或七层的信息来决定怎么样转发流量.
        
        比如四层的负载均衡,就是通过发布三层的IP地址,然后加四层的端口号,来决定哪些流量需要做负载均衡,
        对需要处理的流量进行NAT处理(报文中目标IP地址进行修改(改为后端服务器IP)),转发至后台服务器,
        并记录下这个TCP或者UDP的流量是由哪台服务器处理的,后续这个连接的所有流量都同样转发到同一台服务器处理.
        此种Load Balance不理解应用协议（如HTTP/FTP/MySQL等等）.
        例子：LVS,F5
            Client->转发(修改报头目标地址+修改源地址根据需求)->server
        
        七层的负载均衡，就是在四层的基础上（没有四层是绝对不可能有七层的）,再考虑应用层的特征,
        比如同一个Web服务器的负载均衡,除了根据IP+80端口辨别是否需要处理的流量,还可根据七层的URL、浏览器类别、语言来决定
        是否要进行负载均衡.如果你的Web服务器分成两组,一组是中文语言的,一组是英文语言的,
        那么七层负载均衡就可以当用户来访问你的域名时,自动辨别用户语言,然后选择对应的语言服务器组进行负载均衡处理.
        Load Balancer能理解应用协议.例子： haproxy,MySQL Proxy.
        
        七层应用负载的好处,是使得整个网络更智能化.例如访问一个网站的用户流量,可以通过七层的方式,
        将对图片类的请求转发到特定的图片服务器并可以使用缓存技术,将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术.
        从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改,极大的提升了应用系统在网络层的灵活性.
        Nginx或者Apache上部署的功能可以前移到负载均衡设备上,例如客户请求中的Header重写,服务器响应中的关键字过滤或者内容插入等
        功能。
        另外一个常常被提到功能就是安全性.网络中最常见的SYN Flood攻击，即黑客控制众多源客户端,
        使用虚假IP地址对同一目标发送SYN攻击,通常这种攻击会大量发送SYN报文,耗尽服务器上的相关资源,
        以达到Denial of Service(DoS)的目的。从技术原理上也可以看出,四层模式下这些SYN攻击都会被转发到后端的服务器上；
        而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营.
        另外负载均衡设备可以在七层层面设定多种策略，过滤特定报文,例如SQL Injection等应用层面的特定攻击手段,
        从应用层面进一步提高系统整体安全.
        现在的7层负载均衡，主要还是着重于应用HTTP协议,所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。
         4层负载均衡则对应其他TCP应用，例如基于C/S开发的ERP等系统.
         
     3.负载均衡软件
        一种是通过硬件来进行,常见的硬件有比较昂贵的F5和Array等商用的负载均衡器,它的优点就是有专业的维护团队来对这些服务进行维护
        、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用；
        另外一种就是类似于Nginx/LVS/HAProxy的基于 Linux的开源免费的负载均衡软件，这些都是通过软件级别来实现,
        所以费用非常低廉。
        
        目前关于网站架构一般比较合理流行的架构方案：Web前端采用Nginx/HAProxy+ Keepalived作负载均衡器；
        后端采用 MySQL数据库一主多从和读写分离,采用LVS+Keepalived的架构.
        
        Nginx的优点是：
            (1).工作在网络的7层之上,可以针对http应用做一些分流的策略,比如针对域名、目录结构,
            它的正则规则比HAProxy更为强大和灵活,这也是它目前广泛流行的主要原因之一,Nginx单凭这点可利用的场合就远多于LVS了.
            (2)Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一；
                相反LVS对网络稳定性依赖比较大.
            (3)可以承担高负载压力且稳定,在硬件不差的情况下一般能支撑几万次的并发量,负载度比LVS相对小些.
            (4)Nginx可以通过端口检测到服务器内部的故障,比如根据服务器处理网页返回的状态码、超时等等,
                并且会把返回错误的请求重新提交到另一个节点,不过其中缺点就是不支持url来检测.
                比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障,Nginx会把上传切到另一台服务器重新处理，
                而LVS就直接断掉了
                
        Nginx的缺点是:
            (1)Nginx仅能支持http、https和Email协议,这样就在适用范围上面小些,这个是它的缺点.
            (2)对后端服务器的健康检查,只支持通过端口来检测,不支持通过url来检测.不支持Session的直接保持,但能通过ip_hash来解决.
            
        LVS的优点是:
            (1) 抗负载能力强、是工作在网络4层之上仅作分发之用,没有流量的产生,这个特点也决定了它在负载均衡软件里的性能最强的,
                对内存和cpu资源消耗比较低
            (2) 工作稳定,因为其本身抗负载能力很强,自身有完整的双机热备方案，如LVS+Keepalived.
            (3) 无流量,LVS只分发请求,而流量并不从它本身出去,这点保证了均衡器IO的性能不会受到大流量的影响
            (4) 应用范围比较广，因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、在线聊天室等等
            
        LVS的缺点是：
            (1) 软件本身不支持正则表达式处理,不能做动静分离；而现在许多网站在这方面都有较强的需求,
                这个是Nginx/HAProxy+Keepalived的优势所在.
            (2) 如果是网站应用比较庞大的话,LVS/DR+Keepalived实施起来就比较复杂了,
                特别后面有 Windows Server的机器的话,如果实施及配置还有维护过程就比较复杂了,
                Nginx/HAProxy+Keepalived就简单多了.
                
        HAProxy的特点是：
            (1) HAProxy的优点能够补充Nginx的一些缺点,比如支持Session的保持,Cookie的引导；
                同时支持通过获取指定的url来检测后端服务器的状态
            (2) HAProxy支持TCP协议的负载均衡转发,可以对MySQL读进行负载均衡,对后端的MySQL节点进行检测和负载均衡，
                大家可以用LVS+Keepalived对MySQL主从做负载均衡
                
            (3)HAProxy负载均衡策略非常多，HAProxy的负载均衡算法现在具体有如下8种：
               ① roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的；
               ② static-rr，表示根据权重，建议关注；
               ③ leastconn，表示最少连接者先处理，建议关注；
               ④ source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注；
               ⑤ ri，表示根据请求的URI；
               ⑥ rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name；
               ⑦ hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；
               ⑧ rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求.
               
               
        对网络负载均衡的使用是随着网站规模的提升使用不同的技术：
            第一阶段：利用Nginx或HAProxy进行单点的负载均衡,这一阶段服务器规模刚脱离开单服务器、单数据库的模式,
                    需要一定的负载均衡,但是仍然规模较小没有专业的维护团队来进行维护,也没有需要进行大规模的网站部署.
                    这样利用Nginx或HAproxy就是第一选择,此时这些东西上手快,配置容易,在七层之上利用HTTP协议就可以.
                    
            第二阶段：随着网络服务进一步扩大,这时单点的Nginx已经不能满足,这时使用LVS或者商用Array就是首要选择,
                    Nginx此时就作为LVS或者Array的节点来使用,具体LVS或Array的是选择是根据公司规模和预算来选择,
                    Array的应用交付功能非常强大,但是一般来说这阶段相关人才跟不上业务的提升,
                    所以购买商业负载均衡已经成为了必经之路.
                    
            第三阶段：这时网络服务已经成为主流产品,此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升,
                    这时无论从开发适合自身产品的定制,以及降低成本来讲开源的LVS,已经成为首选，这时LVS会成为主流.
                    
        最终形成比较理想的基本架构为：Array/LVS — Nginx/Haproxy — Squid/Varnish — AppServer.
                     	
```

## 反向代理

``` shell

   1.反向代理：工作在反向代理模式下的负载均衡设备,则是外网用户通过代理设备访问内网
                
   2.正向代理:普通的代理设备是内网用户通过代理设备出外网进行访问,
                	
```

## 分布式系统工程实践

```shell
    1.分布式系统的本质困难是 partial failure, 分布式系统不是放大的单机系统,根本原因是单机没有部分故障(partial failure)
      对应单机我们能轻易判断某个进程或则硬件是否还在正常运行.当在分布式系统中,我们无法得知另外一台机器是网络故障还是程序故障. 
      而且在分布式中事件的顺序性也没法保证,比如一台机器先发出消息,但由于网络原因不一定先收到
      
    2. 基于客户端视角的负载均衡策略
            这里站在客户端的角度思考,判断各个服务器端的负载情况可以根据该客户端向各个服务端请求时未收到响应的个数,即
            未收到响应的个数越少则代表该服务器负载小.
            
            实现思路: 客户端维护一个队列,该队列保存该客户端向各个服务器请求消息时未响应的个数,当要发送请求时,从
                     上次调用服务端的下一个位置进行遍历判断,选择负载最轻的服务器(即请求消息时未响应的个数最少)
                     
            在多客户端的情况下,防止潮涌(多个客户端一起向相同的服务端请求),刚开始访问服务器下标可以根据 ip 地址, MAC地址,
            时间等产生随机数种子
            
    3. 分布式系统的可靠性
            高可用的关键不在于不停机,而在于随时能够重启服务
            (1) 不要使用跨进程的 mutex 或则 semaphore, 也不要使用共享内存，因为进程意外终止，无法清理资源，
            　　　特别是无法解锁．也不要使用父子进程共享文件描述符通信(pipe)
            
            (2) 优雅的重启
                    A. 先主动停止一个服务进程的心跳：
                            对于短链接，关闭 listen port, 不会有新的请求到达
                            对于长连接，客户端会主动 failover 到备用的服务器端
                            
                    B. 等一段时间，待服务程序处理完剩下的请求，直到没有活动的请求
                    C. kill 并重启服务
                    D. 检测新进程的服务是否重启
                    E. 依次重启服务端的
                    
            (3) TCP 连接作为分布式系统进程间通信的唯一方式．原因是任何一方进程意外退出，对方都能及时的收到通知(操作系统会及时得
            　　关闭进程的 TCP socket)
            (4) TCP keepalive 不能代替应用层的心跳，原因是心跳除了判断网络是否正常，还可以判断该程序是否正常运行．
            　　　通常是服务器向客户端发送心跳．
                　心跳协议的关键点:
                        1. 尽量在工作线程中发送，不要另起一个线程．防止工作线程阻塞或则死锁，但心跳还是正常发送．
                        2. 与业务消息采用同一条连接，不要新开 TCP 连接．
                        
            (5) 分布式系统的进程标识
                    A. 进程标识是用来唯一标识一个程序的"一次运行"，同一份代码多次运行其对应的进程标识不同．
                    B. 用 ip:port 来标识进程，如果该进程服务为无状态的(没有上下文关系)，则没有问题．如果
                    　　该进程服务是有状态关系的，客户端无法区分该 ip:port　是新的进程还是原来的进程，导致某些
                    　　业务不正常．
                    C. 用 host:pid 标识进程，需考虑 pid 可能会轮回
                    D. 正确表示进程标识(ip:port:start_time:pid), 而　ip:port:start_time　不能保证唯一性，
                    　　如果程序短时间内重启，start_time可能会一样．
                    　　有了唯一的 gpid, 那么全局唯一的消息 id 可以用计数器递增的值和 gpid 组合起来
                    
            (6) 构建易于维护的分布式程序
                    易于维护即管理方便，日常劳动负担小．长期运行的且与其他机器继续通信交互的进程应该要提供管理接口，
                    可以查看进程的状态．一种具体的做法是在程序中内置一个 HTTP 服务器，能够查看进程的健康状态及当前
                    负载．
                    采用　HTTP　的原因是
                          A. 本身是 TCP Server ,可以安全的方便防止重复启动(bind() 失败退出)
                          B. 不必使用特定的客户端程序，用普通的 web 浏览器就可以
                          C. HTTP 是文本协议，在异常条件下可以使用 wget/curl 来获取内容
                          D. 可以借助 url 来划分请求的业务
                          
            (7) 为系统后续升级做准备
                    升级之前一定要做好 rollback 计划，做好回退准备
                    A. 要定义跨语言的可扩展的消息格式
                            1.可扩展的消息格式要求：内容中避免协议版本号，否则代码中会有一堆难以维护的 case-switch
                            2.可扩展的消息格式的内容，如果是文本格式数据，可以采用 JSON 或则 XML. 如果是二进制格式
                            　则可以采用 Google Protocol Buffer.
                            
            (8) 分布式自动化回归测试
                    A. 单元测试
                            1. 单元测试主要测试一个函数，一个 class 
                            2. 单一测试的缺点
                                    I. 阻碍大型重构．单元测试属于白盒测试，需要编写测试代码来调用被测代码(被测的函数)
                                    　　所以测试代码与被测代码紧耦合．在添加新功能的时候，我们常会重构已有的代码，
                                    　　在保持原来功能的情况下重构的代码能够用到其他的地方，这样一来原先单元测试就
                                    　　通不过．这样又得修改单元测试，耗时
                                    II. 为了方便测试而实施依赖注入，破坏代码的完整性．单看一块代码不知道到它是干嘛的，
                                    　　　它依赖的对象不知道在哪儿创建的．
                                    
                   　B. 一种自动化的回归测试方案　test harness , 这是一个独立的进程，模拟与被测程序的交互的所有程序．
                            1. test harness 优点
                                    (1) 完全从外部观察被测程序，没有对被测程序进行侵入，被测程序代码不需要像
                                    　　　单元测试一样考虑接口
                                    (2) 允许被测程序做大的重构，以优化内部代码结构，只要外部表现的形式不变(接口报文不变)
                                    (3) 有了一套完整的 test harness,甚至可以换种语言重写被测程序，测试用例依然可用．
                                    
                            2.　实现机制
                                    (1) test harness 能发起或则多个连接，可能需要用到现成的 NIO 网络库
                                    (2) test harness 只需要表现跟它 mock 程序一样，不需要真正的实现其业务逻辑，
                                    　　　只需要给被测程序的信息一样就可以了．如果要 mock 比较复杂的逻辑，可以
                                    　　　用 "记录 + 回放"的方式，把预设的响应回放到被测程序中．
                            
            (9) 分布式系统的运维
                    运维包括部署(升级)可执行程序与配置文件，监控进程状态，管理服务进程(重启服务)，故障响应
                    1.等级一: 全手工操作(实验室水平)
                            部署: 编译后手工将可执行程序拷贝到各台机器上，配置文件也要手工修改放到对应的机器上
                            管理: 手工启动服务进程，并且显式指名配置文件的路劲，重启进程需要登陆到 host (机器)
                            　　　进行 restart
                            升级: 如果需要升级服务进程，需要手动登陆多台 hosts,并拷贝新的可执行程序，重启
                            配置: Web Server 配置文件里写了 Suduku Sover 的 ip:port, 如果要部署新的
                            　　　Suduku Sover，则需要在　Web Server 配置文件增加并重启 Web Server
                            
                    2. 等级二: 使用零散的自动化脚本和第三方组件
                            这一层级主要是公司刚起步，开发重心在实现新功能上，顾不上高效的运维，运维工作基本上由
                            开发人员兼职．
                                部署: 部署可执行程序用脚本实现,为了让 c++ 可执行程序拷贝到 host 就能运行，通常采用静态运行
                                　　　以避免 .so 版本不同造成故障．同时服务进程的配置文件需要放在 git(版本管理) 上，
                                　　　每个不同的服务进程实例都有自己的 branch, 每次修改都要入库．程序启动时用到的配置文件
                                    　都应该从 git check out , 不能手工修改(减少人为失误)
                                管理: 服务进程使用 daemon 方式管理，异常 crash 后自动重启
                                升级: 可执行程序也有一套版本管理，发布新版本时不能覆盖原先老的可执行文件
                                　　　现在运行的是 /v1.0.0/bin/solver
                                     需要发布的是 /v2.0.0/bin/solver
                                     原因是　(1) 已经把老的替换成新的，那么老的可执行程序不存在，在老的可执行程序运行一段时间
                                     　　　　　　　后会出现 bus error
                                            (2) 当出现 core dump ,需要与"产生该 core dump 的可执行程序" 配对
                                            
                                监控: 公司会使用开源的软件监控每台 host 的资源使用情况，
                                
                    3. 等级三: 自制机群管理系统，集中化配置
                            这一层级主要适合成熟的大公司
                            部署:只需要向 Master 发送一条指令， Master 会命令　Slave 从指定的地点 rsync 新的可执行
                            　　　程序到本地目录
                            进程监控和管理: Sudoku Solver 是由 Slave 节点 fork() 产生的，同时父子进程可以通过 pipe()
                                          进行消息的通信，　Slave 节点得知 Sudoku Solver 异常 crash 后会令其重启．
                                          Master 提供一个 Web 页面来看本机群中各个服务程序是否正常．
                                          
                            升级: 如果要主动重启 Sudoku Solver ,可以向 Master 发送指令，不需要 ssh & kill,
                                 同时会保存每台 host 的服务进程启动时间．动态的获知配置情况，当一个系统新增
                                 Sudoku Solver　服务，可以通过 Web Server 管理接口向其发送增加 ip:port 命令．
                                 还有一种方法就是通过数据库，每个 Sudoku Solver 服务启动时往数据库表中 insert 
                                 自身的 ip:port, Web Server 配置里写了 select 语句,获取可利用的服务的 ip:port
                                 Web Server 通过数据库触发器及时的感知 Sudoku Solver ip address list 的变化.
```

## 分布式系统架构本质

```shell
    1.采用分布式系统而不用单机系统的原因
            (1) 增大系统容量．随着业务量越来越大，一台机器已经无法满足要求，需要垂直或则水平拆分系统业务，
            　　让其变为分布式系统. 其主要工作是大流量处理，对应的技术是通过集群技术把大规模并发请求的负载
            　　分散到不同的机器上．
            (2) 增加系统的可用性(高可用)，提高系统的高可用，则该架构中不能存在单点故障，则需要通过分布式架构来冗余系统．
                关键业务保护,提高后台服务的可用性，把故障隔离起来阻止多米诺骨牌效应（雪崩效应）。
                如果流量过大，需要对业务降级，以保护关键业务流转。
            (3) 模块化，开发效率高 
             
    2. 分布式系统的劣势
            (1) 系统架构的设计复杂(例如分布式事务)
            (2) 部署分布式系统复杂(而单机系统则比较简单)
            (3) 系统吞吐量会变大，但其响应的时间会变长(要考虑到分发处理)
            
    3. 分布式系统架构的难点在于系统设计，以及管理和运维,虽然解决了"单点”和“性能容量”的问题, 但会引发其他的问题，
    　　需要不断地用各式各样的技术和手段来解决这些问题．
    
    4. 面向服务的架构的阶段
            (1) 第一阶段: 单体架构，模块的耦合性高，模块功能之间的相互关联
            (2) 第二阶段: SOA 架构，需要一个标准的协议或是中间件来联动其它相关联的服务（如 ESB）
            　　　　　　　　服务间并不直接依赖，而是通过中间件的标准协议或是通讯框架相互依赖
            (3) 第三阶段: 微服务架构，耦合度低，每一个微服务都能独立完整地运行，
            　　　　　　　　它和传统 SOA 的差别在于，服务间的整合需要一个服务编排或是服务整合的引擎，
            　　　　　　　　这个编排和组织引擎可以是工作流引擎，也可以是网关。还需要辅助于像容器化调度这样的技术方式，如 Kubernetes
            
    5. 分布式系统的难点
            (1) 分布式系统的不标准问题
                    a. 软件和应用不标准。 不同的软件，不同的语言会出现不同的兼容性和不同的开发、测试、运维标准
                    b. 通讯协议不标准。不同的软件用不同的协议.
                    c. 数据格式不标准。不同的团队中相同的网络协议里也会出现不同的数据格式.
                    d. 开发和运维的过程和方法不标准。
                    
                    A. 一个好的配置管理，应该分成三层,底层(和操作系统相关)，中间层(和中间件相关)，最上层(和业务应用相关)
                       底层和中间层是不能让用户灵活修改的，只能让用户选择
                       
                    B. 规范数据通讯协议．作为一个协议，一定要有协议头和协议体。协议头定义最基本的协议数据，而协议体才是真正的业务数据。
                    　对于协议头，我们需要非常规范地让每一个使用这个协议的团队都使用一套标准的方式来定义，
                    　这样我们才容易对请求进行监控、调度和管理。
                    
            (2) 系统架构中服务依赖性问题
                    分布式架构下，服务是会有依赖的，于是一个服务依赖链上，某个服务挂掉了，会导致出现“多米诺骨牌”效应，会倒一片。
                    服务依赖具体带来了问题:
                        A. 服务依赖链中，出现“木桶短板效应”——整个 SLA(Service-Level Agreement服务级别协议) 由最差的那个服务所决定。
                        
                    这是服务治理的内容.服务治理不但需要我们定义出服务的关键程度，还需要我们定义或是描述出关键业务或服务调用的主要路径。
                    没有这些，我们将无法运维或是管理整个系统
                    
                    我们不但要拆分服务，还要为每个服务拆分相应的数据库．数据库方面也需要做相应的隔离，系统间不能读取对方的数据库，
                    只通过服务接口耦合，这也是微服务的要求
                    
            (3) 故障发生的概率更大(但产生的影响面小)
                    在分布式系统中，因为使用的机器和服务会非常多，所以，故障发生的频率会比传统的单体应用更大，但产生的影响面小
                    这时将引发运维团队在分布式系统下会非常忙，我们可以定义一些关键指标，同时在设计系统时考虑如何减轻故障。
                    如果无法避免，也要使用自动化的方式恢复故障，减少故障影响面。
                    
            (4) 多层架构的运维复杂度更大
                    系统分成四层,由下到上划分：
                        a. 基础层就是我们的机器、网络和存储设备等。
                        b. 平台层就是我们的中间件层，Tomcat、MySQL、Redis、Kafka 之类的软件。
                        c. 应用层就是我们的业务软件，比如，各种功能的服务。
                        d. 接入层就是接入用户请求的网关、负载均衡(nginx)或是 CDN、DNS 
                        
                    这逻辑架构的划分带来的影响是:
                        a. 任何一层的问题都会导致整体的问题；
                        b. 没有统一的视图和管理，导致运维被割裂开来，造成更大的复杂度。
                    
                    应对策略: 规范标准
```

## 分布式系统技术栈

```shell
    1. 提高架构的性能
            (1) 缓存系统(缓存分区，缓存更新，缓存命中)
                   加入缓存系统，可以有效地提高系统的访问能力。从前端的浏览器，到网络，再到后端的服务，底层的数据库、文件系统、
                   硬盘和 CPU，全都有缓存，这是提高快速访问能力最有效的手段。对于分布式系统下的缓存系统，需要的是一个缓存集群。
                   这其中需要一个 Proxy 来做缓存的分片和路由
            (2) 负载均衡系统(网关系统，负载均衡，服务路由，服务发现)
                    是做水平扩展的关键技术，用多台机器来共同分担一部分流量请求
            (3) 异步调用(消息队列，消息持久，异步事务)
                    异步系统主要通过消息队列来对请求做排队处理，把前端的请求的峰值给“削平”了，而后端通过自己能够处理的速度来处理请求。
                    这样可以增加系统的吞吐量，但是实时性就差很多了。还会引入消息丢失的问题，所以要对消息做持久化，
                    这会造成“有状态”的结点，从而增加了服务调度的难度。
            (4) 数据分区和数据镜像
                    数据分区是把数据按一定的方式分成多个区（比如通过地理位置），不同的数据区来分担不同区的流量。
                    这需要一个数据路由的中间件，会导致跨库的 Join 和跨库的事务非常复杂。而数据镜像是把一个数据库镜像成多份一样的数据，
                    这样就不需要数据路由的中间件了。你可以在任意结点上进行读写，内部会自行同步数据。然而，
                    数据镜像中最大的问题就是数据的一致性问题。对于一般公司来说，在初期，会使用读写分离的数据镜像方式，
                    而后期会采用分库分表的方式。
                    
    2. 提高系统稳定性
            (1) 服务拆分(服务调用，服务依赖，服务隔离)
                    主要有两个目的：一是为了隔离故障，二是为了重用服务模块。但服务拆分完之后，会引入服务调用间的依赖问题
            (2) 服务冗余(弹性伸缩，故障迁移，服务发现)
                    是为了去除单点故障，并可以支持服务的弹性伸缩，以及故障迁移。然而，对于一些有状态的服务来说，
                    冗余这些有状态的服务带来了更高的复杂性。弹性伸缩时，需要考虑数据是复制还是重新分片，
                    故障迁移的时候还要连同数据一起迁移
            (3) 限流降级(异步队列，降级控制，服务熔断)
                    当系统实在扛不住压力时，只能通过限流或者功能降级的方式来停掉一部分服务，或是拒绝一部分用户，
                    以确保整个架构不会挂掉。这些技术属于保护措施
            (4) 高可用架构(多租户系统，灾备多活，高可用服务)
                    从冗余架构的角度来保障可用性。比如，多租户隔离，灾备多活，或是数据一致性的集群。总之，就是为了不出单点故障。
            (5) 高可用运维(全栈监控，DevOps, 自动化运维)
                    指的是 DevOps 中的 CI（持续集成）/CD（持续部署）。一个良好的运维应该是一条很流畅的软件发布管线，
                    其中做了足够的自动化测试，还可以做相应的灰度发布，以及对线上系统的自动化控制。
                    这样，可以做到“计划内”或是“非计划内”的宕机事件的时长最短
                    
    3. 分布式系统的关键技术
            (1) 服务治理
                    服务拆分、服务调用、服务发现，服务依赖，服务的关键度定义……
                    服务治理的最大意义是需要把服务间的依赖关系、服务调用链，以及关键的服务给梳理出来，
                    并对这些服务进行性能和可用性方面的管理
            (2) 架构软件管理
                    服务之间有依赖，而且有兼容性问题，所以，整体服务所形成的架构需要有架构版本管理、整体架构的生命周期管理，
                    以及对服务的编排、聚合、事务处理等服务调度功能。
            (3) DevOps
                    分布式系统可以更为快速地更新服务，但是对于服务的测试和部署都会是挑战。所以，还需要 DevOps 的全流程，
                    其中包括环境构建、持续集成(CI)、持续部署(CD)等
            (4) 自动化运维
                    有了 DevOps 后，我们就可以对服务进行自动伸缩、故障迁移、配置管理、状态管理等一系列的自动化运维技术了。
            (5) 资源调度管理
                    应用层的自动化运维需要基础层的调度支持，也就是云计算 IaaS 层的计算、存储、网络等资源调度、隔离和管理
            (6) 整体架构监控
                    如果没有一个好的监控系统，那么自动化运维和资源调度管理只可能成为一个泡影，因为监控系统是你的眼睛。
                    没有眼睛，没有数据，就无法进行高效的运维(没有一个好的监控系统，我们将无法进行自动化运维和资源调度)
                    所以说，监控是非常重要的部分。
                    这里的监控需要对三层系统（应用层、中间件层、基础层）进行监控
            (7) 流量控制
                    负载均衡、服务路由、熔断、降级、限流等和流量相关的调度都会在这里，包括灰度发布之类的功能也在这里
                    
            根据以上那么多的技术，学习成本，投入的人力物力较大，可以通过 Docker 以及其衍生出来的 Kubernetes 之类的软件或解决方案，
            大大地降低了做上面很多事情的门槛．Docker 把软件和其运行的环境打成一个包，然后比较轻量级地启动和运行。
            在运行过程中，软件变成了服务　可能会改变　现有的环境。但是没关系，当你重新启动一个 Docker 的时候，
            环境又会变成初始化状态。

    4. 分布式系统的“纲”
            由于分布式系统所需要的技术太复杂，所以我们不能着眼于每个细节，而需要掌握关键技术．
                (1) 全栈系统监控(应用整体监控)
                (2) 服务 / 资源调度；
                (3) 流量调度；
                (4) 状态 / 数据调度；
                (5) 开发和运维的自动化。 是需要把前四项都做到了，才有可能实现的
```

### 分布式系统的关键技术一：全栈系统监控

```shell
    1. 监控系统需要具备的功能:
            (1) 全栈监控；
            (2) 关联分析；
            (3) 跨系统调用的串联；
            (4) 实时报警和自动处置；
            (5) 系统性能分析。
            
    2. 全栈监控(对基础层，中间层，应用层进行监控)
            (1) 基础层：监控主机和底层资源。比如：CPU、内存、网络吞吐、硬盘 I/O、硬盘使用等。
            (2) 中间层：就是中间件层的监控。比如：Nginx(网关)、Redis(缓存服务)、ActiveMQ、
            　　　　　　Kafka(消息队列)、MySQL、Tomcat(Java容器) 等。
            (3) 应用层：监控应用层的使用。比如：HTTP 访问的吞吐量、响应时间、返回码，
                       调用链路分析，性能瓶颈，还包括用户端的监控。
                       
            将这些监控数据进行标准化:
                a. 日志数据结构化；
                b. 监控数据格式标准化；
                c. 统一的监控平台；
                d. 统一的日志分析。
                
    3. 现实中很多监控系统存在的问题
            (1) 监控数据都是隔离开来的。
                    因为公司分工的问题，开发、应用运维、系统运维，各管各的，所以很多公司的监控系统也是各是各的，完全串不起来。
            (2) 监控的数据项太多。
                    有些公司的运维团队把监控的数据项多做为一个亮点到处讲，比如监控指标达到 5 万多个。这不合理，
                    因为信息太多等于没有信息，抓不住重点的监控才会做成这个样子
                    
    4. 一个好的监控系统具备的特点
            (1) 容量管理
                     提供一个全局的系统其在运行过程中数据的展示，可以让工程师团队知道是否需要增加机器或者其它资源。
            (2) 性能管理分析
                    可以通过查看大盘，找到系统瓶颈，并有针对性地优化系统和相应代码。
            (3) 定位问题
                    可以快速地暴露并找到问题的发生点，帮助技术人员诊断问题。故障发生不可怕，可怕的是故障的恢复时间过长，
                    需要快速的定位问题
                    
    5. 如何做出一个好的监控系统
            (1) 服务调用链跟踪
                    这个监控系统应该从对外的 API 开始，然后将后台的实际服务给关联起来，然后这个服务的依赖服务给关联起来，
                    直到最后一个服务（如 MySQL 或 Redis），这样就可以把整个系统的服务全部都串连起来了。
                    这个事情的最佳实践是 Google Dapper 系统，其对应于开源的实现是 Zipkin。
                    对于 Java 类的服务，我们可以使用字节码技术进行字节码注入，做到代码无侵入式。
            (2) 服务调用时长分布
                    使用 Zipkin, 可以看到一个服务调用链上的时间分布(各个服务的时间分布)，这样有助于我们知道最耗时的服务是什么
            (3) 服务的 TOP N 视图
                    所谓 TOP N 视图就是一个系统请求的排名情况。 排名的方法：a）按调用量排名，b) 按请求最耗时排名
            (4) 数据库操作关联
                    对于 Java 应用，我们可以很方便地通过 JavaAgent 字节码注入技术拿到 JDBC 执行数据库操作的执行时间。
                    对此，我们可以和相关的请求对应起来。
            (5) 服务资源跟踪
                    
    6.好的监控系统的作用
            有了以上数据，同时把数据关联好。这样，我们才可能很快地定位故障，进而才能进行自动化调度，
            比如：
                一旦发现某个服务过慢是因为 CPU 使用过多，我们就可以做弹性伸缩。
                一旦发现某个服务过慢是因为 MySQL 出现了一个慢查询，我们就无法在应用层上做弹性伸缩，只能做流量限制，或是降级操作了。
  
```

### 分布式系统的关键技术二：服务调度

```shell
    1.服务治理的关键技术
            (1) 服务关键程度
            (2) 服务依赖关系。
            (3) 服务发现。
            (4) 整个架构的版本管理。
            (5) 服务应用生命周期全管理
            
            A. 服务关键程度和服务的依赖关系
                    (1) 服务关键程度要我们梳理和定义服务的重要程度。这不是使用技术可以完成的，这需要对业务的有较深理解，
                        才能定义出架构中各个服务的重要程度
                    (2) 梳理出服务间的依赖关系，服务间的依赖是一件很易碎的事。依赖越多越复杂，我们的系统就越易碎
                    　　一个服务的问题很容易出现一条链上的问题。因此，传统的 SOA 希望通过 ESB 来解决服务间的依赖关系，
                    　　这也是为什么微服务中希望服务间是没有依赖的，而让上层或是前端业务来整合这些个后台服务．
                    　　服务依赖最优解的上限是微服务，而服务依赖的下限是千万不要有依赖环．如果系统架构中有服务依赖环，
                    　　那么表明你的架构设计是错误的。循环依赖有很多的副作用，最大的问题是这是一种极强的耦合，会导致服务部署相当复杂和难解，
                    　　而且会导致无穷尽的递归故障和一些你意想不到的的问题。
                    
                       服务的依赖关系是可以通过技术的手段来发现的，这其中，Zipkin是一个很不错的服务调用跟踪系统，
                       它是通过 Google Dapper这篇论文来实现的。这个工具可以帮你梳理服务的依赖关系，以及了解各个服务的性能。
                       
                   　(3) 在梳理完服务的重要程度和服务依赖关系之后，我们就相当于知道了整个架构的全局。
                   
            B. 服务状态和生命周期的管理
                    (1) 在梳理完服务的重要程度和服务依赖关系之后,有了对架构的大致了解，这时需要［服务发现］这个中间件，来知道在这个动态的
                    　　架构中，当前所处的状态
                            a. 整个架构中有多少种服务？
                            b. 这些服务的版本是什么样的？
                            c. 每个服务的实例数有多少个，它们的状态是什么样的?
                            d. 每个服务的状态是什么样的？是在部署中，运行中，故障中，升级中，还是在回滚中，伸缩中，或者是在下线中……
                    (2) 服务状态
                            a. Provision，代表在供应一个新的服务；
                            b. Ready，表示启动成功了；
                            c. Run，表示通过了服务健康检查；
                            d. Update，表示在升级中；
                            e. Rollback，表示在回滚中。
                            f. Scale，表示正在伸缩中（可以有 Scale-in 和 Scale-out 两种）。
                            g. Destroy，表示在销毁中。
                            h. Failed，表示失败状态。
                            
                    (3) 整个架构的版本管理
                            除了各个项目的版本管理之外(也就是各个服务的版本)，还需要在上面再盖一层版本管理(架构版本)，
                            用来控制其中各个服务的版本兼容。比如，A 服务的 1.2 版本只能和 B 服务的 2.2 版本一起工作，
                            A 服务的上个版本 1.1 只能和 B 服务的 2.0 一起工作。这就是版本兼容性
                            如果我们要回滚一个服务的版本，就可以把与之有版本依赖的服务也一起回滚掉。
                            
                            这时版本管理需要一个服务清单：
                                a. 服务的软件版本；
                                b. 服务的运行环境——环境变量、CPU、内存、可以运行的结点、文件系统等；
                                c. 服务运行的最大最小实例数。
                                
                            每一次对这个清单的变更都需要被记录下来，算是一个架构的版本管理。
                            而我们上面所说的那个集群控制系统需要能够解读并执行这个清单中的变更，以操作和管理整个集群中的相关变更
                    
    2. 资源 / 服务调度
            (1) 主要有以下一些关键技术。
                    a. 服务状态的维持和拟合。
                    b. 服务的弹性伸缩和故障迁移。
                    c. 作业和应用调度。
                    d. 作业工作流编排。
                    e. 服务编排。     
                    
            A. 服务状态的维持和拟合
                    (1) 服务状态是服务的运行状态(Provision, Ready, Run等等)
                    (2) 服务在运行过程中状态会发生变化：
                            a. 一种是不预期的变化
                                    比如，服务运行因为故障导致一些服务挂掉，或是别的什么原因出现了服务不健康的状态。
                                    而一个好的集群管理控制器应该能够强行维护服务的状态。在健康的实例数变少时，
                                    控制器会把不健康的服务给摘除，而又启动几个新的，强行维护健康的服务实例数
                            b. 另外一种是预期的变化
                                    比如，我们需要发布新版本，需要伸缩，需要回滚。这时，集群管理控制器就应该把集群从现有状态迁移到
                                    另一个新的状态。这个过程并不是一蹴而就的，集群控制器需要一步一步地向集群发送若干控制命令。
                                    这个过程叫“拟合”——从一个状态拟合到另一个状态，而且要穷尽所有的可能，玩命地不断地拟合，
                                    直到达到目的。
                    (3) 程序正常的将一种状态切换到另一种状态的操作(例如当需要对集群进行 Scale 的时候): 这个叫 "拟合"
                            a. 先扩展出几个结点；
                            b. 再往上部署服务；
                            c. 然后启动服务；
                            d. 再检查服务的健康情况；
                            e. 最后把新扩展出来的服务实例加入服务发现中提供服务。
                            
                    (4) 集群控制系统就是要处理异常的状态变化和正常的服务状态变化(拟合)
            B. 服务的弹性伸缩和故障迁移
                    (1) 服务的弹性伸缩:
                            a. 底层资源的伸缩；
                            b. 服务的自动化部署；
                            c. 服务的健康检查；
                            d. 服务发现的注册；
                            e. 服务流量的调度。
                            
                    (2) 故障迁移(服务的某个实例出现问题时，我们需要自动地恢复它)
                            有两种模式
                                a. 宠物模式，就是一定要救活，主要是对于 stateful 的服务
                                b. 奶牛模式，就是不救活了，重新生成一个实例。
                            
                            故障迁移具体操作:
                                a. 服务的健康监控（这可能需要一个 APM 的监控）。
                                b. 如果是宠物模式，需要：服务的重新启动和服务的监控报警（如果重试恢复不成功，需要人工介入）。
                                c. 如果是奶牛模式，需要：服务的资源申请，服务的自动化部署，服务发现的注册，以及服务的流量调度。
                                
                            可用通过现成的技术  Docker 和 Kubernetes 这样的技术
            C. 服务工作流和编排
                    (1) 编排: 类比与操作系统， 一个好的操作系统需要能够通过一定的机制把一堆独立工作的进程给协同起来。
                             在分布式的服务调度中，这个工作叫做 Orchestration，国内把这个词翻译成“编排
                    (2) 传统的 SOA 是通过 ESB（Enterprise Service Bus）——企业服务总线来完成的。
                        ESB 的主要功能是服务通信路由、协议转换、服务编制和业务规则应用等.
                        ESB 的服务编制叫 Choreography，与我们说的 Orchestration 是不一样的。
                        Orchestration 的意思是，一个服务像大脑一样来告诉大家应该怎么交互，就跟乐队的指挥一样。
                        Choreography 的意思是，在各自完成专属自己的工作的基础上，怎样互相协作，就跟芭蕾舞团的舞者一样。
                        而在微服务中，我们希望使用更为轻量的中间件来取代 ESB 的服务编排功能。
                        简单来说，这需要一个 API Gateway 或一个简单的消息队列来做相应的编排工作。在 Spring Cloud 中，
                        所有的请求都统一通过 API Gateway（Zuul）来访问内部的服务。这个和 Kubernetes 中的 Ingress 相似。
```

### 分布式系统的关键技术三：流量与数据调度

```shell
    1. 流量调度和服务治理的区别
            一方面，服务治理是内部系统的事，而流量调度可以是内部的也可以外部接入层的事。
            另一方面，服务治理是数据中心的事，而流量调度要做得好，应该是数据中心之外的事，也就是我们常说的边缘计算，
            　　　　　是应该在类似于 CDN 上完成的事。
    2. 流量调度的主要功能为了提高系统架构的稳定性和高可用性。
    3. 流量调度的关键技术
            (1) 需要该关键技术的理由: 作为一个 API Gateway 来说，因为要调度流量，首先需要扛住流量，而且还需要有一些比较轻量的业务逻辑
            (2) 关键技术的内容:
                    a. 高性能。 API Gateway 必须使用高性能的技术，所以也就需要使用高性能的语言。
                    b. 扛流量。 要能扛流量，就需要使用集群技术。集群技术的关键点是在集群内的各个结点中共享数据。
                               这就需要使用像 Paxos、Raft、Gossip 这样的通讯协议。因为 API Gateway 需要部署在广域网上，
                               所以还需要集群的分组技术。
                    c. 业务逻辑。 API Gateway 需要有简单的业务逻辑，所以，最好是像 AWS 的 Lambda 服务一样，
                                可以让人注入不同语言的简单业务逻辑。
                    d. 服务化。 一个好的 API Gateway 需要能够通过 Admin API 来不停机地管理配置变更的，
                               而不是通过一个.conf 文件来人肉地修改配置。
    4. 状态数据调度
            (1) 这里的状态是 State，也就是说，有些服务会保存一些数据，而这些数据是不能丢失的，所以，这些数据是需要随服务一起调度的。
            (2) 状态数据调度采取的方案(转移问题)
                    转移问题”: 把这些有状态的东西存储到第三方服务上(比如 Redis、MySQL、ZooKeeper，或是 NFS、Ceph 的文件系统中),
                              让服务变为“无状态的服务”，但是 Redis 和 MySQL 上则有了状态。所以，
                              现在的分布式系统架构中出问题的基本都是这些存储状态的服务
                              
            (3) 分布式事务一致性的问题
                    a. 问题：　让数据服务可以像无状态的服务一样在不同的机器上进行调度，就会涉及数据的 replication 问题。
                    　　　　　　而数据 replication 则会带来数据一致性的问题，进而对性能带来严重的影响。
                    b. 解决数据副本间的一致性问题
                            I.   Master-Slave 方案。
                            II.  Master-Master 方案。
                            III. 两阶段和三阶段提交方案。
                            VI.  Paxos 方案。
                            
                            很多公司的分布式系统事务基本上都是两阶段提交的变种。比如：阿里推出的 TCC–Try–Confirm–Cancel，
                            或是我在亚马逊见到的 Plan–Reserve–Confirm 的方式，等等。凡是通过业务补偿，
                            或是在业务应用层上做的分布式事务的玩法，基本上都是两阶段提交，或是两阶段提交的变种。
                            换句话说，迄今为止，在应用层上解决事务问题，只有“两阶段提交”这样的方式，
                            而在数据层解决事务问题，Paxos 算法则是不二之选。
                            
                            数据结点的分布式方案: 真正完整解决数据 Scale 问题的应该还是数据结点自身(即数据存储方而不是应用层)
                            
            (4) 状态数据调度应该是由分布式存储系统来解决的，这样会更为完美。但是因为数据存储的 Scheme 太多，所以，
               导致我们有各式各样的分布式存储系统，有文件对象的，有关系型数据库的，有 NoSQL 的，有时序数据的，有搜索数据的，有队列的……
               总之，状态数据调度应该是在 IaaS 层的数据存储解决的问题，而不是在 PaaS 层或者 SaaS 层来解决的。
               在 IaaS 层上解决这个问题, 一般来说有三种方案，
                    一种是使用比较廉价的开源产品，如：NFS、Ceph、TiDB、CockroachDB、ElasticSearch、InfluxDB、MySQL Cluster
                                               和 Redis Cluster 之类的；
                    另一种是用云计算厂商的方案。
                    第三种可以使用更为昂贵的商业网络存储方案。
                            
```

### 一个软件公司的软件工程能力

```shell
    1. 提高服务的 SLA
        服务的 SLA:  我们能提供多少个 9 的系统可用性，而每提高一个 9 的可用性都是对整个系统架构的重新洗礼
        提高系统的 SLA 主要表现在两个方面：
            a. 高可用的系统；
            b. 自动化的运维。 因为故障是常态，如果没有自动化的故障恢复，很难提高服务的 SLA
            
    2. 能力和资源重用或复用
            表现为:
                    a. 软件模块的重用
                    b. 软件运行环境和资源的重用
            
            这就需要我们设计的时候构建出通用的软件模块或则服务，同时使用统一的软件通讯协议，统一的开发和运维管理方法
            
    3. 过程的自动化
            软件生产和运维的过程自动化，　对应与软件生产流水线和软件运维自动化
```

### PasS 平台的本质

```shell
    1.一个好的 PaaS 平台应该具有分布式、服务化、自动化部署、高可用、敏捷以及分层开放的特征，并可与 IaaS 实现良好的联动。
    　服务化是 PaaS 的本质。软件模块重用，服务治理，对外提供能力是 PaaS 的本质．
    　分布式是 PaaS 的根本特性。多租户隔离、高可用、服务编排是 PaaS 的基本特性
    　自动化是 PaaS 的灵魂。自动化部署安装运维，自动化伸缩调度是 PaaS 的关键。
    2. 一个完整的 PaaS 平台会包括以下几部分:
           (1) PaaS 调度层 – 主要是 PaaS 的自动化和分布式对于高可用高性能的管理。
           (2) PaaS 能力服务层 – 主要是 PaaS 真正提供给用户的服务和能力。
           (3) PaaS 的流量调度 – 主要是与流量调度相关的东西，包括对高并发的管理。
           (4) PaaS 的运营管理 – 软件资源库、软件接入、认证和开放平台门户。
           (5) PaaS 的运维管理 – 主要是 DevOps 相关的东西。
    3. PaaS 平台的生产和运维
            从左上开始软件构建，进入软件资产库（Docker Registry+ 一些软件的定义），然后走 DevOps 的流程，
            通过整体架构控制器进入生产环境，生产环境通过控制器操作 Docker+Kubernetes 集群进行软件部署和生产变更。
            其中，同步服务的运行状态，并通过生命周期管理来拟合状态，服务运行时的数据会进入到相关应用监控，
            应用监控中的一些监控事件会同步到生命周期管理中，再由生命周期管理器来做出决定，通过控制器来调度服务运行。
            当应用监控中心发现流量变化，要进行强制性伸缩时，它通过生命周期管理来通知控制系统进行伸缩。
    4. 总结
            (1) 构建分布式系统面临的问题
                    a. 分布式系统的硬件故障发生率更高，故障发生是常态，需要尽可能地将运维流程自动化。
                    b. 需要良好地设计服务，避免某服务的单点故障对依赖它的其他服务造成大面积影响。
                    c. 为了容量的可伸缩性，服务的拆分、自治和无状态变得更加重要，可能需要对老的软件逻辑做大的修改。
                    d. 老的服务可能是异构的，此时需要让它们使用标准的协议，以便可以被调度、编排，且互相之间可以通信。
                    e. 服务软件故障的处理也变得复杂，需要优化的流程，以加快故障的恢复。
                    f. 为了管理各个服务的容量，让分布式系统发挥出最佳性能，需要有流量调度技术。
                    g. 分布式存储会让事务处理变得复杂；在事务遇到故障无法被自动恢复的情况下，手动恢复流程也会变得复杂。
                    h. 测试和查错的复杂度增大。
                    i. 系统的吞吐量会变大，但响应时间会变长。
                    
            (2) 解决方案
                    a. 需要有完善的监控系统，以便对服务运行状态有全面的了解。
                    b. 设计服务时要分析其依赖链；当非关键服务故障时，其他服务要自动降级功能，避免调用该服务。
                    c. 重构老的软件，使其能被服务化；可以参考 SOA 和微服务的设计方式，目标是微服务化；
                        使用 Docker 和 Kubernetes 来调度服务。
                    d. 为老的服务编写接口逻辑来使用标准协议，或在必要时重构老的服务以使得它们有这些功能。
                    e. 自动构建服务的依赖地图，并引入好的处理流程，让团队能以最快速度定位和恢复故障
                    f. 使用一个 API Gateway，它具备服务流向控制、流量控制和管理的功能。
                    g. 事务处理建议在存储层实现；根据业务需求，或者降级使用更简单、吞吐量更大的最终一致性方案，
                        或者通过二阶段提交、Paxos、Raft、NWR 等方案之一，使用吞吐量小的强一致性方案。
                    h. 通过更真实地模拟生产环境，乃至在生产环境中做灰度发布，从而增加测试强度；
                       同时做充分的单元测试和集成测试以发现和消除缺陷；最后，在服务故障发生时，
                       相关的多个团队同时上线自查服务状态，以最快地定位故障原因。
                    i. 通过异步调用来减少对短响应时间的依赖；对关键服务提供专属硬件资源，并优化软件逻辑以缩短响应时间。
```

# 分布式系统设计模式

## 分布式系统弹力设计

### 认识故障和弹力设计

```shell
    1.弹力设计又叫容错设计．其中着眼于分布式系统的各种“容忍”能力，包括容错能力（服务隔离、异步调用、请求幂等性）、
    　可伸缩性（有 / 无状态的服务）、一致性（补偿事务、重试）、应对大流量的能力（熔断、降级）
     
       弹力（Resiliency）的概念: 一方面，在好的情况下，这个事对于我们的用户和内部运维来说是完全透明的，系统自动修复不需要人的干预
                         　　　另一方面，如果修复不了，系统能够做自我保护，而不让事态变糟糕。
    2. 系统可用性测量
            Availability=MTTFMTTF+MTTR
            a. MTTF 是 Mean Time To Failure，平均故障前的时间，即系统平均能够正常运行多长时间才发生一次故障。
               系统的可靠性越高，MTTF 越长
            b. MTTR 是 Mean Time To Recovery，平均修复时间，即从故障出现到故障修复的这段时间，这段时间越短越好。
    3. 故障原因
            A.
                (1) 无计划的
                        a. 系统级故障，包括主机、操作系统、中间件、数据库、网络、电源以及外围设备。
                        b. 数据和中介的故障，包括人员误操作、硬盘故障、数据乱了。
                        c. 还有自然灾害、人为破坏，以及供电问题等
                (2) 有计划的
                        a. 日常任务：备份，容量规划，用户和安全管理，后台批处理应用。
                        b. 运维相关：数据库维护、应用维护、中间件维护、操作系统维护、网络维护。
                        c. 升级相关：数据库、应用、中间件、操作系统、网络，包括硬件升级。
                        
            B.
                a. 网络问题。网络链接出现问题，网络带宽出现拥塞……
                b. 性能问题。数据库慢 SQL、Java Full GC、硬盘 IO 过大、CPU 飙高、内存不足……
                c. 安全问题。被网络攻击，如 DDoS 等。
                d. 运维问题。系统总是在被更新和修改，架构也在不断地被调整，监控问题……
                e. 管理问题。没有梳理出关键服务以及服务的依赖关系，运行信息没有和控制系统同步……
                f. 硬件问题。硬盘损坏、网卡出问题、交换机出问题、机房掉电、挖掘机问题……
    4. 不要尝试着去避免故障，而是要把处理故障的代码当成正常的功能做在架构里写在代码里
```

### 弹力设计之"隔离设计" (Bulkheads)

```shell
    1.按服务的种类来做分离
            (1) 例如：将系统分成了用户、商品、社区三个版块。三个板块分别使用各自的域名、服务器和数据库，
            　　　　　做到从接入层到应用层再到数据层三层完全隔离。这样一个版块的故障就不会影响到另一版块。
            (2) 微服务所推荐的架构方式
                    每个服务都有自己的一个数据库，每个数据库中都保存着和这个业务相关的数据和相应的处理状态
            (3) 按服务的种类进行隔离存在的问题
                    a. 需要同时获得多个版块的数据，就需要同时调用多个服务，这会增加响应时间
                    b. 如果有大数据平台，就需要把这些数据都抽取到一个数据仓库中进行计算，这也增加了数据合并的复杂度。
                       对于这个问题，我们需要一个框架或是一个中间件来对数据进行相应的抽取。
                    c. 如果我们的业务逻辑或是业务流程需要跨版块的话，那么一个版块的故障也会导致整个流程走不下去，
                       同样会导致整体业务故障。
                       对于这个问题：我们需要保证这个业务流程中各个子系统的高可用性，并且在业务流程上做成 Step-by-Step 的方式，
                       　　　　　　　这样用户交互的每一步都可以保存，以便故障恢复后可以继续执行，而不是从头执行。
                    d. 有跨版块的交互变得复杂
                        对于这个问题：需要一个类似于 Pub/Sub 的高可用的并可以持久化的消息订阅通知的中间件 
                        　　　　　　　来打通各个版块的数据和信息交换。
                    e. 在多个版块中分布式事务的问题。
                        对于这个问题： 我们需要“二阶段提交”这样的方案。
                                      在亚马逊中，使用的是 Plan – Reserve – Commit/Cancel 模式。
                                      先做一个 plan 的 API 调用，然后各个子系统 reserve 住相应的资源，如果成功，则 Commit；
                                      如果有一个失败，则整体 Cancel
                                      
    2. 按用户的请求来做分离
            (1) 例如: 将用户分成不同的组，并把后端的同一个服务根据这些不同的组分成不同的实例。让同一个服务对于不同的用户进行冗余和隔离，
                     当某一个服务实例挂掉时，只会影响其中一部分用户，而不会导致所有的用户无法访问
            (2) 多租户模式
                    a. 概念
                            对于一些比较大的客户，我们可以为他们设置专门独立的服务实例，或是服务集群与其他客户隔离开来，
                            对于一些比较小的用户来说，可以让他们共享一个服务实例，这样可以节省相关的资源。
                    b. 多租户的做法
                            a. 完全独立的设计。每个租户有自己完全独立的服务和数据。
                                    在开发实现上和资源隔离度方面会非常好，然而，成本会比较高，计算资源也会有一定的浪费。
                            b. 独立的数据分区，共享的服务。多租户的服务是共享的，但数据是分开隔离的。
                            c. 共享的服务，共享的数据分区。每个租户的数据和服务都是共享的。
                                    在资源利用和成本上会非常好，然而，开发难度非常大，而且数据和资源隔离非常不好
                    c. 工程上采用的方法
                            理论上(小公司)　技术方案会使用折衷方案，也就是中间方案，服务是共享的，数据通过分区来隔离，
                            　　　　　　　　而对于一些比较重要的租户（需要好的隔离性），则使用完全独立的方式。
                            
                            大公司  使用“完全独立”（完全隔离）的方案，通过底层的虚拟化技术（Hypervisor 的技术，如 KVM
                                    ，或是 Linux Container 的技术，如 Docker）来实现物理资源的共享和成本的节约
                                    
    3. 隔离设计的重点(设计时需要考虑到问题)
            (1) 定义好隔离业务的大小和粒度，过大和过小都不好。需要熟悉业务需求和系统分析。
            (2) 无论是做系统版块(服务隔离)还是多租户的隔离，你都需要考虑系统的复杂度、成本、性能、资源使用的问题，找到一个合适的均衡方案，
            (3) 隔离模式需要配置一些高可用、重试、异步、消息中间件，流控、熔断等设计模式的方式配套使用。
            (4) 这极大增加了分布式系统中的运维的复杂度需要很多自动化运维的工具，尤其是使用像容器或是虚拟机这样的虚拟化技术可以帮助
            　　　我们更方便地管理和利用资源部。
            (5) 需要一个非常完整并且看得到所有服务的监控系统(全栈监控)
                            
```

### 弹力设计之"异步通讯设计"

```shell
    1.同步调用
            (1) 好处
                    让系统间只耦合于接口，而且实时性也会比异步调用要高
            (2) 问题
                    a. 整个同步调用链的性能会由最慢的那个服务所决定
                    b. 同步调用只能是一对一的，很难做到一对多的通讯方式
                    c. 如果被调用方有问题，那么其调用方就会跟着出问题，于是会出现多米诺骨牌效应，故障会扩散
                    
    2. 异步通信
        A. 异步通讯的好处
                (1) 异步通讯最重要的是解耦服务间的依赖。最佳解耦的方式是通过 Broker 的机制。
                    解耦的目的是让各个服务的隔离性更好，这样不会出现“一倒倒一片”的故障。
                (2) 异步通讯的架构可以获得更大的吞吐量，而且各个服务间的性能不受干扰相对独立。
                    利用 Broker 或队列的方式还可以达到把抖动的吞吐量变成均匀的吞吐量，这就是所谓的“削峰”，
                    这对后端系统是个不错的保护。
                (3) 服务相对独立，在部署、扩容和运维上都可以做到独立不受其他服务的干扰。
                
        B. 设计异步通信需要注意的
                (1) 用于异步通讯的中间件 Broker 需要设计成高可用不丢消息的。因为是分布式的，所以可能很难保证消息的顺序，
                    因此你的设计最好不依赖于消息的顺序。
                (2) 异步通讯会导致业务处理流程不那么直观，因为像接力一样，所以在 Broker 上需要有相关的服务消息跟踪机制，
                    否则出现问题后不容易调试。
                (3) 消息传递中，可能有的业务逻辑会有像 TCP 协议那样的 send 和 ACK 机制。
                    比如：A 服务发出一个消息之后，开始等待处理方的 ACK，如果等不到的话，就需要做重传。此时，需要处理方有幂等的处理，
                        即同一件消息无论收到多少次都只处理一次。
                    
        A. 异步通讯的三种方式
                (1) 请求响应式
                        发送方依赖于接收方，并且要把自己的回调发送给接收方，接收方处理完后回调。
                (2) 通过直接订阅方式
                        接收方（receiver）会来订阅发送方（sender）的消息，发送方会把相关的消息或数据放到接收方所订阅的队列中，
                        而接收方会从队列中获取数据。
                (3) 通过 Broker 的方式(中间人订阅)
                        发送方（sender）和接收方（receiver）都互相看不到对方，它们看得到的是一个 Broker，
                        发送方向 Broker 发送消息，接收方向 Broker 订阅消息
                        
                        在 Broker 这种模式下，发送方的服务和接收方的服务最大程度地解耦。但是所有人都依赖于一个总线，
                        所以这个总线就需要有如下的特性：
                            a. 必须是高可用的，因为它成了整个系统的关键；
                            b. 必须是高性能而且是可以水平扩展的；
                            c. 必须是可以持久化不丢数据的。
                    
        B. 分布式系统的服务设计是需要向无状态服务（Stateless）努力的，无状态意味着你可以非常方便地运维。
           所以，事件通讯成为了异步通讯中最重要的一个设计模式。
      
        C. 事件驱动设计
                每个服务都是“自包含”的。所谓“自包含”也就是没有和别人产生依赖。而要把整个流程给串联起来，
                我们需要一系列的“消息通道（Channel）”。各个服务做完自己的事后，发出相应的事件，
                而又有一些服务在订阅着某些事件来联动。
                
                (1) 事件驱动方式的好处
                        a. 服务间的依赖没有了，服务间是平等的，每个服务都是高度可重用并可被替换的。
                        b. 服务的开发、测试、运维，以及故障处理都是高度隔离的。
                        c. 服务间通过事件关联，所以服务间是不会相互 block 的。
                        d. 在服务间增加一些 Adapter（如日志、认证、版本、限流、降级、熔断等）相当容易。
                        e. 服务间的吞吐也不再受限了，各个服务可以按照自己的处理速度处理。
                (2) 事件驱动方式的坏处
                        a. 业务流程不再那么明显和好管理。整个架构变得比较复杂。
                           解决这个问题需要有一些可视化的工具来呈现整体业务流程。
                        b. 事件可能会乱序。这会带来非常 Bug 的事。
                           解决这个问题需要很好地管理一个状态机。
                        c. 事务处理变得复杂。
                           需要使用两阶段提交来做强一致性，或是退缩到最终一致性。        
```

### 弹力设计之“幂等性设计”(Idempotency)

```shell
    1. 概念: 一次和多次请求某一个资源应该具有同样的副作用.
    2. 背景: 在我们把系统解耦隔离后，服务间的调用可能会有三个状态，
             一个是成功（Success），一个是失败（Failed），一个是超时（Timeout）. 而针对超时,调用者会重新再调一次接口
             
             例如:
                a. 订单创建接口，第一次调用超时了，然后调用方重试了一次。是否会多创建一笔订单？
                b. 订单创建时，我们需要去扣减库存，这时接口发生了超时，调用方重试了一次。是否会多扣一次库存？
                
             处理方式:
                a. 一种是需要下游系统提供相应的查询接口。上游系统在 timeout 后去查询一下。如果查到了，就表明已经做了，
                   成功了就不用做了，失败了就走失败流程。
                b. 另一种是通过幂等性的方式。把这个查询操作交给下游系统，我上游系统只管重试，
                   下游系统保证一次和多次的请求结果是一样的。
    3. 全局 ID
            要做到幂等性的交易接口，需要有一个唯一的标识，来标志交易是同一笔交易。
            而这个交易 ID 由谁来分配是一件比较头疼的事。因为这个标识要能做到全局唯一。
            
            解决方法:
                    (1) 如果由一个中心系统来分配，那么每一次交易都需要找那个中心系统来。 这样增加了程序的性能开销。
                    (2) 如果由上游系统来分配，则可能会导致可能会出现分配 ID 重复了的问题。
                        因为上游系统可能会是一个集群，它们同时承担相同的工作。
                    (3) 采用　UUID 这样冲突非常小的算法．
                            但是它的字符串占用的空间比较大，索引的效率非常低，生成的 ID 太过于随机，完全不是人读的，
                            而且没有递增，如果要按前后顺序排序的话，基本不可能。
                    (4)  Twitter 的开源项目 Snowflake(推荐使用) 
                                产生一个 long 型的 ID，其中：
                                    41bits 作为毫秒数。大概可以用 69.7 年。
                                    10bits 作为机器编号（5bits 是数据中心，5bits 的机器 ID），支持 1024 个实例。
                                    12bits 作为毫秒内的序列号。一毫秒可以生成 4096 个序号。
                                    
    4. 幂等性的处理流程
            一般做法: 收到交易请求(交易 ID)的时候，我们就会到这个存储中去查询。
                     如果查找到了，那么就不再做查询了，并把上次做的结果返回。如果没有查到，那么我们就记录下来。
                     
            优化方法: 绝大多数请求应该都不会是重新发过来的，所以让 100% 的请求都到这个存储里去查一下，
                    这会导致处理流程可能会很慢。
                    我们可以在收到交易请求后，直接去存储里记录这个 ID（相对于数据的 Insert 操作），
                    如果出现 ID 冲突了的异常，那么我们就知道这个之前已经有人发过来了，所以就不用再做了
                    
    5. 示例(HTTP 的幂等性)
            (1) HTTP GET 方法用于获取资源,不应有副作用,满足幂等性的。但不代表每次 GET 的结果相同，
            　　　例如GET http://www.news.com/latest-news这个 HTTP 请求可能会每次得到不同的结果，但它本身并没有产生任何副作用
            (2) HTTP HEAD 可以用来做探活使用。其也是幂等性
            (3) HTTP DELETE 方法用于删除资源，有副作用，但它应该满足幂等性。
                比如：DELETE http://www.forum.com/article/4231，调用一次和 N 次对系统产生的副作用是相同的，
                即删掉 ID 为 4231 的帖子。因此，调用者可以多次调用或刷新页面而不必担心引起错误。
            (4) HTTP POST 方法不具备等幂性，这个是用于创建资源，所对应的 URI 并非创建的资源本身，而是去执行创建动作，有副作用，
            　　不满足幂等性。比如：POST http://www.forum.com/articles　是在http://www.forum.com/articles
            　　下创建一篇帖子，HTTP 响应中应包含帖子的创建状态以及帖子的 URI。
               两次相同的 POST 请求会在服务器端创建两份资源，它们具有不同的 URI；所以，POST 方法不具备幂等性。
               
               在 Http协议是不具备等幂性,在浏览器中如果想将 post 具备等幂性,需要采取如下操作:
                    a. 第一,在表单中需要隐藏一个 token，这个 token 可以是前端生成的一个唯一的 ID。
                       用于防止用户多次点击了表单提交按钮，而导致后端收到了多次请求，却不能分辨是否是重复的提交。
                       这个 token 是表单的唯一标识。（这种情况其实是通过前端生成 ID 把 POST 变成了 PUT。）
                    b. 当用户点击提交后，后端会把用户提示的数据和这个 token 保存在数据库中。
                       如果有重复提交，那么数据库中的 token 会做排它限制，从而做到幂等性。
                   
                    更为稳妥的做法是，后端成功后向前端返回 302 跳转，把用户的前端页跳转到 GET 请求，把刚刚 POST 的数据给展示出来。
                    如果是 Web 上的最好还把之前的表单设置成过期，这样用户不能通过浏览器后退按钮来重新提交。
                    这个模式又叫做 PRG 模式（Post/Redirect/Get）
               
            (5) HTTP PUT 方法具备等幂性，用于创建或更新操作，所对应的 URI 是要创建或更新的资源本身，有副作用，
                比如：PUT http://www.forum/articles/4231的语义是创建或更新 ID 为 4231 的帖子。
                对同一 URI 进行多次 PUT 的副作用和一次 PUT 是相同的；因此，PUT 方法具有幂等性。
```

### 弹力设计之“服务的状态”

```shell
    1. 在幂等设计中，为了过滤掉已经处理过的请求，其中需要保存处理过的状态，为了把服务做成无状态的，我们引入了第三方的存储
    2. 状态，就是为了保留程序的一些数据或是上下文。状态的应用:
            (1) 幂等性设计中所说的需要保留下每一次请求的状态
            (2) 用户登录时的 Session，我们需要这个 Session 来判断这个请求的合法性
            (3) 一个业务流程中需要让多个服务组合起来形成一个业务逻辑的运行上下文 Context
    3. 无状态的服务 Stateless
            (1) 无状态的服务被当成分布式服务设计的最佳实践和铁律.原因如下:
                   a. 无状态的服务有利于扩展性和运维。没有状态的服务，可以随意地增加和减少结点，
                      同样可以随意地搬迁。
                   b. 无状态的服务可以大幅度降低代码的复杂度以及 Bug 数，因为没有状态，所以也没有明显的“副作用”。
                   
                 无状态的服务劣势:
                    a. 服务之间有依赖
                    b. 增加了网络开销，导致服务的响应时间也会变慢
            (2) 状态的表现
                    a. 程序调用的结果。
                    b. 服务组合下的上下文。
                    c. 服务的配置。
            (3) 做出无状态的服务，需要把状态保存到一个第三方的地方(这就得保证存储服务也必须要做成高可用高扩展的方式)。
                比如，不太重要的数据可以放到 Redis 中，重要的数据可以放到 MySQL 中
            (4) 无状态的服务需要依赖于像 ZooKeeper/Etcd 这样的高可用的有强一致的服务，
                或是依赖于底层的分布式文件系统（像开源的 Ceph 和 GlusterFS）
    4. 有状态的服务 Stateful
            (1) 好处:
                    a. 数据本地化（Data Locality）. 状态和数据在本机保存，延时低.对于数据密集型的应用来说，这会更快。
                    b. 更高的可用性和更强的一致性。也就是 CAP 原理中的 A 和 C。
            (2)  Sticky Session(Sticky Connection) : 对于客户端传来的请求，都必须保证其落在同一个实例上
            (3) 无状态的服务需要我们把数据同步到不同的结点上，而有状态的服务通过 Sticky Session 做数据分片
            (4) Sticky Session 的实现
                    用持久化的长连接。就算是 HTTP 协议也要用长连接。或是通过一个简单的哈希（hash）算法，比如，通过 uid 求模的方式，
                    走一致性哈希的玩法，也可以方便地做水平扩展。
                    
                    持久化的长连接存在问题:
                        结点的负载和数据不均匀.可以通过反向压力 (Back Pressure)(如果服务端成为热点，就主动断连接,配合客户端使用)
                        
                    实现负载和数据均匀:
                        通过[元数据索引]来映射后端服务实例和请求的对应关键.其中分为要不要用路由结点
                            方法一:使用路由结点,它会根据[元数据索引]来路由,元数据索引表会根据后端服务的压力来重新组织相关的映射。
                            方法二:不使用路由结点
                                        方式一: 直接使用配置，在节点启动时把其元数据读到内存中，以后增加或减少结点都需要更新这个配置，
                                               会导致其它结点也一同要重新读入. 例如 Facebook 的 Scuba，
                                               这是一个分布式的内存数据库，它使用了方式一
                                               
                                        方式二: 使用到 Gossip 协议(比较好的做法), 通过这个协议在各个节点之间互相散播消息来同步
                                               元数据，这样新增或减少结点，集群内部可以很容易重新分配
                                               
    5. 服务状态的容错设计
            在容错设计中，服务状态是一件非常复杂的事。尤其对于运维来说，因为你要调度服务就需要调度服务的状态，
            迁移服务的状态就需要迁移服务的数据。在数据量比较大的情况下，这一点就变得更为困难了。
            虽然上述有状态的服务的调度通过 Sticky Session 的方式是一种方式，但我依然觉得理论上来说虽然可以这么干，这实际在运维的过程中，
            这么干还是件挺麻烦的事儿，不是很好的玩法。
            
            很多系统的高可用的设计都会采取数据在运行时就复制的方案，比如：ZooKeeper、Kafka、Redis 或是 ElasticSearch 等等。
            在运行时进行数据复制就需要考虑一致性的问题，所以，强一致性的系统一般会使用两阶段提交。
            这要求所有的结点都需要有一致的结果，这是 CAP 里的 CA 系统。而也有的系统采用的是大多数人一致就可以了，比如 Paxos 算法，
            这是 CP 系统。
            但我们需要知道，即使是这样，当一个结点挂掉了以后，在另外一个地方重新恢复这个结点时，这个结点需要把数据同步过来才能提供服务。
            然而，如果数据量过大，这个过程可能会很漫长，这也会影响我们系统的可用性。
            所以，我们需要使用底层的分布式文件系统，对于有状态的数据不但在运行时进行多结点间的复制，同时为了避免挂掉，
            还需要把数据持久化在硬盘上，这个硬盘可以是挂载到本地硬盘的一个外部分布式的文件卷。
            这样当结点挂掉以后，以另外一个宿主机上启动一个新的服务实例时，这个服务可以从远程把之前的文件系统挂载过来。
            然后，在启动的过程中就装载好了大多数的数据，从而可以从网络其它结点上同步少量的数据，因而可以快速地恢复和提供服务。
            这一点，对于有状态的服务来说非常关键。所以，使用一个分布式文件系统是调度有状态服务的关键。
            
    6. 小结
            无状态的服务就像一个函数一样，对于给定的输入，它会给出唯一确定的输出。它的好处是很容易运维和伸缩，
            但需要底层有分布式的数据库支持。
            
            有状态的服务，它们通过 Sticky Session、一致性 Hash 和 DHT 等技术实现状态和请求的关联，并将数据同步到分布式数据库中；
            利用分布式文件系统，还能在节点挂掉时快速启动新实例
            
```

### 弹力设计之“补偿事务”(Compensating Transaction)

```shell
    1.分布式系统有一个比较明显的问题就是，一个业务流程需要组合一组服务。这样的事情在微服务下就更为明显了，这需要业务上的一致性的保证。
      如果一个步骤失败了，要么回滚到以前的服务调用，要么不断重试保证所有的步骤都成功。
      如果需要强一性的需求则在业务层上需要使用“两阶段提交”这样的方式。但是好在我们的很多情况下并不需要这么强的一致性，
      而且强一致性的最佳保证最好是在底层完成。或是像之前说的那样 Stateful 的 Sticky Session 那样在一台机器上完成。
      在我们接触到的大多数业务，其实只需要最终一致性就好
    2. ACID 
            (1) 传统关系型数据库系统的事务都有 ACID 属性，即原子性（Atomicity）、一致性（Consistency）、
                隔离性（Isolation，又称独立性）、持久性（Durability）
                
            (2) 原子性: 整个事务中的所有操作，要么全部完成，要么全部不完成，不可能停滞在中间某个环节。
                       事务在执行过程中发生错误，会被回滚（Rollback）到事务开始前的状态，就像这个事务从来没有执行过一样。
            (3) 一致性: 在事务开始之前和事务结束以后，数据库的完整性约束没有被破坏。
            (4) 隔离性: 两个事务的执行是互不干扰的，一个事务不可能看到其他事务运行时，中间某一时刻的数据。两个事务不会发生交互。
            (5) 持久性: 在事务完成以后，该事务对数据库所做的更改便持久地保存在数据库之中，并不会被回滚。
    3. BASE
            (1) 
               a. Basic Availability：基本可用。系统可以出现暂时不可用的状态，但是后面会快速恢复。
               b. Soft-state：软状态。它是我们前面的“有状态”和“无状态”的服务的一种中间状态。为了提高性能，
                               我们可以让服务暂时保存一些状态或数据，这些状态和数据不是强一致性的。
               c. Eventual Consistency：最终一致性，系统在一个短暂的时间段内可以不一致的，但最终整个系统看到的数据是一致的。
                
            (2) Design for Failure: 在分布式系统中，故障是不可避免的，我们能做的就是把 故障处理 作为 功能点写入代码中
            (3) BASE 系统是允许系统出现暂时性的问题,其更加的弹力,即在短时间内允许数据不同步,只需要在后面我们对于业务上将可能出现问题
                的事务给处理掉，以保证最终的一致性
    4. 两种模式的应用场景(买书)
            (1) ACID 
                    大家在买同一本书的过程中，每个用户的购买请求都需要把库存锁住，等减完库存后，把锁释放出来，后续的人才能进行购买。
                    在 ACID 的模式下，我们在同一时间不可能有多个用户下单，我们的订单流程需要有排队的情况，
                    这样我们就不可能做出高性能的系统。
            (2) BASE
                    大家都可以同时下单，这个时候不需要去真正地分配库存，然后系统异步地处理订单，而且是批量的处理。
                    因为下单的时候没有真正去扣减库存，所以，有可能会有超卖的情况。而后台的系统会异步地处理订单时，
                    发现库存没有了，于是才会告诉用户你没有购买成功。
                    
    5. 业务补偿
            (1) 在分布式系统中,当条件不满足，或是有变化的时候，需要从业务上做相应的整体事务的补偿,业务的事务补偿都是需要一个工作流引擎的,
                这个工作流引擎把各式各样的服务给串联在一起，并在工作流上做相应的业务补偿，整个过程设计成为最终一致性的
                
            (2) 对于业务补偿，首先需要将服务做成幂等性的，即如果一个事务失败或是超时，我们需要不断地重试，努力地达到最终我们想要的状态。
                如果不能达到想要的状态，需要把整个状态恢复到之前的状态(回滚)。
                如果有变化的请求，需要启动整个事务的业务更新机制。
                
            (3) 业务补偿机制需要做到
                    a. 要能知道应该达到什么样的状态（比如：请假、机票、酒店这三个都必须成功，租车是可选的），
                        以及如果其中的条件不满足，我们要回退到哪一个状态。这就是整个业务的起始状态定义。
                    b. 当整条业务跑起来的时候，我们可以串行或并行地做这些事。对于旅游订票是有些步骤是可以并行的，
                       但是对于网购流程（下单、支付、送货）是不能并行的。
                       我们的系统通过一系列的操作达到想要的状态。如果达不到，需要通过补偿机制回滚到之前的状态,这就是所谓的状态拟合。
                    c. 对于已经完成的事务进行整体修改。其实可以考虑成一个修改事务。
                    
            (3) 业务补偿的设计重点
                    a. 把一个业务流程执行完成，需要这个流程中所涉及的服务方支持幂等性,并且在上游有重试机制
                    b. 需要工作流引擎(业务流程的控制方) 维护和监控整个过程的状态,如果有问题，可以进行回滚和补偿的。
                    c. 下层的业务方最好提供短期的资源预留机制。
                        例如电商把货品的库存预先占住来等待用户在 15 分钟内支付。如果没有收到用户的支付，则释放库存。
                        然后回滚到之前的下单操作，等待用户重新下单。
                        
    6. 小结
            在分布式系统中，ACID 有更强的一致性，但可伸缩性非常差，仅在必要时使用；
            BASE 的一致性较弱，但有很好的可伸缩性，还可以异步批量处理；大多数分布式事务适合 BASE。
            要实现 BASE 事务，需要实现业务补偿
``` 

### 弹力设计之“重试设计”(Retry)

```shell
    1. 重试的场景(在声明情况下进行重试)
            重试的场景: 调用超时、被调用端返回了某种可以重试的错误（如繁忙中、流控中、维护中、资源不足等）
            不需要重试的场景: 业务级的错误（如没有权限、或是非法数据等错误）
                            技术上的错误（如：HTTP 的 503 等，这种原因可能是触发了代码的 bug，重试下去没有意义）
         
    2. 重试的策略
            需要有个重试的最大值，经过一段时间不断的重试后，就没有必要再重试了，应该报故障了.
            同时可以采用指数级退避(Exponential Backoff),每一次重试的间隔都会翻倍增加, 之后增加到某个最大值,将不再增加,
            以后重试的时间间隔就是这个最大值.这种机制主要是用来让被调用方能够有更多的时间来从容处理我们的请求
            
    3. 重试设计的重点
            (1) 确定什么样的错误下需要重试
            (2) 确定重试的时间间隔和重试的次数。在不同的情况下要有不同的考量
            (3) 重试还需要考虑被调用方是否有幂等的设计
            
```

### 弹力设计之“熔断设计”(Circuit Breaker)

```shell
    1. 在分布式系统中,如果错误太多，或是在短时间内得不到修复，那么重试也没有意义，此时应该开启熔断操作，尤其是后端太忙的时候，
       使用熔断设计可以保护后端不会过载
    2. 熔断器的状态
            (1) 闭合（Closed）状态：
                    我们需要一个计数器(用于记录调用失败)，如果调用失败，则计数器加 1.如果失败次数超过了在给定时间内允许失败的阈值，
                    则切换到断开 (Open) 状态。此时开启了一个超时时钟，超时事件发生时，则切换到半断开（Half-Open）状态。
                    该超时时间的设定是给系统一次机会来修正导致调用失败的错误，以回到正常工作的状态。
                    在 Closed 状态下，错误计数器是基于时间的。在特定的时间间隔内会自动重置。
                    这能够防止由于某次的偶然错误导致熔断器进入断开状态。也可以基于连续失败的次数。
            (2) 断开 (Open) 状态：在该状态下，对应用程序的请求会立即返回错误响应，而不调用后端的服务。这样也许比较粗暴，
                                有些时候，我们可以 cache 住上次成功请求，直接返回缓存(这个缓存可以放在本地内存)，
                                如果没有缓存再返回错误（缓存的机制最好是全局一样的数据，而不是用在不同的用户间不同的数据，
                                                    因为后者需要缓存的数据有可能会很多）
            (3) 半开（Half-Open）状态：允许应用程序[一定数量]的请求去调用服务。如果这些请求对服务的调用成功，
                                     那么可以认为之前导致调用失败的错误已经修正，此时熔断器切换到闭合状态 (并且将错误计数器重置)。
                                     如果这一定数量的请求有调用失败的情况，则认为导致之前调用失败的问题仍然存在，
                                     熔断器切回到断开状态，然后重置计时器来给系统一定的时间来修正错误。
                                     半断开状态能够有效防止正在恢复中的服务被突然而来的大量请求再次拖垮
                                     
    3. 实现熔断器模式使系统更加稳定和弹性，能够使系统从错误中恢复的时候提供稳定性，并且减少错误对系统性能的影响。
    　　它通过快速地拒绝那些导致错误返回的服务调用(断开状态)，而不是等待操作超时m], 这样提高系统的响应时间。
       如果熔断器设计模式在每次状态切换时发出一个事件，该事件可以用来监控服务的运行状态，并且通知管理员在熔断器状态切换到
       断开状态时进行处理。
       
    4. 熔断设计的重点
            (1) 错误的类型.根据不同的错误情况调整相应的策略。一些错误(例如限流,超时)可以先进行重试的策略，重试几次后再打开熔断。
            　　　　　　　　而一些错误(例如远程服务挂掉），其恢复时间比较长，那么直接采用熔断策略。
            (2) 日志监控. 熔断器应该记录所有失败的请求，以及失败后又能成功的请求，使得管理员可以了解服务(使用熔断器保护)的执行情况。
            (3) 在断开状态下探测服务是否可用
                    在断开状态定期地探测远程的服务的健康检查接口，来判断服务是否恢复，而不是使用计时器来自动切换到半开状态．
                    这样做的优点是在服务恢复的情况下，不需要用户真实流量就可以把状态从半开状态切回闭合状态，从而减少对用户
                    的影响．
            (4) 手动重置状态
                    管理员需要立即恢复时可以手动地强制将熔断器切换到闭合状态。
                    如果受熔断器保护的服务暂时不可用的话，管理员能够强制将熔断器设置为断开状态
            (5) 并发问题
                    大量并发的请求同时访问相同的熔断器。熔断器的实现不应该阻塞并发的请求或者增加每次请求调用的负担。
                    最好使用一些无锁的数据结构，或是 atomic 的原子操作，提高性能。
            (6) 资源分区
                    有时候会把资源分布在不同的分区上。比如，数据库的分库分表，某个分区可能出现问题，而其它分区还可用。
                    这种情况单一的熔断器会把所有的分区访问当成一个整体，一旦开始熔断，所有的分区都会受到熔断影响
                    或是出现一会儿熔断一会儿又好，来来回回的情况。所以，好的熔断器只对有问题的分区进行熔断，而不是整体。
```

### 弹力设计之“限流设计”(Throttle)

```shell
    1.使系统在过载的情况下能够正常运行，需要采用限流策略
    2.限流的策略
            (1) 对于异常请求拒绝服务。
                    把多出来的请求拒绝掉。在流量暴增时，系统统计当前哪个客户端来的请求最多，直接拒绝该客户端的请求，
                    这种策略可以把一些不正常的或者是有恶意的高并发访问抵挡掉
            (2) 服务降级
                    关闭或是把后端服务做降级处理，可以让服务有足够的资源来处理更多的请求。
                    降级有很多方式，一种是把一些不重要的服务给停掉，把 CPU、内存或是数据的资源让给更重要的功能；
                    　　　　　　　　一种是不再返回全量数据，只返回部分数据，全量数据需要做 SQL Join 操作，部分的数据则不需要，
                    　　　　　　　　　　可以让 SQL 执行更快
                    　　　　　　　　还有最快的一种是直接返回预设的缓存，以牺牲一致性的方式来获得更大的性能吞吐。
            (3) 特权请求
                    资源不够只能把有限的资源分给重要的用户，比如：分给权利更高的 VIP 用户。
                    在多租户系统下，限流的时候应该保大客户的，大客户可以优先处理，而其它的非特权用户就得等待
            (4) 延时处理
                    一个队列来缓冲大量的请求，如果队列满了，接下来就只能拒绝用户请求，如果这个队列中的任务超时，要返回错误(系统繁忙)
                    使用缓冲队列只是为了减缓压力，一般用于应对短暂的峰刺请求。
            (5) 弹性伸缩
                    通过自动化运维的方式对相应的服务进行自动化的伸缩。这个需要一个应用性能的监控系统，
                    能够检测到目前系统中最繁忙的服务．然后去伸缩它们，同时需要一个自动化的发布、部署和服务注册的运维系统，
                    整套流程要快。如果是数据库的压力过大，弹性伸缩就没有用，对应的应该采用限流策略
    3. 静态限流的实现方式
            (1) 计数器方式(最简单的限流算法)
                    维护一个计数器 Counter，当一个请求来时，就做加一，当一个请求处理完后就做减一。
                    如果这个 Counter 大于某个数（我们设定的限流阈值），就开始拒绝请求以保护系统的负载
            (2) 队列算法
                    请求的速度可以是波动，而处理的速度则是均速的,即先将请求放入队列中，处理服务从队列中取．
                    更灵活的操作是定义各个不同优先级的队列，根据该队列中不同权重进行处理
                    缺点:
                        用队列长度来控制流量，在配置上比较难以操作。
                        队列的长度要合适，如果队列过长，导致后端服务在队列没有满时就挂掉了
            (3) 漏斗算法(Leaky Bucket)
                    这个“漏斗”是用一个队列来实现的，当请求过多时，队列就会开始积压请求，如果队列满了，就会开拒绝请求。
                    很多系统都有这样的设计，比如 TCP。当请求的数量过多时，就会有一个 sync backlog 的队列来缓冲请求，
                    TCP 的滑动窗口也是用于流控的队列。
            (4) 令牌桶算法(Token Bucket)
                    令牌桶算法，在一个桶内按一定的速率放入一些 token(令牌)，当处理程序要处理请求时，需要拿到 token 才能处理；
                    如果拿不到，则不处理。它与漏斗算法的区别是，漏斗算法处理请求是以恒定的速度处理的，而令牌桶算法则是在流量小的时候
                    积累 token(令牌)，流量大的时候，可以快速处理。
                    
    4. 动态限流(基于响应时间)
            (1) 分布式无法确定一个限流值的原因:
                    a. 很多服务会依赖于数据库。不同的用户请求，会对不同的数据集进行操作,数据库的数据是在不断地变化,其对应的
                    　　性能也是不断的变化，所以我们很难给出一个确定的限流值
                    b. 不同的 API 有不同的性能。为每一个 API 配置不同的限流值，这点太难配置，也很难管理
                    c. 现在的服务是能自动化伸缩的，不同大小的集群的性能也不一样，很难根据自动化伸缩动态地调整限流的阈值
            (2) 自动限流的要点
                    a. 计算的一定时间内的 P90(在一定时间内的请求的响应时间排个序，然后看 90%　是多少) 或 P99.在有大量请求的情况下，
                    　　这个非常地耗内存也非常地耗 CPU(需要对大量的数据进行排序),解决方案有两种，一种是不记录所有的请求，采样就好了，
                       另一种是使用一个叫蓄水池的近似算法(Reservoir Sampling)
                    b. 动态流控需要像 TCP ，你需要记录一个当前的 QPS. 如果发现后端的 P90/P99 响应太慢, 则通过慢启动，将 QPS 直接
                    　　减半，待 后端的 P90/P99 响应变快，则逐步增加 QPS.
                    
    5. 限流目的
            (1) 在多租户的情况下，防止某一用户把资源耗尽而让所有的用户都无法访问的问题
            (2) 应对突发的流量
            (3) 节约成本。不会为一个不常见的尖峰来把我们的系统扩容到最大的尺寸,在有限的资源下能够承受比较高的流量。　
            
    6. 设计限流时考虑方面
            (1) 在架构的早期就考虑限流的。当架构形成后，限流不是很容易加入。
            (2) 限流模块必需要有好的性能，而且对流量的变化要灵敏的，否则太过迟钝的限流，系统会因为早早得过载而挂掉了。
            (3) 限流应该有个手动的开关，在应急的时候，可以手动操作。
            (4) 当限流发生时，应该有个监控事件通知。让我们知道有限流事件发生，这样运维人员可以及时跟进.
                而且还可以自动化触发扩容或降级，以缓解系统压力。
            (5) 当限流发生时，对于拒掉的请求，我们应该返回一个特定的限流错误码。可以和其它错误区分开来。客户端看到限流，
                可以调整发送速度，或是走重试机制。
            (6) 限流应该让后端的服务感知到。限流发生时，我们应该在协议头中塞进一个标识，比如 HTTP Header 中，放入一个限流的级别，
                告诉后端服务目前正在限流中。后端服务可以根据这个标识决定是否做降级。
```

### 弹力设计之“降级设计”(Degradation)

```shell
    1.降级设计是为了解决资源不足和访问量过大的问题,需要暂时牺牲掉一些东西(降低一致性, 停止次要功能, 简化功能)，
      保障整个系统的平稳运行。
      
    2. 降低一致性
            (1) 从强一致性变成最终一致性,可以有效地释放资源，并且让系统运行得更快，从而可以扛住更大的流量,方法有两种，
            　　 做法如下:
                    a. 简化流程的一致性(使用异步简化流程)
                            例如．电商的下单交易系统中，在强一致的情况下是使用全同步的方式，
                            结算账单->扣除库存->发起支付->发货, 这一系列的操作都是同步进行的，其处理时间慢，如果在支付
                            方面(银行接口有问题)，则将导致无法发货．在系统降级时(改为最终一致性)，把这一系列的操作做成异步的，
                            快速结算订单，不占库存，然后把在线支付降级成用户到付，省去支付环节，然后批量处理用户的订单，向用户发货，
                            用户货到付款。这种功能降级可能会损害用户的体验，一般给用户友好的提示
                    b. 降低数据的一致性
                            I. 降低数据的一致性会使用缓存的方式，或是直接就去掉数据。比如，在页面上不显示库存的具体数字，
                               只显示有还是没有库存这两种状态
                            II. 对于缓存来说，可以有效地降低数据库的压力，把数据库的资源交给更重要的业务，这样就能让系统更快速地运行。
                            
    3. 停止次要功能
            把一些不重要的功能给暂时停止掉，让系统释放出更多的资源来.最好不要停止次要的功能，首先可以限制次要的功能的流量，
            最后如果量太大了，我们才会进入停止功能的状态
            
    4. 简化功能
            一个 API 会有两个版本，一个版本返回全量数据，另一个版本只返回部分或最小的可用的数据。
            例如, 对于一个商品，一个 API 会把商品详情页或文章的内容和所有的评论都返回到前端。在降级的情况下，
           我们就只返回商品信息和文章内容，而不返回用户评论(用户评论会涉及更多的数据库操作), 同时商品信息或文章信息可以放在缓存中，
           这样又能释放出更多的资源
           
    5. 降级设计的要点
            (1) 定义好降级的关键条件(触发点)，如吞吐量过大、响应时间过慢、失败次数多过，有网络或是服务故障
            (2) 功能降级需要梳理业务的功能，哪些是 must-have 的功能，哪些是 nice-to-have 的功能；哪些是必需要死保的功能，
                                        哪些是可以牺牲的功能。而且在事前需要设计好可以简化的或是用来应急的业务流程。
                                        当系统出问题的时候，就需要走简化应急流程。  　　
```

### 弹力设计总结

```shell
    1.弹力设计总图
            (1) 第一，我们的服务不能是单点，需要在架构中冗余服务(有多个服务的副本),这需要使用到的具体技术有：
                    a. 负载均衡 + 服务健康检查 -- 可以使用像 Nginx 或 HAProxy 这样的技术；
                    b. 服务发现 + 动态路由 + 服务健康检查，比如 Consul 或 Zookeeper；
                    c. 自动化运维，Kubernetes 服务调度、伸缩和故障迁移
            (2) 第二，需要隔离业务,需要对服务进行解耦和拆分，这需要技术。
                    a. bulkheads 模式：业务分片 、用户分片、数据库拆分。
                    b. 自包含系统：所谓自包含系统是从单体到微服务的中间状态，其把一组密切相关的微服务给拆分出来，
                                 只需要做到没有外部依赖就行。
                    c. 异步通讯：服务发现、事件驱动、消息队列、业务工作流。
                    d. 自动化运维：需要服务调用链和性能监控的监控系统。
            (3) 第三，容错设计(弹力设计)。需要技术。
                        a. 错误方面：调用重试 + 熔断 + 服务的幂等性设计。
                        b. 一致性方面：强一致性使用两阶段提交、最终一致性使用异步通讯方式。
                        c. 流控方面：使用限流 + 降级技术。
                        d. 自动化运维方面：网关流量调度，服务监控。
                       
    2.弹力设计开发和运维
            (1) 运维(至少需要两个系统), 一个是服务监控(像 APM )；另一个是服务调度的系统(如：Docker + Kubernetes)
```

## 分布式系统管理设计

### 管理设计之"分布式锁"(Distributed Lock)

```shell
    1. 分布式的锁服务，可以用数据库 DB、Redis 和 ZooKeeper 等实现
    2. 锁服务特点
            (1) 安全性（Safety）：在任意时刻，只有一个客户端可以获得锁（排他性）。
            (2) 避免死锁：客户端最终一定可以获得锁(即使获得该锁的客户端在释放锁之前崩溃或者网络不可达), 
                         Redis 的锁服务的做法是通过超时时间来释放锁．
            (3) 容错性：只要锁服务集群中的大部分节点存活，Client 就可以进行加锁解锁操作。
            
    3. Redis 分布式锁服务的问题
            (1) Redis 的锁服务超时释放锁导致的问题．例如，A 服务先得到锁，但 A 服务因为 IO 等待阻塞了，而此时因为锁超时
            　　导致被释放(A 服务还不知道)，这时 B 服务成功的获得锁，要对其管理的资源进行操作，刚好此时 A 服务右就绪，继续
            　　处理数据，这时候对应的数据就乱了
            (2) 解决方案一: 乐观锁机制(需要一个版本号排它)，该锁的版本号是由 Redis 提供的
                                当 A 服务获得锁时，会得到一个锁的版本号(Version:76),该锁的版本号是由 Redis 提供的，
                                A 服务因为 IO 等待阻塞了，而此时因为锁超时致被释放,B 服务成功的获得锁,
                                B 服务得到更高的该锁的版本号(Version:77), 此时对资源进行操作需要
                                验证锁的版本号是不是比之前要高，如果要高则运行进行操作，如果低的话则不允许操作．
            (3) 解决方案二: 利用数据库本身保存的版本号
                                使用数据版本（Version）记录机制，为数据增加一个版本标识(在数据库表增加一个数字类型的 "version" 
                                字段来实现)。当读取数据时，将 version 字段的值一同读出，数据每更新一次， version 值加一。
                                当我们提交更新时，数据库表对应记录的版本信息与第一次取出来的 version 值进行比对。
                                如果数据库表当前版本号与第一次取出来的 version 值相等，则予以更新，否则认为是过期数据
```

### 管理设计之"配置中心"(Configuration Management)

```shell
    1. 软件的配置中心是分布式系统的一个必要组件.需要配置的参数有数据库的用户名和密码，线程池大小、队列长度等运行参数，
    　 以及日志级别、算法策略等，还有一些是软件运行环境的参数，如 Java 的内存大小，应用启动的参数，包括操作系统的一些参数配置……
    
    2. 区分软件的配置
        (1) 如果这些配置没有按照各个层次管理起来，会增加太多系统维护的复杂度
        (2) 
            a. 静态配置
                    在软件启动时的一些配置，运行时基本不会进行修改(环境或软件初始化时需要用到的配置)
                    例如，操作系统的网络配置，软件运行时 Docker 进程的配置，这些配置在软件环境初始化时就确定了，未来基本不会修改了
                    
            b. 动态配置
                    在运行时会被修改。比如，日志级别、降级开关、活动开关
                    I.   按运行环境分。有开发环境、测试环境、预发环境、生产环境。这些环境上的运行配置都不完全一样
                    II.  按依赖区分。一种是依赖配置，一种是不依赖的内部配置。比如，外部依赖的 MySQL 或 Redis 的连接配置
                    III. 按层次分. 像云计算一样，分成 IaaS、PaaS、SaaS 三层。基础层的配置是操作系统的配置，
                                 中间平台层的配置是中间件的配置(Tomcat 的配置), 上层软件层的配置是应用自己的配置。
    
    3. 配置中心的模型
            (1) 每个配置项就是 key/value 的模型
            (2) 操作系统层和平台层的配置项由专门的运维人员或架构师来配置。其中的 value 应该是选项，而不是让用户可以自由输入的，
                最好是有相关的模板来初始化全套的配置参数
                
    4. 配置中心的架构
            (1) 流程图
                
                                        <----配置读取　　　　　　　　　　　　　　　服务应用配置变更
                    配置录入---->配置中心------------------配置变更控制器----->　 平台层配置变更
                                        变更通知------>                        操作系统配置变更
                                        
                    a. 为什么需要一个变更通知的组件，而不是让配置中心直接推送？
                            原因是分布式环境下，服务器太多，推送不太现实，而采用一个 Pub/Sub 的通知服务可以让数据交换经济一些。
                    b. 为什么不直接 Pub 数据过去，还要订阅方(配置变更控制器)反向拉数据？
                            让程序用 API 读配置的好处是 
                                    1.通过 API 可以校验请求者的权限
                                    2.有时候还是需要调用配置中心的基本 API，比如下载最新的证书之类的
                                    3.服务启动时需要从服务中心拉一份配置下来。
                    c. 配置变更控制器部署在哪里？
                            变更配置有很多步骤,这些步骤算是一个事务。为了执行效率更好，事务成功率更大，建议把这个配置变更的控制
                            放在每一台主机上
                    d. 操作系统的配置变更和平台层的配置变更最好模块化，就像云服务中的不同尺寸的主机型号一样,
                       这样有利于维护和减少配置的复杂性
                    e. 应用服务配置更新的标准化。因为一个公司的应用由不同的团队完成，可能其配置会因为应用的属性不同而不一样。
                       为了便于管理，最好有统一的配置更新.方案如下:
                            I. 可以通过一个开发框架或 SDK 的方式来解决，提供配置变更的 Admin 的 API。
                            　  这种方式的好处在于在开发期标准化，并可以规范开发；不好的是，耦合语言。
                            II. 通过一个标准应用运维脚本，让应用方自己来提供应用变更时的脚本动作。
                                    好处：　通过运维的方式　标准化　配置变更的接口，不耦合语言，灵活
                                    坏处: 不太容易标准化，而且使用或者调用脚本是存在 Bug , 容易出问题。
                            III. 结合上述两种方案，不使用开发阶段的 SDK 方式嵌入到应用服务中，而是为每个应用服务单独做一个 Agent。
                                 这个 Agent 对外以 Admin API 的方式服务，后面则适配应用的配置变更手段，如更新配置文件，
                                 或者调用应用的 API 等。这种方式在落地方面是很不错的
                                 
    5. 配置中心设计
            (1) 使用模块可以简化相应的配置
            (2) 配置更新时是一个事务处理，需要考虑事务的问题，如果变更不能继续，需要回滚到上个版本的配置。
            　　配置版本最好和软件版本对应上。
            (3) 配置更新控制器，需要应用服务的配合，比如，配置的 reload，服务的优雅重启，服务的 Admin API，
                或是通过环境变量……这些最好是由一个统一的开发框架搞定。
            (4) 配置更新控制器还担任服务启动的责任，由配置更新控制器来启动服务
            
    6. 传统单机软件的配置通常保存在文件中，但在分布式系统下，为了管理方便，必须有一个配置中心,
       配置中心主要的用处是统一和规范化管理所有的服务配置
```

### 管理设计之"边车模式"(Sidecar)

```shell
    1. 边车就有点像一个服务的 Agent，这个服务所有对外的进出通讯都通过这个 Agent 来完成,我们就可以在这个 Agent 上进行相关的操作。
    　　这个 Agent 要和应用程序一起创建，一起停用
    2. 编程的本质就是将控制和逻辑分离和解耦，而边车模式同样是在分布式架构中做到逻辑和控制分离
    3.  "监视、日志、限流、熔断、服务注册、协议转换……" 这些功能模块，可以做成标准化的组件和模块的。有两种方式
            a. 第一种通过 SDK、Lib 方式，在开发时与真实的应用服务集成起来。
                    优点: 和应用密切集成，有利于资源的利用和应用的性能
                    缺点: 对应用有侵入，而且受应用的编程语言和技术限制。当软件包升级的时候，需要重新编译并重新发布应用。
            b. 第二种通过像 Sidecar 这样的方式，在运维时与真实的应用服务集成起来。
                    优点: 对应用服务没有侵入性，并且不受应用服务的语言和技术的限制，而且可以做到控制和逻辑的分开升级和部署
                    缺点: 增加每个应用服务的依赖性，也增加应用的延迟，并且也会大大增加管理、托管、部署的复杂度。
    4. Sidecar 服务在逻辑上和应用服务部署在一个结点上，和应用服务有相同的生命周期。应用程序的每个实例，都会有一个 Sidecar 的实例。
    　 Sidecar 很容易为应用服务进行扩展，而不需要对应用服务的改造,这样应用服务则可以完全做到专注于业务逻辑。比如：
            (1) Sidecar 可以帮助服务注册到相应的服务发现系统，并对服务做健康检查。如果服务不健康，
                可以从服务发现系统中把服务实例移除掉。
            (2) 当应用服务要调用外部服务时， Sidecar 可以帮助从服务发现中找到相应外部服务的地址，然后做服务路由。
            (3) Sidecar 接管进出流量，可以在 Sidecar 里实现日志监视、调用链跟踪、流控熔断……
            (4) 服务控制系统可以通过控制 Sidecar 来控制应用服务，如流控、下线等。
    5. 如果把 Sidecar 这个实例和应用服务部署在同一台机器中,，最好是与 Docker 容器的方式一起使用.
    6. 熔断、路由、服务发现、计量、流控、监视、重试、幂等、鉴权等控制面上的功能，以及其相关的配置更新，和服务的关系并不大。
       但是传统的工程做法是在开发层面完成这些功能，这就会导致各种维护上的问题，而且还会受到特定语言和编程框架的约束和限制。
       而随着系统架构的复杂化和扩张，我们需要更统一地管理和控制这些控制面上的功能，需要通过 Sidecar 模式(边车模式)来架构我们的系统.
       用 Docker 来打包边车和服务
     
    7. 边车模式工程实现设计
            (1) 进程间通讯机制是这个设计模式的重点(Sidecar 服务与应用服务之间的通信)，不要使用任何对应用服务有侵入的方式，比如，
            　　通过信号的方式，或是通过共享内存的方式。最好的方式就是网络远程调用的方式（HTTP 进行通信）
            (2) 服务协议方面,尽量使用统一标准．这里有两层协议，一个是 Sidecar 到 service(应用服务) 的内部协议，
            　　另一个是 Sidecar 到远端服务 的外部协议(对外)。对于内部协议，需要尽量靠近和兼容本地 service 的协议；
                对于外部协议，需要尽量使用更开放更标准的协议。但无论是哪种，都不应该使用与语言相关的协议。
            (3) Sidecar 中所实现的功能应该是控制面上，而不是业务逻辑层面，尽量不要把业务逻辑设计到 Sidecar 
            
    8.  Sidecar 适用场景
            (1) 对老应用系统的改造和扩展。
            (2) 对多种语言混合出来的分布式服务系统进行管理和扩展。
            (3) 其中的应用服务由不同的供应商提供。
            (4) 控制和逻辑分离，标准化控制面上的动作和技术，从而提高系统整体的稳定性和可用性
            
    9. Sidecar 不适用场景
            (1) 架构并不复杂的时候，不需要使用这个模式，直接使用 API Gateway 或者 Nginx 和 HAProxy
            (2) 服务间的协议不标准且无法转换。
            (3) 不需要分布式的架构
```

### 管理设计之"服务网格"(Service Mesh)

```shell
    1.Service Mesh 的特点
            a. Service Mesh 是一个基础设施。
            b. Service Mesh 是一个轻量的服务通讯的网络代理。
            c. Service Mesh 对于应用服务来说是透明无侵入的。
            d. Service Mesh 用于解耦和分离分布式系统架构中控制层面上的东西。
            
    2. Service Mesh　的发展过程
            第一: 一开始是最原始的两台主机间的进程直接通信。
            第二: 然后分离出网络层来，服务间的远程通信，通过底层的网络模型完成。
            第三: 再后来，因为两边的服务在接收的速度上不一致，所以需要应用层中实现流控。
            第四: 后来发现，流控模块基本可以交给网络层实现，于是 TCP/IP 就成了世界上最成功的网络协议。
            第五: 再往后面，我们知道了分布式系统中的 8 个谬论 The 8 Fallacies of Distributed Computing ，
                 意识到需要在分布式系统中有 " 弹力设计 "。我们在更上层中加入了像限流、熔断、服务发现、监控等功能。
            第六: 我们发现这些弹力设计的模式都是可以标准化的。将这些模式写成 SDK/Lib/Framework，
                  这样就可以在开发层面上很容易地集成到我们的应用服务中。
            第七: SDK、Lib、Framework 不能跨编程语言。有什么改动后，要重新编译重新发布服务，不方便。
                应该有一个专门的层来干这事，于是出现了 Sidecar。
            第八: Sidecar 集群就成了 Service Mesh,加上对整个集群的管理控制面板，就成了我们整个的 Service Mesh 架构
            
    3. Service Mesh 相关的开源软件
            (1) Service Mesh 开源软件:  lstio 和 Conduit
            (2) lstio 是目前最主流的解决方案，其核心的 Sidecar 被叫做 Envoy（使者），用来协调服务网格中所有服务的出入站流量，
                并提供服务发现、负载均衡、限流熔断等能力，还可以收集大量与流量相关的性能指标。
                在 Service Mesh 控制面上，有一个叫 Mixer 的收集器，用来从 Envoy 收集相关的被监控到的流量特征和性能指标。
                通过 Pilot 的控制器将相关的规则发送到 Envoy 中，让 Envoy 应用新的规则。
                最后，还有一个为安全设计的 lstio-Auth 身份认证组件，用来做服务间的访问安全控制。
               
```

### 管理设计之"网关模式"(Gateway)

```shell
    1. 基于边车模式和服务网格让运维成本变得大，因为每个服务都需要一个 Sidecar，这让本来就复杂的分布式系统的架构就更为复杂和难以管理
       解决的方案是使用 Gateway, 并不需要为每个服务的实例都配置上一个 Sidecar。一个服务集群(服务集群里面是相同的集群)配上一个 
       Gateway 就可以了，或是一组类似的服务配置上一个 Gateway
       
    2. Gateway 是一个服务器，是进入系统的唯一节点。Gateway 封装内部系统的架构，并且提供 API 给各个客户端。
       它还可能有其他功能，如授权、监控、负载均衡、缓存、熔断、降级、限流、请求分片和管理、静态响应处理，等等。
       
    3. 网关的功能
            (1) 请求路由.
                    因为不再是 Sidecar ，网关必需要有请求路由的功能。对于调用端不需要知道用到的服务的地址，全部统一是 Gateway 的地址
                    只要交给 Gateway 来处理就行
            (2) 服务注册
                    Gateway 可以根据接收到的请求中的信息来决定路由到哪一个后端的服务上.这就需要网关具备服务注册的功能，例如：
                    HTTP 的 Restful 请求，可以注册相应的 API 的 URI、方法、HTTP 头中
            (3) 负载均衡
                    一个网关可以接多个服务实例，需要对这些服务实例进行负载均衡。有
                     round robin 轮询，根据权重进行分发， session 粘连
            (4) 弹力设计
                    网关可以把弹力设计中的异步、重试、熔断、幂等、流控、监视等都可以实现进去。像 Service Mesh 那样，
                    让应用服务只关心自己的业务逻辑而不是控制逻辑
            (5) 安全方面
                    SSL 加密及证书管理、Session 验证、授权、数据校验，以及对请求源进行恶意攻击的防范。
                    网关可以做到全站的接入来对后端的服务进行保护。
            
            
            (6) 灰度发布
                    网关可以做到对相同服务不同版本的实例进行导流，并收集相关的数据。
                    这样对软件质量的提升，产品试错都有作用
            (7) API 聚合
                    使用网关可将多个单独请求聚合成一个请求。在微服务体系的架构中，因为服务变小了，所以一个明显的问题是，
                    客户端可能需要多次请求才能得到所有的数据。客户端与后端之间的频繁通信会对应用程序的性能和规模产生非常不利的影响。
                    可以让网关来帮客户端请求多个后端的服务（有些场景下完全可以并发请求），然后把后端服务的响应结果拼装起来，
                    回传给客户端（当然，这个过程也可以做成异步的，但这需要客户端的配合）
            (8) API 编排
                    在微服务的架构下，要走完一个完整的业务流程，我们需要调用一系列 API，就像一种工作流一样，这个事完全可以通过网关
                    来编排这个业务流程。通过一个 DSL 来定义和编排不同的 API，也可以通过像 AWS Lambda 服务那样的方式来
                    串联不同的 API。
                
    4. Gateway、Sidecar 和 Service Mesh 区别
           (1) Sidecar 的方式主要是用来改造已有服务进行架构变更，通过 Sidecar 的方式，可以适配应用服务，成为应用服务进出请求的代理．
           (2) 当 Sidecar 在架构中越来越多时，需要对 Sidecar 进行统一的管理。为 Sidecar 增加一个全局的中心控制器(Service Mesh)
               在中心控制器(Service Mesh)出现后，可以把非业务功能全部实现在 Sidecar 和 Controller 中，就成了一个网格。
               业务方只需要把服务往这个网格中一放就好了，与其它服务的通讯、服务的弹力等都不用管，像一个服务的 PaaS 平台。
           (3) Service Mesh 的架构和部署太过于复杂，会让我们运维层面上的复杂度变大,Gateway 只负责进入的请求，
              不像 Sidecar 还需要负责对外的请求。服务对外的请求可以交给对方服务的 Gateway。
              我们只需要用一个只负责进入请求的 Gateway 来简化需要同时负责进出请求的 Sidecar 的复杂度。
              
    5. 网关设计
           (1) 高性能, 可以使用 C、C++、Go 和 Java
           (2) 高可用
                    a. 集群化。 自己组成一个集群，并可以自己同步集群数据，而不需要依赖于一个第三方系统来同步数据。
                    b. 服务化。 在不重启动态修改配置，一种是像 Nginx reload 配置那样，可以做到不停服务，
                               另一种是最好做到服务化,要有自己的 Admin API 在运行时修改自己的配置。
                    c. 持续化。比如重启，像 Nginx 优雅地重启。有一个负责请求分发的主进程。当我们需要重启时，
                    　　　　　　新的请求被分配到新的进程中，而老的进程处理完正在处理的请求后就退出。
           (3) 高扩展。因为网关需要承接所有的业务流量和请求，所以一定会有或多或少的业务逻辑。
                      业务逻辑是多变和不确定的。例如，需要在网关上加上一些和业务相关的东西，所以，
                      一个好的 Gateway 还需要是可以扩展的，并能进行二次开发的。
                      像 Nginx 那样通过 Module 进行二次开发的固然可以。但我还是觉得应该做成像 AWS Lambda 那样的方式，
                      也就是所谓的 Serverless 或 FaaS（Function as a Service）那样的方式。
           (4) 运维方面
                    a. 业务松耦合.
                                在业务设计上，网关不应与后面的服务之间形成服务耦合，也不应该有业务逻辑。
                                网关应该是网络应用层上的组件，不应该处理通讯协议体，只应该解析和处理通讯协议头。
                                除了服务发现外，网关不应该有第三方服务的依赖。
                    b. 应用监视，提供分析数据。
                                网关上需要对应用性能的监控，有相应后端服务的高可用的统计，还需要使用 Tracing ID 实施分布式链路跟踪，
                                并统计好一定时间内每个 API 的吞吐量、响应时间和返回码，以便启动弹力设计中的相应策略。
                    c. 用弹力设计保护后端服务
                                网关一定要实现重试、熔断、限流和超时等弹力设计。如果一个或多个服务调用花费的时间过长，
                                那么可接受超时并返回一部分数据，或是返回一个网关里的缓存的上一次成功请求的数据
                    d. DevOps
                                因为网关这个组件太关键了，所以需要 DevOps，将其发生故障的概率降到最低。
                                需要经过精良的测试，包括功能和性能的测试，还有浸泡测试。还需要有一系列自动化运维的管控工具。
           (5) 架构方面
                    a. 不要在网关代码里内置聚合后端服务的功能，而是将聚合服务放在网关核心代码之外。
                    　　可以使用 Plugin 的方式，也可以放在网关后面形成一个 Serverless 服务。
                    b. 网关应该靠近后端服务，并和后端服务使用同一个内网，保证网关和后端服务调用的低延迟，并可以减少网络问题
                    c. 网关自己需要容量扩展，需要成为一个集群(网关集群)来分担前端带来的流量。实现对网关的负载均衡，可以
                    　　通过 DNS 轮询，可以通过 CDN 来做流量调度，可以通过底层的性能更高的负载均衡设备。
                    d. 为网关考虑 bulkhead 设计方式。用不同的网关服务不同的后端服务
           (6) 安全方面
                    a. 加密数据。可以把 SSL 相关的证书放到网关上，由网关做统一的 SSL 传输管理。
                    b. 校验用户的请求。一些基本的用户验证可以放在网关上来做，比如用户是否已登录，用户请求中的 token 是否合法等。
                                     但是，我们需要权衡一下，网关是否需要校验用户的输入。因为这样，网关就需要从只关心协议头，
                                     到还需要关心协议体。而协议体中的东西一方面不像协议头是标准的，
                                     另一方面解析协议体还要耗费大量的运行时间，从而降低网关的性能。
                       　　　　　　　　所以看具体需求，如果协议体是标准的，那么可以干；
                       　　　　　　　　如果对于解析协议所带来的性能问题，需要做相应的隔离。
                    c. 检测异常访问。网关需要检测一些异常访问，比如，在一段比较短的时间内请求次数超过一定数值；
                       　　　　　　　同一客户端的 4xx 请求出错率太高……对于这样的一些请求访问，网关一方面要把这样的请求屏蔽掉，
                       　　　　　　　另一方面需要发出警告，有可能会是一些比较重大的安全问题，如被黑客攻击
                    
```

### 管理设计之"部署升级策略"

```shell
    1. 服务部署模式
        (1) 停机部署（Big Bang / Recreate）： 把现有版本的服务停机，然后部署新的版本。
        (2) 蓝绿部署（Blue/Green /Stage）：部署好新版本后，把流量从老服务那边切过来。
        (3) 滚动部署（Rolling Update / Ramped）： 一点一点地升级现有的服务。
        (4) 灰度部署（Canary）：把一部分用户切到新版上来，然后看一下有没有问题。如果没有问题就继续扩大升级，
                              直到全部升级完成。
        (5) AB 测试（A/B Testing）：同时上线两个版本，然后做相关的比较。
        
    2. 停机部署
            (1) 在一些时候，我们必需使用这样的方式来部署或升级多个服务。比如，新版本中的服务使用到了和老版本完全不兼容的数据表的设计。
                这个时候，我们对生产环境有两个变更，一个是数据库，另一个是服务，而且新老版本互不兼容，只能使用停机部署的方式。
            (2) 优势
                    在部署过程中不会出现新老版本同时在线的情况，所有状态完全一致。停机部署主要是为了新版本的一致性问题。
            (3) 劣势
                    对用户的影响会很大。这种部署方式需要事前挂公告，选择一个用户访问少的时间段来做。
                    
    3. 蓝绿部署
            (1) 蓝绿部署与停机部署最大的不同是，在生产线上部署相同数量的新的服务，然后当新的服务测试确认 OK 后，
                把流量切到新的服务这边来, 其不需要停机．
                这种部署方式就是预发环境。例如生产线上有两套相同的集群，一套是 Prod(真实服务)，另一套是 Stage(预发环境)，
                发布发到 Stage，确认正常运行后，然后把流量切到 Stage 这边，于是 Stage 就成了 Prod，
                而之前的 Prod 则成了 Stage
            (2) 优势
                    没有停机，实时发布和升级，也避免有新旧版本同时在线的问题
            (3) 劣势
                    需要两份相同的资源，比较浪费
                    
    4. 滚动部署
            (1) 滚动部署策略是指通过逐个替换服务的所有实例，来缓慢发布应用的一个新版本。通常过程如下：
            　　　在负载调度后有个版本 A 的应用实例池，一个版本 B 的实例部署成功，可以响应请求时，该实例被加入到池中。
            　　　然后，版本 A 的一个实例从池中删除并下线。
            (2) 劣势
                    a. 在发布过程中，会出现新老两个版本同时在线的情况，同一用户的请求可能在新老版中切换而导致问题。
                    b. 新版程序没有在生产线上经过验证就上线。
                    c. 在整个过程中，生产环境处于一个新老更替的中间状态，如果有问题要回滚就比较麻烦
                    d. 如果在升级过程中，需要做别的一些运维工作，我们还要判断哪些结点是老版本的，哪些结点是新版本的。
                       这导致运维负载困难
                    e.新老版本的代码同时在线，所以其依赖的服务需要同时处理两个版本的请求，这可能会带来兼容性问题。
                    f. 无法控制让流量在新老版本中切换。
    5. 灰度部署
            (1) 灰度部署又叫金丝雀部署.灰度部署是逐渐将生产环境流量从老版本切换到新版本。流量是按比例分配的。例如 90% 的请求流向老版本，
                 10% 的流向新版本,发现没有问题，逐步扩大新版本上的流量，减少老版本上的流量。
                 
            (2) 除了切流量外，对于多租户的平台，例如云计算平台，灰度部署也可以将一些新的版本先部署到一些用户上，如果没有问题，扩大部署，
                直到全部用户。一般的策略是，从内部用户开始，然后是一般用户，最后是大客户。
            (3) 大多数用于缺少足够测试，或者缺少可靠测试，或者对新版本的稳定性缺乏信心的情况下。
                
    6. AB 测试
            (1) AB 测试是同时上线两个版本，然后做相关的比较。是用来测试应用功能表现的方法，例如可用性、受欢迎程度、可见性等。
               蓝绿部署是为了不停机，灰度部署是对新版本的质量没信心。而 AB 测试是对新版的功能没信心。
               一个是质量(灰度部署)，一个是功能(AB 测试)。
               
               比如，网站 UI 大改版，推荐算法的更新，流程的改变，我们不知道新的版本否会得到用户青睐或是能得到更好的用户体验，
               我们需要收集一定的用户数据才能知道。
               
    7. 总结
            (1) 当发布到开发或者模拟环境时，停机或者滚动部署是一个好选择，因为干净和快速
            (2) 当发布到生产环境时，滚动部署或者蓝绿部署通常是一个好选择，但新平台的主流程测试是必须的。
                蓝绿部署也不错，但需要额外的资源。
                如果应用缺乏测试或者对软件的功能和稳定性影响缺乏信心，那么可以使用金丝雀部署(灰度部署)或者 AB 测试发布。
                如果业务需要根据地理位置、语言、操作系统或者浏览器特征等参数来给一些特定的用户测试，那么可以采用 AB 测试技术。
 
```

### 性能设计之"缓存"

```shell
    1. 缓存的重要性，为了提高响应速度，缓解后端数据库的查询压力．
    2. Cache Aside 更新模式(常用的设计模式)
            失效：应用程序先从 cache 取数据，没有得到，则从数据库中取数据，成功后，放到缓存中。
            命中：应用程序从 cache 中取数据，取到后返回。
            更新：先把数据存到数据库中，成功后，再让缓存失效。 成功后不更新缓冲数据，而是让它失效，因为怕两个并发的写操作导致脏数据
            
            (1) Cache Aside 更新模式也会存在脏数据
                    例如：一个是读操作，但是没有命中缓存，向数据库取数据。而此时一个写操作，
            　　　　　　　　写完数据库后，让缓存失效，在缓存失效后此时另一个线程中之前的那个读操作把老的数据放进去，
            　　　　　　　　这时会造成脏数据.但这种概率极低．
            (2) 最好为缓存设置好过期时间
            (3) 应用程序需要维护两个数据存储，一个是缓存（cache），一个是数据库（repository）
            
    3. Read/Write Through 更新模式
            (1) Read/Write Through 把更新数据库（repository）的操作由缓存自己代理，
                对于应用层来说后端就是一个单一的存储，而存储自己维护自己的 Cache。
            (2) Read Through
                    当缓存失效的时候(过期或 LRU 换出),Cache Aside 是由调用方负责把数据加载入缓存，
                    而 Read Through 则用缓存服务自己来加载，从而对应用方是透明的。
            (3) Write Through
                    当有数据更新时，如果没有命中缓存，直接更新数据库，然后返回。如果命中了缓存，则更新缓存，
                    然后由 Cache 自己更新数据库（这是一个同步操作）
                    
    4. Write Behind Caching 更新模式
            (1) 在更新数据的时候，只更新缓存，不更新数据库，而我们的缓存会异步地批量更新数据库。
                好处:
                    让数据的 I/O 操作速度变快(因为直接操作内存嘛)。因为异步，Write Back 还可以合并对同一个数据的多次操作,
                    有利于性能的提高
                坏处:
                    数据不是强一致性的，而且可能会丢失(由于程序异常退出，导致无法及时更新到数据库中)
                    Write Back 实现逻辑比较复杂，因为它需要 了解到有哪些数据是被更新了的，需要更新到磁盘中。
                    操作系统的 Write Back 会在仅当这个 cache 需要失效的时候(内存不够，或是进程退出了等情况)，
                    才会把它真正持久化。叫 lazy write。
                    
    5. 
        (1) 用 Redis 来搭建缓存系统, 
                第一： Redis 的数据结构比较丰富。
                第二：我们不能在 Service(服务)内放 local cache(自定义的缓存)，
                             一是每台机器的内存不够大，
                　　　　　　　 二是我们的 Service 有多个实例，负载均衡器会把请求随机分布到不同的实例。那么缓存需要在所有的
                 　　　　　　　　Service 实例上都建好，这让我们的 Service 有状态，更难管理             
        (2). 在分布式架构下，需要一个外部的缓存集群。需要保证的这个缓冲集群内存足够大，网络带宽要好，
    　　      因为缓存本质上是个内存和 IO 密集型的应用
        (3) 缓存的好坏要看命中率。缓存的命中率高说明缓存有效
        (4) 缓存是通过牺牲强一致性来提高性能的,使用缓存提高性能，就是导致数据更新的延迟
        (5) 使用缓存的时候，一般会使用 LRU 策略。当内存不够时需要有数据被清出内存，会找最不活跃的数据(长时间没有被访问过)清除。
            开启 LRU 策略会使用每个数据在访问的时候调到前面，而从最后面开始淘汰数据
                    
```

### 性能设计之"异步处理"

```shell
    1. 异步通讯讲的是怎么把系统连接起来,异步处理重点在处理
    2. 异步处理流程
            需要一个前台系统，把用户发来的请求记录下来(如果需要保存到数据库只会有追加的操作，性能高)，收到请求后，
            给客户端返回 " 收到请求，正在处理中 "，为了解耦，需要一个任务派发器，将请求分派给任务处理系统．其中
            任务派发器分发任务有两种模式，
                第一：Push 模型，把任务派发给相应的功能去处理，它需要知道下游工作结点的情况，
                               除了要知道哪些是活着的，还要知道它们的忙闲程度。并且当下游工作结点扩容缩容或是有故障需要维护
                               等一些情况发生时， Push 结点都需要知道，会增加一定的系统复杂度
                第二: Pull 模型，处理程序从任务派发器取请求，可以让上游结点不用关心下游结点的状态，只要自己忙得过来，就会来拿任务处理，
                　　　　　　　　　这样减少一定的复杂度，但是少了整体任务调度。
                
            实际任务派发器可以将Push 模型　和　Pull 模型相结合，采用订阅的模式，任务派发器可以先将请求进行整合，之后再发布，而处理端
            只需要订阅该主题就行了
    3. 事件溯源(Event Sourcing)
            通过记录一系列事件操作，从而能够推出最终的数据状态． 
            事件不会直接更新数据存储，只会对事件进行记录，以便在合适的时间进行处理
            
    4. 异步处理的设计要点(需要考虑到问题)
            (1) 异步处理可能会因为网络原因导致请求方没有收到回复，所以异步处理完后需要给请求方一个响应
            (2) 发起方在没收到回复后需要重新请求(当然该处理服务符合幂等性)
            (3) 异步处理的整体业务事务还需要考虑补偿性事务
      
   5. 异步处理系统的本质是把被动的任务处理变成主动的任务处理，是在对任务进行调度和统筹管理
   6. 异步处理的事务一致性一般不是强一致性，而是最终一致性
   
```

### 性能设计之"数据库扩展"

```shell
    1.读写分离 
        (1) 适用于读多写少的业务场景, 减少读操作的压力
        (2) 优势
                a. 容易实现。数据库的 master-slave 的配置和服务框架读写分离都比较成熟，开发快。
                b. 通过多个读库将各个业务隔离。不会因为一个业务把数据库拖死而导致所有的业务都死掉。
                c. 很好地分担数据库的读负载
        (3) 劣势
                a. 数据库同步不实时，某一时刻存在读库和写库数据不一致
                b. 需要强一致性的读写操作还是需要落在写库
                
    2. CQRS(Command and Query Responsibility Segregation):命令与查询职责分离
        (1) 用户对一个应用的操作有两种
                a. 第一种：Command 对应于写操作（增，删，改），主要用于业务逻辑，Command 会改变数据但不会返回结果数据，
                　　　　　　只会返回执行状态
                b. 第二种: Query 对应于读操作(查)，主要用于数据整合呈现, 查询 Query 会返回结果数据，不会改变数据
        (2) 好处
                a. 分工明确，可以负责不同的部分。
                b. 将业务上的命令和查询的职责分离，能够提高系统的性能、可扩展性和安全性。并且在系统的演化中能够保持高度的灵活性，
                   能够防止出现 CRUD 模式中，对查询或者修改中的某一方进行改动，导致另一方出现问题的情况。
                c. 逻辑清晰，能够看到系统中的哪些行为或者操作导致了系统的状态变化。
                d. 可以从数据驱动（Data-Driven）转到任务驱动（Task-Driven）以及事件驱动。
                
    3. 分库分表 Sharding
        (1) 影响数据库性能主要有两方面，第一：数据库的操作．　第二：数据库表的大小

        (3) 数据访问层。为了不让服务感知到数据库的变化，需要引入" 数据访问层 " 的中间件，用来做数据路由。其中要有解析 SQL 语句的能力，
                       还要根据解析好的 SQL 语句来做路由
        (4) 数据库分片必须考虑业务，从业务的角度入手，而不是从技术的角度入手
        (5) 只考虑业务分片,不要走哈希散列的分片方式
        
    4. 数据库扩展设计
        (1) 先服务化拆分，再分片
            数据库和应用服务一同拆开即一个服务一个库，微服务和 Amazon 的服务化都是用这个方法，服务之间只能通过服务接口通讯，
        　　 不能通过访问对方的数据库．在一个单体的库上做读写分离或是做分片是一件治标不治本的事，真正治本的方法就是要和服务一起拆解。
            数据库也服务化后，才会在这个小的服务数据库上进行读写分离或分片的方式来获得更多的性能和吞吐量。这是整个设计模式的原则——
          　先做服务化拆分，再做分片
        (2) 分片模式两种模式(我们所说的 sharding 更多的是说 水平分片)
                a. 水平分片
                     水平分片的策略,可以按照某种规则分库
                        a. 按多租户的方式。用租户 ID 来分，可以把租户隔离开来。如：一个电商平台的商家中心按商家的 ID 来分
                        b. 按数据的种类来分。如，一个电商平台的商品库可以按品种分，或是将商家按地域来分。
                        c. 通过范围来分。保证在同一分片中的数据是连续的，进行数据库操作(分页查询会更高效)。
                                       大多数情况是用时间来分片的，如，一个电商平台的订单中心是按月份来分表的，
                                       可以快速检索和统计一段连续的数据。
                        d. 通过哈希散列算法来分（比如：主键 id % 3 之类的算法）此策略的目的是降低形成热点的可能性
                           （接收不成比例的负载的分片）.会带来两个问题，一个是跨库跨表的查询和事务问题，
                           另一个就是要扩容需要应用层重新编写哈希部分引导到每个库
                b. 垂直分片
                        是计划把 A表中的一些字段放到 B 中，A表中另一些字段放到 C 表中。垂直分片主要是把一些经常修改的数据和
                        不经常修改的数据给分离开来，这样在修改某个字段的数据时，不会导致其它字段的数据被锁而影响性能。
                        比如，对于电商系统来说，商品的描述信息不常改，但是商品的库存和价格经常改，
                        可以把描述信息和库存价格分成两张表，这样可以让商品的描述信息的查询更快
        (3) 水平分片的注意事项
                a. 随着数据库中数据的变化，有可能需要定期重新平衡分片，以保证均匀分布并降低形成数据热点的可能性。 
                　　同时要注意不能频繁进行平衡分片，需要确保在未来的一段时间内每个分片包含足够的可用空间．
                　　还需要开发快速重新平衡分片的工具和脚本
                b. 数据分片后，很难在分片之间保持引用完整性和一致性，增加跨分片的事务的复杂度，
                　　尽量减少会影响多个分片中的数据的操作。如果应用程序必须跨分片修改数据，
                　　需要评估一致性以及评估是否采用两阶段提交的方式。
                c. 配置和管理大量分片可能是一个挑战。在做相应的变更时，一定要先从生产线上取出数据，然后根据数据规划新的分片方式，
                　　并做好测试工作。否则，会引发灾难性的问题。
``` 

### 性能设计之"秒杀"(Flash Sales)

```shell
    1.秒杀的流程
        (1) 从用户或是产品的角度
                第一: 你需要一个秒杀的 landing page(一个网页)，在这个秒杀页上有一个倒计时的按钮。
                第二: 一旦这个倒计时的时间到了，按钮就被点亮，让你可以点击按钮下单。
                第三: 下单时需要你填一个校验码，以防止机器来抢。
        (2) 技术上
                a. 每个电脑用户前端页面要不断地向后端来请求，开没开始，开没开始……
                b. 一旦后端服务器表示 OK 可以开始，后端服务会返回一个 URL。
                c. 这个 URL 会被安置在那个按钮上，就可以点击了。
                d. 点击后，如果抢到了库存，就进入支付页面，如果没有则返回秒杀已结束。
                
    2. 秒杀的技术挑战
            怎么应对这 100 万人同时下单请求？100 万同时并发会导致我们的网站瞬间就崩溃了，一方面是 100 万人同时请求，我们的网络带宽不够，
            另一方面是理论上来说要扛 100 万的 TPS，需要非常多的机器。所有的请求都会集中在同一条数据库记录上,
            无论是怎么分库分表，还热点数据都会集中在一条记录上。
            
    3. 秒杀的解决方案
            (1) 使用 CDN 
                    在 CDN 上，这 100 万个用户就会被几十个甚至上百个 CDN 的边缘结点给分担.
                    需要把服务部署到 CDN 结点上去，当前端页面来问开始了没，这个小服务除了告诉前端开没开始外，其可以做一下
                    有多少人在线的统计。每个部署在 CDN 上的服务会把当前在线等待秒杀的人数每隔一段时间就回传给我们的数据中心，
                    这样我们就知道全网总共在线的人数有多少．
                    在秒杀快要开始的时候，由数据中心向各个部署在 CDN 结点上的小服务上传递一个概率值，比如说是 0.02%。
                    当秒杀开始的时候，这 100 万用户都在点下单按钮时，首先请求到的是 CDN 上的这个小服务，
                    这个小服务按照 0.02% 的量把用户请求传递到后面的数据中心，也就是 1 万个人放过去两个，
                    剩下的 9998 个都直接返回秒杀已结束。
                    
    4. 像双 11 那样，想尽可能多地卖出商品，就不能像秒杀那样，我们要尽量满足客户的需求，需要做好高并发的架构和测试，
    　　需要各个系统把自己的性能调整上去，要小心地做性能规划，把分布式的弹力设计做好，要不断地做性能测试，找到整个架构的系统瓶颈，
    　　然后不断地做水平扩展，以解决大规模的并发
            
```

### 性能设计之"边缘计算"(Edge Computing)

```shell
    1.通过一个秒杀的示例，展示了在 CDN 结点上简单地部署个小服务，就可以完成在数据中心很难完成的事，可以看到边缘结点的威力。
    2. 数据中心，所有的服务放在一个机房里集中处理用户的数据和请求，集中式部署，第一便于管理和运维，
    　　第二因为部署在同一机房环境中，服务间的通讯不会有很大的网络问题．
    3. 边缘计算广泛应用的原因
            (1) 从趋势上来说
                    随着时间的推移数量越来越大，分析结果的速度需要越来越快，这两个需求，只会把我们逼到边缘计算上去。
                    如果你还是在数据中心处理，你会发现你的成本只会越来越高.例如，如果苹果手机的人脸识别需要到服务器上算，然后把结果返回，
                    那么用户的体验就很糟糕了。这就是为什么苹果在手机里直接植入了神经网络的芯片。
            (2) 从成本上来说
                    当需要处理的数据或是用户请求的规模越来越大时,数据中心的成本是不是线性增长，而是快速上升．
                    数据量变大，架构变复杂，就要做很多非功能的东西，比如，缓存、队列、服务发现、网关、自动化运维、监控等。
                    
                    对于数据中心而言：
                        上百万用户的公司，只需要处理千级 QPS 的量，需要有 50 台左右的服务器
                        上亿用户的公司，其需要处理百万级 QPS 的量，需要上万台的服务器。
                    
                    如果我们有办法将一个 10000 台服务器的数据中心拆分成 100 个 50 台服务器的小数据中心,那么成本下降得很快，
                    只不过，我们需要运维 100 个小数据中心。运维 100 个 50 台服务器的小数据中心的难度应该远远低于运维一个 
                    10000 台服务器的数据中心。有地域性的业务可以这么做(外卖、叫车、共享单车之类)
    4. 边缘计算的业务场景
            a. 处理一些实时响应的业务。它和用户靠得很近，所以其可以实时响应用户的一些本地请求，
               比如，某公司的人脸门禁系统、共享单车的开锁。
            b. 处理一些简单的业务逻辑。比如像秒杀、抢红包这样的业务场景。
            c. 收集并结构化数据。比如，把视频中的车牌信息抠出来，转成文字，传回数据中心。
            d. 实时设备监控。主要是线下设备的数据采集和监控。
            e. P2P 的一些去中心化的应用。比如：边缘结点作为一个服务发现的服务器，可以让本地设备之间进行 P2P 通讯。
            f. 云资源调度。边缘结点非常适合用来做云端服务的调度。比如，允许用户使用不同生产商的云存储服务，
                         使用不同生产商但是功能相同的 API 服务（比如支付 API 相关）。因为是流量接入方，所以可以调度流量。
            g. 云资源聚合。比如，我们可以把语音转文字的 API 和语义识别的 API 相结合，聚合出来一个识别语音语义的 API，
                          从而简化开发人员的开发成本。
    5. 边缘计算的关键技术
            a. API Gateway
            b. Serverless/FaaS。就是服务函数化，这个技术就像是 AWS Lambda 服务一样，你写好一个函数，
                               然后不用关心这个函数运行在哪里，直接发布就好了。然后就可以用了。
    6. 如果说微服务是以专注于单一责任与功能的小型功能块为基础，利用模块化的方式组合出复杂的大型应用程序，
       那么我们还可以进一步认为 Serverless 架构可以提供一种更加 " 代码碎片化 " 的软件架构范式，
       我们称之为 Function as a Services（FaaS）。所谓的 " 函数 "（Function）提供的是相比微服务更加细小的程序单元。
       
       流行的开源代码
                   Serverless Framework
                   Fission: Serverless Functions for Kubernetes
                   Open Lambda
                   Open FaaS
                   IronFunction
```