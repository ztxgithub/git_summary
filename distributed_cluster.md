# 分布式集群

## 集群

- 两大特性

``` shell

    1.可扩展性: 集群的性能是由多个相同服务实体构成的,新的服务实体可以动态地加入到集群,从而增强集群的性能
    2.高可用性: 集群通过服务实体冗余使客户端免于轻易遇到out of service的警告.即如果一台服务器崩溃了,可以切换到另外一台
                服务器,使得客户端的功能请求可以正常.
                	
```

- 两大能力

``` shell

    为了具有可扩展性和高可用性特点,集群的必须具备以下两大能力：
    
    1.负载均衡: 把任务比较均衡地分布到集群环境下的服务实体
    2.错误恢复: 由于某种原因,执行某个任务的资源出现故障,另一服务实体中执行同一任务的资源接着完成任务.
               这种由于一个实体中的资源不能工作，另一个实体中的资源透明的继续完成任务的过程叫错误恢复.
                	
```

- 两大技术

``` shell

   1.集群地址:客户端通过访问集群的集群地址获取集群内部各服务实体的功能.具有单一集群地址(也叫单一影像)是集群的一个基本特征.
             维护集群地址的设置被称为负载均衡器.负载均衡器内部负责管理各个服务实体的加入和退出,
             外部负责集群地址向内部服务实体地址的转换.
             
   2. 内部通信 : 为了能协同工作、实现负载均衡和错误恢复,集群各实体间必须时常通信,比如负载均衡器对服务实体心跳测试信息,
                服务实体间任务执行上下文信息的通信.
                
   具有同一个集群地址使得客户端能访问集群提供的计算服务,一个集群地址下隐藏了各个服务实体的内部地址,
   使得客户要求的计算服务能在各个服务实体之间分布.内部通信是集群能正常运转的基础,它使得集群具有均衡负载和错误恢复的能力.
                	
```

## 负载均衡

``` shell

     1.LB(Load Balance负载均衡器)
            LB负责分发设备的 MQTT连接与消息到 EMQ 集群,LB 提高 EMQ 集群可用性、实现负载平衡以及动态扩容.
            负载均衡器可以将来自多个公网地址的访问流量分发到多台主机上,并支持自动检测并隔离不可用的主机,
            从而提高业务的服务能力和可用性.你还可以随时通过添加或删减主机来调整你的服务能力,而且这些操作不会影响业务的正常访问.
            负载均衡器支持HTTP/HTTPS/TCP 三种监听模式,并支持透明代理,可以让后端主机不做任何更改就可以直接获取客户端真实IP.
            负载均衡器还支持灵活配置多种转发策略,实现高级的自定义转发控制功能.
            
            (1)均衡方式
                轮询：依据后端服务器的权重,将请求轮流发送给后端服务器,常用于短连接服务，例如 HTTP 等服务。
                
                最少连接：优先将请求发给拥有最少连接数的后端服务器,常用于长连接服务，例如数据库连接等服务。
                
                源地址：将请求的源地址进行hash运算,并结合后端的服务器的权重派发请求至某匹配的服务器,
                        这可以使得同一个客户端IP的请求始终被派发至某特定的服务器.该方式适合负载均衡无cookie功能的TCP协议.
                        
            (2)会话保持
            
                ip_hash实现tcp会话保持
                          
                会话保持可以将来自同一个客户端的请求始终发给同一个后端服务器,是通过 cookie 的方式来实现的.
                    植入cookie：由负载均衡器向客户端植入 cookie，这时你需要指定 cookie 的过期时间,不指定默认为不过期。
                    改写cookie：cookie 由你的后端业务来植入和管理,负载均衡器会通过改写该 cookie 的值来实现会话保持,
                                改写cookie对后端服务是透明的,不会影响后端服务的正常运行；
                                这时你需要指定需要改写的 cookie 名称.
                            
            (3)健康检查
                开启健康检测后,负载均衡器会根据你的配置定期检查后端服务的运行状态,当某个后端服务出现异常时,会自动隔离该后端服务,
                并将请求转发给其他健康的后端服务,实现高可用性。
            
                健康检查方式：
            
                    TCP：通过向后端服务器发送 TCP 包来检测后端服务
            
                    HTTP：通过向后端服务器发送HTTP请求来检测后端服务,你可以指定需要检测的URI.
                          负载均衡器会通过HTTP返回值是否为200来判断服务是否正常.
            
                健康检查选项：
            
                    检查间隔：连续两次健康检查之间的时间间隔，单位为秒，范围为 2 - 60s
            
                    超时时间：等待健康检查请求返回的超时时间，检查超时将会被判定为一次检查失败，单位为秒，范围为 5 - 300s
            
                    不健康阈值：多少次连续检查失败之后，可以将后端服务屏蔽，范围为 2 - 10次
            
                    健康阈值：多少次连续检查成功之后，可以将后端服务恢复，范围为 2 - 10次
                    
            (4)后端服务器权重
                当均衡方式为 “轮询” 时,你可以通过设置后端服务器的权重来让负载均衡器进行权重转发.权重的范围为 1 - 100,
                数值越大权重越高.
                
     2.四层、七层负载均衡
        四层就是基于IP+端口的负载均衡,七层就是基于URL等应用层信息的负载均衡,基于MAC地址的二层负载均衡和基于IP地址的三层负载均衡
        所谓的四到七层负载均衡,就是在对后台的服务器进行负载均衡时,依据四层的信息或七层的信息来决定怎么样转发流量.
        
        比如四层的负载均衡,就是通过发布三层的IP地址,然后加四层的端口号,来决定哪些流量需要做负载均衡,
        对需要处理的流量进行NAT处理(报文中目标IP地址进行修改(改为后端服务器IP)),转发至后台服务器,
        并记录下这个TCP或者UDP的流量是由哪台服务器处理的,后续这个连接的所有流量都同样转发到同一台服务器处理.
        此种Load Balance不理解应用协议（如HTTP/FTP/MySQL等等）.
        例子：LVS,F5
            Client->转发(修改报头目标地址+修改源地址根据需求)->server
        
        七层的负载均衡，就是在四层的基础上（没有四层是绝对不可能有七层的）,再考虑应用层的特征,
        比如同一个Web服务器的负载均衡,除了根据IP+80端口辨别是否需要处理的流量,还可根据七层的URL、浏览器类别、语言来决定
        是否要进行负载均衡.如果你的Web服务器分成两组,一组是中文语言的,一组是英文语言的,
        那么七层负载均衡就可以当用户来访问你的域名时,自动辨别用户语言,然后选择对应的语言服务器组进行负载均衡处理.
        Load Balancer能理解应用协议.例子： haproxy,MySQL Proxy.
        
        七层应用负载的好处,是使得整个网络更智能化.例如访问一个网站的用户流量,可以通过七层的方式,
        将对图片类的请求转发到特定的图片服务器并可以使用缓存技术,将对文字类的请求可以转发到特定的文字服务器并可以使用压缩技术.
        从技术原理上，这种方式可以对客户端的请求和服务器的响应进行任意意义上的修改,极大的提升了应用系统在网络层的灵活性.
        Nginx或者Apache上部署的功能可以前移到负载均衡设备上,例如客户请求中的Header重写,服务器响应中的关键字过滤或者内容插入等
        功能。
        另外一个常常被提到功能就是安全性.网络中最常见的SYN Flood攻击，即黑客控制众多源客户端,
        使用虚假IP地址对同一目标发送SYN攻击,通常这种攻击会大量发送SYN报文,耗尽服务器上的相关资源,
        以达到Denial of Service(DoS)的目的。从技术原理上也可以看出,四层模式下这些SYN攻击都会被转发到后端的服务器上；
        而七层模式下这些SYN攻击自然在负载均衡设备上就截止，不会影响后台服务器的正常运营.
        另外负载均衡设备可以在七层层面设定多种策略，过滤特定报文,例如SQL Injection等应用层面的特定攻击手段,
        从应用层面进一步提高系统整体安全.
        现在的7层负载均衡，主要还是着重于应用HTTP协议,所以其应用范围主要是众多的网站或者内部信息平台等基于B/S开发的系统。
         4层负载均衡则对应其他TCP应用，例如基于C/S开发的ERP等系统.
         
     3.负载均衡软件
        一种是通过硬件来进行,常见的硬件有比较昂贵的F5和Array等商用的负载均衡器,它的优点就是有专业的维护团队来对这些服务进行维护
        、缺点就是花销太大，所以对于规模较小的网络服务来说暂时还没有需要使用；
        另外一种就是类似于Nginx/LVS/HAProxy的基于 Linux的开源免费的负载均衡软件，这些都是通过软件级别来实现,
        所以费用非常低廉。
        
        目前关于网站架构一般比较合理流行的架构方案：Web前端采用Nginx/HAProxy+ Keepalived作负载均衡器；
        后端采用 MySQL数据库一主多从和读写分离,采用LVS+Keepalived的架构.
        
        Nginx的优点是：
            (1).工作在网络的7层之上,可以针对http应用做一些分流的策略,比如针对域名、目录结构,
            它的正则规则比HAProxy更为强大和灵活,这也是它目前广泛流行的主要原因之一,Nginx单凭这点可利用的场合就远多于LVS了.
            (2)Nginx对网络稳定性的依赖非常小，理论上能ping通就就能进行负载功能，这个也是它的优势之一；
                相反LVS对网络稳定性依赖比较大.
            (3)可以承担高负载压力且稳定,在硬件不差的情况下一般能支撑几万次的并发量,负载度比LVS相对小些.
            (4)Nginx可以通过端口检测到服务器内部的故障,比如根据服务器处理网页返回的状态码、超时等等,
                并且会把返回错误的请求重新提交到另一个节点,不过其中缺点就是不支持url来检测.
                比如用户正在上传一个文件，而处理该上传的节点刚好在上传过程中出现故障,Nginx会把上传切到另一台服务器重新处理，
                而LVS就直接断掉了
                
        Nginx的缺点是:
            (1)Nginx仅能支持http、https和Email协议,这样就在适用范围上面小些,这个是它的缺点.
            (2)对后端服务器的健康检查,只支持通过端口来检测,不支持通过url来检测.不支持Session的直接保持,但能通过ip_hash来解决.
            
        LVS的优点是:
            (1) 抗负载能力强、是工作在网络4层之上仅作分发之用,没有流量的产生,这个特点也决定了它在负载均衡软件里的性能最强的,
                对内存和cpu资源消耗比较低
            (2) 工作稳定,因为其本身抗负载能力很强,自身有完整的双机热备方案，如LVS+Keepalived.
            (3) 无流量,LVS只分发请求,而流量并不从它本身出去,这点保证了均衡器IO的性能不会受到大流量的影响
            (4) 应用范围比较广，因为LVS工作在4层，所以它几乎可以对所有应用做负载均衡，包括http、数据库、在线聊天室等等
            
        LVS的缺点是：
            (1) 软件本身不支持正则表达式处理,不能做动静分离；而现在许多网站在这方面都有较强的需求,
                这个是Nginx/HAProxy+Keepalived的优势所在.
            (2) 如果是网站应用比较庞大的话,LVS/DR+Keepalived实施起来就比较复杂了,
                特别后面有 Windows Server的机器的话,如果实施及配置还有维护过程就比较复杂了,
                Nginx/HAProxy+Keepalived就简单多了.
                
        HAProxy的特点是：
            (1) HAProxy的优点能够补充Nginx的一些缺点,比如支持Session的保持,Cookie的引导；
                同时支持通过获取指定的url来检测后端服务器的状态
            (2) HAProxy支持TCP协议的负载均衡转发,可以对MySQL读进行负载均衡,对后端的MySQL节点进行检测和负载均衡，
                大家可以用LVS+Keepalived对MySQL主从做负载均衡
                
            (3)HAProxy负载均衡策略非常多，HAProxy的负载均衡算法现在具体有如下8种：
               ① roundrobin，表示简单的轮询，这个不多说，这个是负载均衡基本都具备的；
               ② static-rr，表示根据权重，建议关注；
               ③ leastconn，表示最少连接者先处理，建议关注；
               ④ source，表示根据请求源IP，这个跟Nginx的IP_hash机制类似，我们用其作为解决session问题的一种方法，建议关注；
               ⑤ ri，表示根据请求的URI；
               ⑥ rl_param，表示根据请求的URl参数’balance url_param’ requires an URL parameter name；
               ⑦ hdr(name)，表示根据HTTP请求头来锁定每一次HTTP请求；
               ⑧ rdp-cookie(name)，表示根据据cookie(name)来锁定并哈希每一次TCP请求.
               
               
        对网络负载均衡的使用是随着网站规模的提升使用不同的技术：
            第一阶段：利用Nginx或HAProxy进行单点的负载均衡,这一阶段服务器规模刚脱离开单服务器、单数据库的模式,
                    需要一定的负载均衡,但是仍然规模较小没有专业的维护团队来进行维护,也没有需要进行大规模的网站部署.
                    这样利用Nginx或HAproxy就是第一选择,此时这些东西上手快,配置容易,在七层之上利用HTTP协议就可以.
                    
            第二阶段：随着网络服务进一步扩大,这时单点的Nginx已经不能满足,这时使用LVS或者商用Array就是首要选择,
                    Nginx此时就作为LVS或者Array的节点来使用,具体LVS或Array的是选择是根据公司规模和预算来选择,
                    Array的应用交付功能非常强大,但是一般来说这阶段相关人才跟不上业务的提升,
                    所以购买商业负载均衡已经成为了必经之路.
                    
            第三阶段：这时网络服务已经成为主流产品,此时随着公司知名度也进一步扩展，相关人才的能力以及数量也随之提升,
                    这时无论从开发适合自身产品的定制,以及降低成本来讲开源的LVS,已经成为首选，这时LVS会成为主流.
                    
        最终形成比较理想的基本架构为：Array/LVS — Nginx/Haproxy — Squid/Varnish — AppServer.
                     	
```

## 反向代理

``` shell

   1.反向代理：工作在反向代理模式下的负载均衡设备,则是外网用户通过代理设备访问内网
                
   2.正向代理:普通的代理设备是内网用户通过代理设备出外网进行访问,
                	
```

## 分布式系统工程实践

```shell
    1.分布式系统的本质困难是 partial failure, 分布式系统不是放大的单机系统,根本原因是单机没有部分故障(partial failure)
      对应单机我们能轻易判断某个进程或则硬件是否还在正常运行.当在分布式系统中,我们无法得知另外一台机器是网络故障还是程序故障. 
      而且在分布式中事件的顺序性也没法保证,比如一台机器先发出消息,但由于网络原因不一定先收到
      
    2. 基于客户端视角的负载均衡策略
            这里站在客户端的角度思考,判断各个服务器端的负载情况可以根据该客户端向各个服务端请求时未收到响应的个数,即
            未收到响应的个数越少则代表该服务器负载小.
            
            实现思路: 客户端维护一个队列,该队列保存该客户端向各个服务器请求消息时未响应的个数,当要发送请求时,从
                     上次调用服务端的下一个位置进行遍历判断,选择负载最轻的服务器(即请求消息时未响应的个数最少)
                     
            在多客户端的情况下,防止潮涌(多个客户端一起向相同的服务端请求),刚开始访问服务器下标可以根据 ip 地址, MAC地址,
            时间等产生随机数种子
            
    3. 分布式系统的可靠性
            高可用的关键不在于不停机,而在于随时能够重启服务
            (1) 不要使用跨进程的 mutex 或则 semaphore, 也不要使用共享内存，因为进程意外终止，无法清理资源，
            　　　特别是无法解锁．也不要使用父子进程共享文件描述符通信(pipe)
            
            (2) 优雅的重启
                    A. 先主动停止一个服务进程的心跳：
                            对于短链接，关闭 listen port, 不会有新的请求到达
                            对于长连接，客户端会主动 failover 到备用的服务器端
                            
                    B. 等一段时间，待服务程序处理完剩下的请求，直到没有活动的请求
                    C. kill 并重启服务
                    D. 检测新进程的服务是否重启
                    E. 依次重启服务端的
                    
            (3) TCP 连接作为分布式系统进程间通信的唯一方式．原因是任何一方进程意外退出，对方都能及时的收到通知(操作系统会及时得
            　　关闭进程的 TCP socket)
            (4) TCP keepalive 不能代替应用层的心跳，原因是心跳除了判断网络是否正常，还可以判断该程序是否正常运行．
            　　　通常是服务器向客户端发送心跳．
                　心跳协议的关键点:
                        1. 尽量在工作线程中发送，不要另起一个线程．防止工作线程阻塞或则死锁，但心跳还是正常发送．
                        2. 与业务消息采用同一条连接，不要新开 TCP 连接．
                        
            (5) 分布式系统的进程标识
                    A. 进程标识是用来唯一标识一个程序的"一次运行"，同一份代码多次运行其对应的进程标识不同．
                    B. 用 ip:port 来标识进程，如果该进程服务为无状态的(没有上下文关系)，则没有问题．如果
                    　　该进程服务是有状态关系的，客户端无法区分该 ip:port　是新的进程还是原来的进程，导致某些
                    　　业务不正常．
                    C. 用 host:pid 标识进程，需考虑 pid 可能会轮回
                    D. 正确表示进程标识(ip:port:start_time:pid), 而　ip:port:start_time　不能保证唯一性，
                    　　如果程序短时间内重启，start_time可能会一样．
                    　　有了唯一的 gpid, 那么全局唯一的消息 id 可以用计数器递增的值和 gpid 组合起来
                    
            (6) 构建易于维护的分布式程序
                    易于维护即管理方便，日常劳动负担小．长期运行的且与其他机器继续通信交互的进程应该要提供管理接口，
                    可以查看进程的状态．一种具体的做法是在程序中内置一个 HTTP 服务器，能够查看进程的健康状态及当前
                    负载．
                    采用　HTTP　的原因是
                          A. 本身是 TCP Server ,可以安全的方便防止重复启动(bind() 失败退出)
                          B. 不必使用特定的客户端程序，用普通的 web 浏览器就可以
                          C. HTTP 是文本协议，在异常条件下可以使用 wget/curl 来获取内容
                          D. 可以借助 url 来划分请求的业务
                          
            (7) 为系统后续升级做准备
                    升级之前一定要做好 rollback 计划，做好回退准备
                    A. 要定义跨语言的可扩展的消息格式
                            1.可扩展的消息格式要求：内容中避免协议版本号，否则代码中会有一堆难以维护的 case-switch
                            2.可扩展的消息格式的内容，如果是文本格式数据，可以采用 JSON 或则 XML. 如果是二进制格式
                            　则可以采用 Google Protocol Buffer.
                            
            (8) 分布式自动化回归测试
                    A. 单元测试
                            1. 单元测试主要测试一个函数，一个 class 
                            2. 单一测试的缺点
                                    I. 阻碍大型重构．单元测试属于白盒测试，需要编写测试代码来调用被测代码(被测的函数)
                                    　　所以测试代码与被测代码紧耦合．在添加新功能的时候，我们常会重构已有的代码，
                                    　　在保持原来功能的情况下重构的代码能够用到其他的地方，这样一来原先单元测试就
                                    　　通不过．这样又得修改单元测试，耗时
                                    II. 为了方便测试而实施依赖注入，破坏代码的完整性．单看一块代码不知道到它是干嘛的，
                                    　　　它依赖的对象不知道在哪儿创建的．
                                    
                   　B. 一种自动化的回归测试方案　test harness , 这是一个独立的进程，模拟与被测程序的交互的所有程序．
                            1. test harness 优点
                                    (1) 完全从外部观察被测程序，没有对被测程序进行侵入，被测程序代码不需要像
                                    　　　单元测试一样考虑接口
                                    (2) 允许被测程序做大的重构，以优化内部代码结构，只要外部表现的形式不变(接口报文不变)
                                    (3) 有了一套完整的 test harness,甚至可以换种语言重写被测程序，测试用例依然可用．
                                    
                            2.　实现机制
                                    (1) test harness 能发起或则多个连接，可能需要用到现成的 NIO 网络库
                                    (2) test harness 只需要表现跟它 mock 程序一样，不需要真正的实现其业务逻辑，
                                    　　　只需要给被测程序的信息一样就可以了．如果要 mock 比较复杂的逻辑，可以
                                    　　　用 "记录 + 回放"的方式，把预设的响应回放到被测程序中．
                            
            (9) 分布式系统的运维
                    运维包括部署(升级)可执行程序与配置文件，监控进程状态，管理服务进程(重启服务)，故障响应
                    1.等级一: 全手工操作(实验室水平)
                            部署: 编译后手工将可执行程序拷贝到各台机器上，配置文件也要手工修改放到对应的机器上
                            管理: 手工启动服务进程，并且显式指名配置文件的路劲，重启进程需要登陆到 host (机器)
                            　　　进行 restart
                            升级: 如果需要升级服务进程，需要手动登陆多台 hosts,并拷贝新的可执行程序，重启
                            配置: Web Server 配置文件里写了 Suduku Sover 的 ip:port, 如果要部署新的
                            　　　Suduku Sover，则需要在　Web Server 配置文件增加并重启 Web Server
                            
                    2. 等级二: 使用零散的自动化脚本和第三方组件
                            这一层级主要是公司刚起步，开发重心在实现新功能上，顾不上高效的运维，运维工作基本上由
                            开发人员兼职．
                                部署: 部署可执行程序用脚本实现,为了让 c++ 可执行程序拷贝到 host 就能运行，通常采用静态运行
                                　　　以避免 .so 版本不同造成故障．同时服务进程的配置文件需要放在 git(版本管理) 上，
                                　　　每个不同的服务进程实例都有自己的 branch, 每次修改都要入库．程序启动时用到的配置文件
                                    　都应该从 git check out , 不能手工修改(减少人为失误)
                                管理: 服务进程使用 daemon 方式管理，异常 crash 后自动重启
                                升级: 可执行程序也有一套版本管理，发布新版本时不能覆盖原先老的可执行文件
                                　　　现在运行的是 /v1.0.0/bin/solver
                                     需要发布的是 /v2.0.0/bin/solver
                                     原因是　(1) 已经把老的替换成新的，那么老的可执行程序不存在，在老的可执行程序运行一段时间
                                     　　　　　　　后会出现 bus error
                                            (2) 当出现 core dump ,需要与"产生该 core dump 的可执行程序" 配对
                                            
                                监控: 公司会使用开源的软件监控每台 host 的资源使用情况，
                                
                    3. 等级三: 自制机群管理系统，集中化配置
                            这一层级主要适合成熟的大公司
                            部署:只需要向 Master 发送一条指令， Master 会命令　Slave 从指定的地点 rsync 新的可执行
                            　　　程序到本地目录
                            进程监控和管理: Sudoku Solver 是由 Slave 节点 fork() 产生的，同时父子进程可以通过 pipe()
                                          进行消息的通信，　Slave 节点得知 Sudoku Solver 异常 crash 后会令其重启．
                                          Master 提供一个 Web 页面来看本机群中各个服务程序是否正常．
                                          
                            升级: 如果要主动重启 Sudoku Solver ,可以向 Master 发送指令，不需要 ssh & kill,
                                 同时会保存每台 host 的服务进程启动时间．动态的获知配置情况，当一个系统新增
                                 Sudoku Solver　服务，可以通过 Web Server 管理接口向其发送增加 ip:port 命令．
                                 还有一种方法就是通过数据库，每个 Sudoku Solver 服务启动时往数据库表中 insert 
                                 自身的 ip:port, Web Server 配置里写了 select 语句,获取可利用的服务的 ip:port
                                 Web Server 通过数据库触发器及时的感知 Sudoku Solver ip address list 的变化.
```

## 分布式系统知识点

```shell
    1. SOA : Service Oriented Architecture ,面向服务架构, 
       SOA 架构是构造分布式计算应用程序的方法。它将 应用程序功能作为服务 发送给最终用户或者其他服务
```

## 分布式系统架构本质

```shell
    1.采用分布式系统而不用单机系统的原因
            (1) 增大系统容量．随着业务量越来越大，一台机器已经无法满足要求，需要垂直或则水平拆分系统业务，
            　　让其变为分布式系统. 其主要工作是大流量处理，对应的技术是通过集群技术把大规模并发请求的负载
            　　分散到不同的机器上．
            (2) 增加系统的可用性(高可用)，提高系统的高可用，则该架构中不能存在单点故障，则需要通过分布式架构来冗余系统．
                关键业务保护,提高后台服务的可用性，把故障隔离起来阻止多米诺骨牌效应（雪崩效应）。
                如果流量过大，需要对业务降级，以保护关键业务流转。
            (3) 模块化，开发效率高 
             
    2. 分布式系统的劣势
            (1) 系统架构的设计复杂(例如分布式事务)
            (2) 部署分布式系统复杂(而单机系统则比较简单)
            (3) 系统吞吐量会变大，但其响应的时间会变长(要考虑到分发处理)
            
    3. 分布式系统架构的难点在于系统设计，以及管理和运维,虽然解决了"单点”和“性能容量”的问题, 但会引发其他的问题，
    　　需要不断地用各式各样的技术和手段来解决这些问题．
    
    4. 面向服务的架构的阶段
            (1) 第一阶段: 单体架构，模块的耦合性高，模块功能之间的相互关联
            (2) 第二阶段: SOA 架构，需要一个标准的协议或是中间件来联动其它相关联的服务（如 ESB）
            　　　　　　　　服务间并不直接依赖，而是通过中间件的标准协议或是通讯框架相互依赖
            (3) 第三阶段: 微服务架构，耦合度低，每一个微服务都能独立完整地运行，
            　　　　　　　　它和传统 SOA 的差别在于，服务间的整合需要一个服务编排或是服务整合的引擎，
            　　　　　　　　这个编排和组织引擎可以是工作流引擎，也可以是网关。还需要辅助于像容器化调度这样的技术方式，如 Kubernetes
            
    5. 分布式系统的难点
            (1) 分布式系统的不标准问题
                    a. 软件和应用不标准。 不同的软件，不同的语言会出现不同的兼容性和不同的开发、测试、运维标准
                    b. 通讯协议不标准。不同的软件用不同的协议.
                    c. 数据格式不标准。不同的团队中相同的网络协议里也会出现不同的数据格式.
                    d. 开发和运维的过程和方法不标准。
                    
                    A. 一个好的配置管理，应该分成三层,底层(和操作系统相关)，中间层(和中间件相关)，最上层(和业务应用相关)
                       底层和中间层是不能让用户灵活修改的，只能让用户选择
                       
                    B. 规范数据通讯协议．作为一个协议，一定要有协议头和协议体。协议头定义最基本的协议数据，而协议体才是真正的业务数据。
                    　对于协议头，我们需要非常规范地让每一个使用这个协议的团队都使用一套标准的方式来定义，
                    　这样我们才容易对请求进行监控、调度和管理。
                    
            (2) 系统架构中服务依赖性问题
                    分布式架构下，服务是会有依赖的，于是一个服务依赖链上，某个服务挂掉了，会导致出现“多米诺骨牌”效应，会倒一片。
                    服务依赖具体带来了问题:
                        A. 服务依赖链中，出现“木桶短板效应”——整个 SLA(Service-Level Agreement服务级别协议) 由最差的那个服务所决定。
                        
                    这是服务治理的内容.服务治理不但需要我们定义出服务的关键程度，还需要我们定义或是描述出关键业务或服务调用的主要路径。
                    没有这些，我们将无法运维或是管理整个系统
                    
                    我们不但要拆分服务，还要为每个服务拆分相应的数据库．数据库方面也需要做相应的隔离，系统间不能读取对方的数据库，
                    只通过服务接口耦合，这也是微服务的要求
                    
            (3) 故障发生的概率更大(但产生的影响面小)
                    在分布式系统中，因为使用的机器和服务会非常多，所以，故障发生的频率会比传统的单体应用更大，但产生的影响面小
                    这时将引发运维团队在分布式系统下会非常忙，我们可以定义一些关键指标，同时在设计系统时考虑如何减轻故障。
                    如果无法避免，也要使用自动化的方式恢复故障，减少故障影响面。
                    
            (4) 多层架构的运维复杂度更大
                    系统分成四层,由下到上划分：
                        a. 基础层就是我们的机器、网络和存储设备等。
                        b. 平台层就是我们的中间件层，Tomcat、MySQL、Redis、Kafka 之类的软件。
                        c. 应用层就是我们的业务软件，比如，各种功能的服务。
                        d. 接入层就是接入用户请求的网关、负载均衡(nginx)或是 CDN、DNS 
                        
                    这逻辑架构的划分带来的影响是:
                        a. 任何一层的问题都会导致整体的问题；
                        b. 没有统一的视图和管理，导致运维被割裂开来，造成更大的复杂度。
                    
                    应对策略: 规范标准
```

## 分布式系统技术栈

```shell
    1. 提高架构的性能
            (1) 缓存系统(缓存分区，缓存更新，缓存命中)
                   加入缓存系统，可以有效地提高系统的访问能力。从前端的浏览器，到网络，再到后端的服务，底层的数据库、文件系统、
                   硬盘和 CPU，全都有缓存，这是提高快速访问能力最有效的手段。对于分布式系统下的缓存系统，需要的是一个缓存集群。
                   这其中需要一个 Proxy 来做缓存的分片和路由
            (2) 负载均衡系统(网关系统，负载均衡，服务路由，服务发现)
                    是做水平扩展的关键技术，用多台机器来共同分担一部分流量请求
            (3) 异步调用(消息队列，消息持久，异步事务)
                    异步系统主要通过消息队列来对请求做排队处理，把前端的请求的峰值给“削平”了，而后端通过自己能够处理的速度来处理请求。
                    这样可以增加系统的吞吐量，但是实时性就差很多了。还会引入消息丢失的问题，所以要对消息做持久化，
                    这会造成“有状态”的结点，从而增加了服务调度的难度。
            (4) 数据分区和数据镜像
                    数据分区是把数据按一定的方式分成多个区（比如通过地理位置），不同的数据区来分担不同区的流量。
                    这需要一个数据路由的中间件，会导致跨库的 Join 和跨库的事务非常复杂。而数据镜像是把一个数据库镜像成多份一样的数据，
                    这样就不需要数据路由的中间件了。你可以在任意结点上进行读写，内部会自行同步数据。然而，
                    数据镜像中最大的问题就是数据的一致性问题。对于一般公司来说，在初期，会使用读写分离的数据镜像方式，
                    而后期会采用分库分表的方式。
                    
    2. 提高系统稳定性
            (1) 服务拆分(服务调用，服务依赖，服务隔离)
                    主要有两个目的：一是为了隔离故障，二是为了重用服务模块。但服务拆分完之后，会引入服务调用间的依赖问题
            (2) 服务冗余(弹性伸缩，故障迁移，服务发现)
                    是为了去除单点故障，并可以支持服务的弹性伸缩，以及故障迁移。然而，对于一些有状态的服务来说，
                    冗余这些有状态的服务带来了更高的复杂性。弹性伸缩时，需要考虑数据是复制还是重新分片，
                    故障迁移的时候还要连同数据一起迁移
            (3) 限流降级(异步队列，降级控制，服务熔断)
                    当系统实在扛不住压力时，只能通过限流或者功能降级的方式来停掉一部分服务，或是拒绝一部分用户，
                    以确保整个架构不会挂掉。这些技术属于保护措施
            (4) 高可用架构(多租户系统，灾备多活，高可用服务)
                    从冗余架构的角度来保障可用性。比如，多租户隔离，灾备多活，或是数据一致性的集群。总之，就是为了不出单点故障。
            (5) 高可用运维(全栈监控，DevOps, 自动化运维)
                    指的是 DevOps 中的 CI（持续集成）/CD（持续部署）。一个良好的运维应该是一条很流畅的软件发布管线，
                    其中做了足够的自动化测试，还可以做相应的灰度发布，以及对线上系统的自动化控制。
                    这样，可以做到“计划内”或是“非计划内”的宕机事件的时长最短
                    
    3. 分布式系统的关键技术
            (1) 服务治理
                    服务拆分、服务调用、服务发现，服务依赖，服务的关键度定义……
                    服务治理的最大意义是需要把服务间的依赖关系、服务调用链，以及关键的服务给梳理出来，
                    并对这些服务进行性能和可用性方面的管理
            (2) 架构软件管理
                    服务之间有依赖，而且有兼容性问题，所以，整体服务所形成的架构需要有架构版本管理、整体架构的生命周期管理，
                    以及对服务的编排、聚合、事务处理等服务调度功能。
            (3) DevOps
                    分布式系统可以更为快速地更新服务，但是对于服务的测试和部署都会是挑战。所以，还需要 DevOps 的全流程，
                    其中包括环境构建、持续集成(CI)、持续部署(CD)等
            (4) 自动化运维
                    有了 DevOps 后，我们就可以对服务进行自动伸缩、故障迁移、配置管理、状态管理等一系列的自动化运维技术了。
            (5) 资源调度管理
                    应用层的自动化运维需要基础层的调度支持，也就是云计算 IaaS 层的计算、存储、网络等资源调度、隔离和管理
            (6) 整体架构监控
                    如果没有一个好的监控系统，那么自动化运维和资源调度管理只可能成为一个泡影，因为监控系统是你的眼睛。
                    没有眼睛，没有数据，就无法进行高效的运维(没有一个好的监控系统，我们将无法进行自动化运维和资源调度)
                    所以说，监控是非常重要的部分。
                    这里的监控需要对三层系统（应用层、中间件层、基础层）进行监控
            (7) 流量控制
                    负载均衡、服务路由、熔断、降级、限流等和流量相关的调度都会在这里，包括灰度发布之类的功能也在这里
                    
            根据以上那么多的技术，学习成本，投入的人力物力较大，可以通过 Docker 以及其衍生出来的 Kubernetes 之类的软件或解决方案，
            大大地降低了做上面很多事情的门槛．Docker 把软件和其运行的环境打成一个包，然后比较轻量级地启动和运行。
            在运行过程中，软件变成了服务　可能会改变　现有的环境。但是没关系，当你重新启动一个 Docker 的时候，
            环境又会变成初始化状态。

    4. 分布式系统的“纲”
            由于分布式系统所需要的技术太复杂，所以我们不能着眼于每个细节，而需要掌握关键技术．
                (1) 全栈系统监控(应用整体监控)
                (2) 服务 / 资源调度；
                (3) 流量调度；
                (4) 状态 / 数据调度；
                (5) 开发和运维的自动化。 是需要把前四项都做到了，才有可能实现的
```

### 分布式系统的关键技术一：全栈系统监控

```shell
    1. 监控系统需要具备的功能:
            (1) 全栈监控；
            (2) 关联分析；
            (3) 跨系统调用的串联；
            (4) 实时报警和自动处置；
            (5) 系统性能分析。
            
    2. 全栈监控(对基础层，中间层，应用层进行监控)
            (1) 基础层：监控主机和底层资源。比如：CPU、内存、网络吞吐、硬盘 I/O、硬盘使用等。
            (2) 中间层：就是中间件层的监控。比如：Nginx(网关)、Redis(缓存服务)、ActiveMQ、
            　　　　　　Kafka(消息队列)、MySQL、Tomcat(Java容器) 等。
            (3) 应用层：监控应用层的使用。比如：HTTP 访问的吞吐量、响应时间、返回码，
                       调用链路分析，性能瓶颈，还包括用户端的监控。
                       
            将这些监控数据进行标准化:
                a. 日志数据结构化；
                b. 监控数据格式标准化；
                c. 统一的监控平台；
                d. 统一的日志分析。
                
    3. 现实中很多监控系统存在的问题
            (1) 监控数据都是隔离开来的。
                    因为公司分工的问题，开发、应用运维、系统运维，各管各的，所以很多公司的监控系统也是各是各的，完全串不起来。
            (2) 监控的数据项太多。
                    有些公司的运维团队把监控的数据项多做为一个亮点到处讲，比如监控指标达到 5 万多个。这不合理，
                    因为信息太多等于没有信息，抓不住重点的监控才会做成这个样子
                    
    4. 一个好的监控系统具备的特点
            (1) 容量管理
                     提供一个全局的系统其在运行过程中数据的展示，可以让工程师团队知道是否需要增加机器或者其它资源。
            (2) 性能管理分析
                    可以通过查看大盘，找到系统瓶颈，并有针对性地优化系统和相应代码。
            (3) 定位问题
                    可以快速地暴露并找到问题的发生点，帮助技术人员诊断问题。故障发生不可怕，可怕的是故障的恢复时间过长，
                    需要快速的定位问题
                    
    5. 如何做出一个好的监控系统
            (1) 服务调用链跟踪
                    这个监控系统应该从对外的 API 开始，然后将后台的实际服务给关联起来，然后这个服务的依赖服务给关联起来，
                    直到最后一个服务（如 MySQL 或 Redis），这样就可以把整个系统的服务全部都串连起来了。
                    这个事情的最佳实践是 Google Dapper 系统，其对应于开源的实现是 Zipkin。
                    对于 Java 类的服务，我们可以使用字节码技术进行字节码注入，做到代码无侵入式。
            (2) 服务调用时长分布
                    使用 Zipkin, 可以看到一个服务调用链上的时间分布(各个服务的时间分布)，这样有助于我们知道最耗时的服务是什么
            (3) 服务的 TOP N 视图
                    所谓 TOP N 视图就是一个系统请求的排名情况。 排名的方法：a）按调用量排名，b) 按请求最耗时排名
            (4) 数据库操作关联
                    对于 Java 应用，我们可以很方便地通过 JavaAgent 字节码注入技术拿到 JDBC 执行数据库操作的执行时间。
                    对此，我们可以和相关的请求对应起来。
            (5) 服务资源跟踪
                    
    6.好的监控系统的作用
            有了以上数据，同时把数据关联好。这样，我们才可能很快地定位故障，进而才能进行自动化调度，
            比如：
                一旦发现某个服务过慢是因为 CPU 使用过多，我们就可以做弹性伸缩。
                一旦发现某个服务过慢是因为 MySQL 出现了一个慢查询，我们就无法在应用层上做弹性伸缩，只能做流量限制，或是降级操作了。
  
```

### 分布式系统的关键技术二：服务调度

```shell
    1.服务治理的关键技术
            (1) 服务关键程度
            (2) 服务依赖关系。
            (3) 服务发现。
            (4) 整个架构的版本管理。
            (5) 服务应用生命周期全管理
            
            A. 服务关键程度和服务的依赖关系
                    (1) 服务关键程度要我们梳理和定义服务的重要程度。这不是使用技术可以完成的，这需要对业务的有较深理解，
                        才能定义出架构中各个服务的重要程度
                    (2) 梳理出服务间的依赖关系，服务间的依赖是一件很易碎的事。依赖越多越复杂，我们的系统就越易碎
                    　　一个服务的问题很容易出现一条链上的问题。因此，传统的 SOA 希望通过 ESB 来解决服务间的依赖关系，
                    　　这也是为什么微服务中希望服务间是没有依赖的，而让上层或是前端业务来整合这些个后台服务．
                    　　服务依赖最优解的上限是微服务，而服务依赖的下限是千万不要有依赖环．如果系统架构中有服务依赖环，
                    　　那么表明你的架构设计是错误的。循环依赖有很多的副作用，最大的问题是这是一种极强的耦合，会导致服务部署相当复杂和难解，
                    　　而且会导致无穷尽的递归故障和一些你意想不到的的问题。
                    
                       服务的依赖关系是可以通过技术的手段来发现的，这其中，Zipkin是一个很不错的服务调用跟踪系统，
                       它是通过 Google Dapper这篇论文来实现的。这个工具可以帮你梳理服务的依赖关系，以及了解各个服务的性能。
                       
                   　(3) 在梳理完服务的重要程度和服务依赖关系之后，我们就相当于知道了整个架构的全局。
                   
            B. 服务状态和生命周期的管理
                    (1) 在梳理完服务的重要程度和服务依赖关系之后,有了对架构的大致了解，这时需要［服务发现］这个中间件，来知道在这个动态的
                    　　架构中，当前所处的状态
                            a. 整个架构中有多少种服务？
                            b. 这些服务的版本是什么样的？
                            c. 每个服务的实例数有多少个，它们的状态是什么样的?
                            d. 每个服务的状态是什么样的？是在部署中，运行中，故障中，升级中，还是在回滚中，伸缩中，或者是在下线中……
                    (2) 服务状态
                            a. Provision，代表在供应一个新的服务；
                            b. Ready，表示启动成功了；
                            c. Run，表示通过了服务健康检查；
                            d. Update，表示在升级中；
                            e. Rollback，表示在回滚中。
                            f. Scale，表示正在伸缩中（可以有 Scale-in 和 Scale-out 两种）。
                            g. Destroy，表示在销毁中。
                            h. Failed，表示失败状态。
                            
                    (3) 整个架构的版本管理
                            除了各个项目的版本管理之外(也就是各个服务的版本)，还需要在上面再盖一层版本管理(架构版本)，
                            用来控制其中各个服务的版本兼容。比如，A 服务的 1.2 版本只能和 B 服务的 2.2 版本一起工作，
                            A 服务的上个版本 1.1 只能和 B 服务的 2.0 一起工作。这就是版本兼容性
                            如果我们要回滚一个服务的版本，就可以把与之有版本依赖的服务也一起回滚掉。
                            
                            这时版本管理需要一个服务清单：
                                a. 服务的软件版本；
                                b. 服务的运行环境——环境变量、CPU、内存、可以运行的结点、文件系统等；
                                c. 服务运行的最大最小实例数。
                                
                            每一次对这个清单的变更都需要被记录下来，算是一个架构的版本管理。
                            而我们上面所说的那个集群控制系统需要能够解读并执行这个清单中的变更，以操作和管理整个集群中的相关变更
                    
    2. 资源 / 服务调度
            (1) 主要有以下一些关键技术。
                    a. 服务状态的维持和拟合。
                    b. 服务的弹性伸缩和故障迁移。
                    c. 作业和应用调度。
                    d. 作业工作流编排。
                    e. 服务编排。     
                    
            A. 服务状态的维持和拟合
                    (1) 服务状态是服务的运行状态(Provision, Ready, Run等等)
                    (2) 服务在运行过程中状态会发生变化：
                            a. 一种是不预期的变化
                                    比如，服务运行因为故障导致一些服务挂掉，或是别的什么原因出现了服务不健康的状态。
                                    而一个好的集群管理控制器应该能够强行维护服务的状态。在健康的实例数变少时，
                                    控制器会把不健康的服务给摘除，而又启动几个新的，强行维护健康的服务实例数
                            b. 另外一种是预期的变化
                                    比如，我们需要发布新版本，需要伸缩，需要回滚。这时，集群管理控制器就应该把集群从现有状态迁移到
                                    另一个新的状态。这个过程并不是一蹴而就的，集群控制器需要一步一步地向集群发送若干控制命令。
                                    这个过程叫“拟合”——从一个状态拟合到另一个状态，而且要穷尽所有的可能，玩命地不断地拟合，
                                    直到达到目的。
                    (3) 程序正常的将一种状态切换到另一种状态的操作(例如当需要对集群进行 Scale 的时候): 这个叫 "拟合"
                            a. 先扩展出几个结点；
                            b. 再往上部署服务；
                            c. 然后启动服务；
                            d. 再检查服务的健康情况；
                            e. 最后把新扩展出来的服务实例加入服务发现中提供服务。
                            
                    (4) 集群控制系统就是要处理异常的状态变化和正常的服务状态变化(拟合)
            B. 服务的弹性伸缩和故障迁移
                    (1) 服务的弹性伸缩:
                            a. 底层资源的伸缩；
                            b. 服务的自动化部署；
                            c. 服务的健康检查；
                            d. 服务发现的注册；
                            e. 服务流量的调度。
                            
                    (2) 故障迁移(服务的某个实例出现问题时，我们需要自动地恢复它)
                            有两种模式
                                a. 宠物模式，就是一定要救活，主要是对于 stateful 的服务
                                b. 奶牛模式，就是不救活了，重新生成一个实例。
                            
                            故障迁移具体操作:
                                a. 服务的健康监控（这可能需要一个 APM 的监控）。
                                b. 如果是宠物模式，需要：服务的重新启动和服务的监控报警（如果重试恢复不成功，需要人工介入）。
                                c. 如果是奶牛模式，需要：服务的资源申请，服务的自动化部署，服务发现的注册，以及服务的流量调度。
                                
                            可用通过现成的技术  Docker 和 Kubernetes 这样的技术
            C. 服务工作流和编排
                    (1) 编排: 类比与操作系统， 一个好的操作系统需要能够通过一定的机制把一堆独立工作的进程给协同起来。
                             在分布式的服务调度中，这个工作叫做 Orchestration，国内把这个词翻译成“编排
                    (2) 传统的 SOA 是通过 ESB（Enterprise Service Bus）——企业服务总线来完成的。
                        ESB 的主要功能是服务通信路由、协议转换、服务编制和业务规则应用等.
                        ESB 的服务编制叫 Choreography，与我们说的 Orchestration 是不一样的。
                        Orchestration 的意思是，一个服务像大脑一样来告诉大家应该怎么交互，就跟乐队的指挥一样。
                        Choreography 的意思是，在各自完成专属自己的工作的基础上，怎样互相协作，就跟芭蕾舞团的舞者一样。
                        而在微服务中，我们希望使用更为轻量的中间件来取代 ESB 的服务编排功能。
                        简单来说，这需要一个 API Gateway 或一个简单的消息队列来做相应的编排工作。在 Spring Cloud 中，
                        所有的请求都统一通过 API Gateway（Zuul）来访问内部的服务。这个和 Kubernetes 中的 Ingress 相似。
```

### 分布式系统的关键技术三：流量与数据调度

```shell
    1. 流量调度和服务治理的区别
            一方面，服务治理是内部系统的事，而流量调度可以是内部的也可以外部接入层的事。
            另一方面，服务治理是数据中心的事，而流量调度要做得好，应该是数据中心之外的事，也就是我们常说的边缘计算，
            　　　　　是应该在类似于 CDN 上完成的事。
    2. 流量调度的主要功能为了提高系统架构的稳定性和高可用性。
    3. 流量调度的关键技术
            (1) 需要该关键技术的理由: 作为一个 API Gateway 来说，因为要调度流量，首先需要扛住流量，而且还需要有一些比较轻量的业务逻辑
            (2) 关键技术的内容:
                    a. 高性能。 API Gateway 必须使用高性能的技术，所以也就需要使用高性能的语言。
                    b. 扛流量。 要能扛流量，就需要使用集群技术。集群技术的关键点是在集群内的各个结点中共享数据。
                               这就需要使用像 Paxos、Raft、Gossip 这样的通讯协议。因为 API Gateway 需要部署在广域网上，
                               所以还需要集群的分组技术。
                    c. 业务逻辑。 API Gateway 需要有简单的业务逻辑，所以，最好是像 AWS 的 Lambda 服务一样，
                                可以让人注入不同语言的简单业务逻辑。
                    d. 服务化。 一个好的 API Gateway 需要能够通过 Admin API 来不停机地管理配置变更的，
                               而不是通过一个.conf 文件来人肉地修改配置。
    4. 状态数据调度
            (1) 这里的状态是 State，也就是说，有些服务会保存一些数据，而这些数据是不能丢失的，所以，这些数据是需要随服务一起调度的。
            (2) 状态数据调度采取的方案(转移问题)
                    转移问题”: 把这些有状态的东西存储到第三方服务上(比如 Redis、MySQL、ZooKeeper，或是 NFS、Ceph 的文件系统中),
                              让服务变为“无状态的服务”，但是 Redis 和 MySQL 上则有了状态。所以，
                              现在的分布式系统架构中出问题的基本都是这些存储状态的服务
                              
            (3) 分布式事务一致性的问题
                    a. 问题：　让数据服务可以像无状态的服务一样在不同的机器上进行调度，就会涉及数据的 replication 问题。
                    　　　　　　而数据 replication 则会带来数据一致性的问题，进而对性能带来严重的影响。
                    b. 解决数据副本间的一致性问题
                            I.   Master-Slave 方案。
                            II.  Master-Master 方案。
                            III. 两阶段和三阶段提交方案。
                            VI.  Paxos 方案。
                            
                            很多公司的分布式系统事务基本上都是两阶段提交的变种。比如：阿里推出的 TCC–Try–Confirm–Cancel，
                            或是我在亚马逊见到的 Plan–Reserve–Confirm 的方式，等等。凡是通过业务补偿，
                            或是在业务应用层上做的分布式事务的玩法，基本上都是两阶段提交，或是两阶段提交的变种。
                            换句话说，迄今为止，在应用层上解决事务问题，只有“两阶段提交”这样的方式，
                            而在数据层解决事务问题，Paxos 算法则是不二之选。
                            
                            数据结点的分布式方案: 真正完整解决数据 Scale 问题的应该还是数据结点自身(即数据存储方而不是应用层)
                            
            (4) 状态数据调度应该是由分布式存储系统来解决的，这样会更为完美。但是因为数据存储的 Scheme 太多，所以，
               导致我们有各式各样的分布式存储系统，有文件对象的，有关系型数据库的，有 NoSQL 的，有时序数据的，有搜索数据的，有队列的……
               总之，状态数据调度应该是在 IaaS 层的数据存储解决的问题，而不是在 PaaS 层或者 SaaS 层来解决的。
               在 IaaS 层上解决这个问题, 一般来说有三种方案，
                    一种是使用比较廉价的开源产品，如：NFS、Ceph、TiDB、CockroachDB、ElasticSearch、InfluxDB、MySQL Cluster
                                               和 Redis Cluster 之类的；
                    另一种是用云计算厂商的方案。
                    第三种可以使用更为昂贵的商业网络存储方案。
                            
```

### 一个软件公司的软件工程能力

```shell
    1. 提高服务的 SLA
        服务的 SLA:  我们能提供多少个 9 的系统可用性，而每提高一个 9 的可用性都是对整个系统架构的重新洗礼
        提高系统的 SLA 主要表现在两个方面：
            a. 高可用的系统；
            b. 自动化的运维。 因为故障是常态，如果没有自动化的故障恢复，很难提高服务的 SLA
            
    2. 能力和资源重用或复用
            表现为:
                    a. 软件模块的重用
                    b. 软件运行环境和资源的重用
            
            这就需要我们设计的时候构建出通用的软件模块或则服务，同时使用统一的软件通讯协议，统一的开发和运维管理方法
            
    3. 过程的自动化
            软件生产和运维的过程自动化，　对应与软件生产流水线和软件运维自动化
```

### PasS 平台的本质

```shell
    1.一个好的 PaaS 平台应该具有分布式、服务化、自动化部署、高可用、敏捷以及分层开放的特征，并可与 IaaS 实现良好的联动。
    　服务化是 PaaS 的本质。软件模块重用，服务治理，对外提供能力是 PaaS 的本质．
    　分布式是 PaaS 的根本特性。多租户隔离、高可用、服务编排是 PaaS 的基本特性
    　自动化是 PaaS 的灵魂。自动化部署安装运维，自动化伸缩调度是 PaaS 的关键。
    2. 一个完整的 PaaS 平台会包括以下几部分:
           (1) PaaS 调度层 – 主要是 PaaS 的自动化和分布式对于高可用高性能的管理。
           (2) PaaS 能力服务层 – 主要是 PaaS 真正提供给用户的服务和能力。
           (3) PaaS 的流量调度 – 主要是与流量调度相关的东西，包括对高并发的管理。
           (4) PaaS 的运营管理 – 软件资源库、软件接入、认证和开放平台门户。
           (5) PaaS 的运维管理 – 主要是 DevOps 相关的东西。
    3. PaaS 平台的生产和运维
            从左上开始软件构建，进入软件资产库（Docker Registry+ 一些软件的定义），然后走 DevOps 的流程，
            通过整体架构控制器进入生产环境，生产环境通过控制器操作 Docker+Kubernetes 集群进行软件部署和生产变更。
            其中，同步服务的运行状态，并通过生命周期管理来拟合状态，服务运行时的数据会进入到相关应用监控，
            应用监控中的一些监控事件会同步到生命周期管理中，再由生命周期管理器来做出决定，通过控制器来调度服务运行。
            当应用监控中心发现流量变化，要进行强制性伸缩时，它通过生命周期管理来通知控制系统进行伸缩。
    4. 总结
            (1) 构建分布式系统面临的问题
                    a. 分布式系统的硬件故障发生率更高，故障发生是常态，需要尽可能地将运维流程自动化。
                    b. 需要良好地设计服务，避免某服务的单点故障对依赖它的其他服务造成大面积影响。
                    c. 为了容量的可伸缩性，服务的拆分、自治和无状态变得更加重要，可能需要对老的软件逻辑做大的修改。
                    d. 老的服务可能是异构的，此时需要让它们使用标准的协议，以便可以被调度、编排，且互相之间可以通信。
                    e. 服务软件故障的处理也变得复杂，需要优化的流程，以加快故障的恢复。
                    f. 为了管理各个服务的容量，让分布式系统发挥出最佳性能，需要有流量调度技术。
                    g. 分布式存储会让事务处理变得复杂；在事务遇到故障无法被自动恢复的情况下，手动恢复流程也会变得复杂。
                    h. 测试和查错的复杂度增大。
                    i. 系统的吞吐量会变大，但响应时间会变长。
                    
            (2) 解决方案
                    a. 需要有完善的监控系统，以便对服务运行状态有全面的了解。
                    b. 设计服务时要分析其依赖链；当非关键服务故障时，其他服务要自动降级功能，避免调用该服务。
                    c. 重构老的软件，使其能被服务化；可以参考 SOA 和微服务的设计方式，目标是微服务化；
                        使用 Docker 和 Kubernetes 来调度服务。
                    d. 为老的服务编写接口逻辑来使用标准协议，或在必要时重构老的服务以使得它们有这些功能。
                    e. 自动构建服务的依赖地图，并引入好的处理流程，让团队能以最快速度定位和恢复故障
                    f. 使用一个 API Gateway，它具备服务流向控制、流量控制和管理的功能。
                    g. 事务处理建议在存储层实现；根据业务需求，或者降级使用更简单、吞吐量更大的最终一致性方案，
                        或者通过二阶段提交、Paxos、Raft、NWR 等方案之一，使用吞吐量小的强一致性方案。
                    h. 通过更真实地模拟生产环境，乃至在生产环境中做灰度发布，从而增加测试强度；
                       同时做充分的单元测试和集成测试以发现和消除缺陷；最后，在服务故障发生时，
                       相关的多个团队同时上线自查服务状态，以最快地定位故障原因。
                    i. 通过异步调用来减少对短响应时间的依赖；对关键服务提供专属硬件资源，并优化软件逻辑以缩短响应时间。
```

# 分布式系统设计模式

## 分布式系统弹力设计

### 认识故障和弹力设计

```shell
    1.弹力设计又叫容错设计．其中着眼于分布式系统的各种“容忍”能力，包括容错能力（服务隔离、异步调用、请求幂等性）、
    　可伸缩性（有 / 无状态的服务）、一致性（补偿事务、重试）、应对大流量的能力（熔断、降级）
     
       弹力（Resiliency）的概念: 一方面，在好的情况下，这个事对于我们的用户和内部运维来说是完全透明的，系统自动修复不需要人的干预
                         　　　另一方面，如果修复不了，系统能够做自我保护，而不让事态变糟糕。
    2. 系统可用性测量
            Availability=MTTFMTTF+MTTR
            a. MTTF 是 Mean Time To Failure，平均故障前的时间，即系统平均能够正常运行多长时间才发生一次故障。
               系统的可靠性越高，MTTF 越长
            b. MTTR 是 Mean Time To Recovery，平均修复时间，即从故障出现到故障修复的这段时间，这段时间越短越好。
    3. 故障原因
            A.
                (1) 无计划的
                        a. 系统级故障，包括主机、操作系统、中间件、数据库、网络、电源以及外围设备。
                        b. 数据和中介的故障，包括人员误操作、硬盘故障、数据乱了。
                        c. 还有自然灾害、人为破坏，以及供电问题等
                (2) 有计划的
                        a. 日常任务：备份，容量规划，用户和安全管理，后台批处理应用。
                        b. 运维相关：数据库维护、应用维护、中间件维护、操作系统维护、网络维护。
                        c. 升级相关：数据库、应用、中间件、操作系统、网络，包括硬件升级。
                        
            B.
                a. 网络问题。网络链接出现问题，网络带宽出现拥塞……
                b. 性能问题。数据库慢 SQL、Java Full GC、硬盘 IO 过大、CPU 飙高、内存不足……
                c. 安全问题。被网络攻击，如 DDoS 等。
                d. 运维问题。系统总是在被更新和修改，架构也在不断地被调整，监控问题……
                e. 管理问题。没有梳理出关键服务以及服务的依赖关系，运行信息没有和控制系统同步……
                f. 硬件问题。硬盘损坏、网卡出问题、交换机出问题、机房掉电、挖掘机问题……
    4. 不要尝试着去避免故障，而是要把处理故障的代码当成正常的功能做在架构里写在代码里
```

### 弹力设计之"隔离设计"(Bulkheads)

```shell
    1.按服务的种类来做分离
            (1) 例如：将系统分成了用户、商品、社区三个版块。三个板块分别使用各自的域名、服务器和数据库，
            　　　　　做到从接入层到应用层再到数据层三层完全隔离。这样一个版块的故障就不会影响到另一版块。
            (2) 微服务所推荐的架构方式
                    每个服务都有自己的一个数据库，每个数据库中都保存着和这个业务相关的数据和相应的处理状态
            (3) 按服务的种类进行隔离存在的问题
                    a. 需要同时获得多个版块的数据，就需要同时调用多个服务，这会增加响应时间
                    b. 如果有大数据平台，就需要把这些数据都抽取到一个数据仓库中进行计算，这也增加了数据合并的复杂度。
                       对于这个问题，我们需要一个框架或是一个中间件来对数据进行相应的抽取。
                    c. 如果我们的业务逻辑或是业务流程需要跨版块的话，那么一个版块的故障也会导致整个流程走不下去，
                       同样会导致整体业务故障。
                       对于这个问题：我们需要保证这个业务流程中各个子系统的高可用性，并且在业务流程上做成 Step-by-Step 的方式，
                       　　　　　　　这样用户交互的每一步都可以保存，以便故障恢复后可以继续执行，而不是从头执行。
                    d. 有跨版块的交互变得复杂
                        对于这个问题：需要一个类似于 Pub/Sub 的高可用的并可以持久化的消息订阅通知的中间件 
                        　　　　　　　来打通各个版块的数据和信息交换。
                    e. 在多个版块中分布式事务的问题。
                        对于这个问题： 我们需要“二阶段提交”这样的方案。
                                      在亚马逊中，使用的是 Plan – Reserve – Commit/Cancel 模式。
                                      先做一个 plan 的 API 调用，然后各个子系统 reserve 住相应的资源，如果成功，则 Commit；
                                      如果有一个失败，则整体 Cancel
                                      
    2. 按用户的请求来做分离
            (1) 例如: 将用户分成不同的组，并把后端的同一个服务根据这些不同的组分成不同的实例。让同一个服务对于不同的用户进行冗余和隔离，
                     当某一个服务实例挂掉时，只会影响其中一部分用户，而不会导致所有的用户无法访问
            (2) 多租户模式
                    a. 概念
                            对于一些比较大的客户，我们可以为他们设置专门独立的服务实例，或是服务集群与其他客户隔离开来，
                            对于一些比较小的用户来说，可以让他们共享一个服务实例，这样可以节省相关的资源。
                    b. 多租户的做法
                            a. 完全独立的设计。每个租户有自己完全独立的服务和数据。
                                    在开发实现上和资源隔离度方面会非常好，然而，成本会比较高，计算资源也会有一定的浪费。
                            b. 独立的数据分区，共享的服务。多租户的服务是共享的，但数据是分开隔离的。
                            c. 共享的服务，共享的数据分区。每个租户的数据和服务都是共享的。
                                    在资源利用和成本上会非常好，然而，开发难度非常大，而且数据和资源隔离非常不好
                    c. 工程上采用的方法
                            理论上(小公司)　技术方案会使用折衷方案，也就是中间方案，服务是共享的，数据通过分区来隔离，
                            　　　　　　　　而对于一些比较重要的租户（需要好的隔离性），则使用完全独立的方式。
                            
                            大公司  使用“完全独立”（完全隔离）的方案，通过底层的虚拟化技术（Hypervisor 的技术，如 KVM
                                    ，或是 Linux Container 的技术，如 Docker）来实现物理资源的共享和成本的节约
                                    
    3. 隔离设计的重点(设计时需要考虑到问题)
            (1) 定义好隔离业务的大小和粒度，过大和过小都不好。需要熟悉业务需求和系统分析。
            (2) 无论是做系统版块(服务隔离)还是多租户的隔离，你都需要考虑系统的复杂度、成本、性能、资源使用的问题，找到一个合适的均衡方案，
            (3) 隔离模式需要配置一些高可用、重试、异步、消息中间件，流控、熔断等设计模式的方式配套使用。
            (4) 这极大增加了分布式系统中的运维的复杂度需要很多自动化运维的工具，尤其是使用像容器或是虚拟机这样的虚拟化技术可以帮助
            　　　我们更方便地管理和利用资源部。
            (5) 需要一个非常完整并且看得到所有服务的监控系统(全栈监控)
                            
```

### 弹力设计之"异步通讯设计"

```shell
    1.同步调用
            (1) 好处
                    让系统间只耦合于接口，而且实时性也会比异步调用要高
            (2) 问题
                    a. 整个同步调用链的性能会由最慢的那个服务所决定
                    b. 同步调用只能是一对一的，很难做到一对多的通讯方式
                    c. 如果被调用方有问题，那么其调用方就会跟着出问题，于是会出现多米诺骨牌效应，故障会扩散
                    
    2. 异步通信
        A. 异步通讯的好处
                (1) 异步通讯最重要的是解耦服务间的依赖。最佳解耦的方式是通过 Broker 的机制。
                    解耦的目的是让各个服务的隔离性更好，这样不会出现“一倒倒一片”的故障。
                (2) 异步通讯的架构可以获得更大的吞吐量，而且各个服务间的性能不受干扰相对独立。
                    利用 Broker 或队列的方式还可以达到把抖动的吞吐量变成均匀的吞吐量，这就是所谓的“削峰”，
                    这对后端系统是个不错的保护。
                (3) 服务相对独立，在部署、扩容和运维上都可以做到独立不受其他服务的干扰。
                
        B. 设计异步通信需要注意的
                (1) 用于异步通讯的中间件 Broker 需要设计成高可用不丢消息的。因为是分布式的，所以可能很难保证消息的顺序，
                    因此你的设计最好不依赖于消息的顺序。
                (2) 异步通讯会导致业务处理流程不那么直观，因为像接力一样，所以在 Broker 上需要有相关的服务消息跟踪机制，
                    否则出现问题后不容易调试。
                (3) 消息传递中，可能有的业务逻辑会有像 TCP 协议那样的 send 和 ACK 机制。
                    比如：A 服务发出一个消息之后，开始等待处理方的 ACK，如果等不到的话，就需要做重传。此时，需要处理方有幂等的处理，
                        即同一件消息无论收到多少次都只处理一次。
                    
        A. 异步通讯的三种方式
                (1) 请求响应式
                        发送方依赖于接收方，并且要把自己的回调发送给接收方，接收方处理完后回调。
                (2) 通过直接订阅方式
                        接收方（receiver）会来订阅发送方（sender）的消息，发送方会把相关的消息或数据放到接收方所订阅的队列中，
                        而接收方会从队列中获取数据。
                (3) 通过 Broker 的方式(中间人订阅)
                        发送方（sender）和接收方（receiver）都互相看不到对方，它们看得到的是一个 Broker，
                        发送方向 Broker 发送消息，接收方向 Broker 订阅消息
                        
                        在 Broker 这种模式下，发送方的服务和接收方的服务最大程度地解耦。但是所有人都依赖于一个总线，
                        所以这个总线就需要有如下的特性：
                            a. 必须是高可用的，因为它成了整个系统的关键；
                            b. 必须是高性能而且是可以水平扩展的；
                            c. 必须是可以持久化不丢数据的。
                    
        B. 分布式系统的服务设计是需要向无状态服务（Stateless）努力的，无状态意味着你可以非常方便地运维。
           所以，事件通讯成为了异步通讯中最重要的一个设计模式。
      
        C. 事件驱动设计
                每个服务都是“自包含”的。所谓“自包含”也就是没有和别人产生依赖。而要把整个流程给串联起来，
                我们需要一系列的“消息通道（Channel）”。各个服务做完自己的事后，发出相应的事件，
                而又有一些服务在订阅着某些事件来联动。
                
                (1) 事件驱动方式的好处
                        a. 服务间的依赖没有了，服务间是平等的，每个服务都是高度可重用并可被替换的。
                        b. 服务的开发、测试、运维，以及故障处理都是高度隔离的。
                        c. 服务间通过事件关联，所以服务间是不会相互 block 的。
                        d. 在服务间增加一些 Adapter（如日志、认证、版本、限流、降级、熔断等）相当容易。
                        e. 服务间的吞吐也不再受限了，各个服务可以按照自己的处理速度处理。
                (2) 事件驱动方式的坏处
                        a. 业务流程不再那么明显和好管理。整个架构变得比较复杂。
                           解决这个问题需要有一些可视化的工具来呈现整体业务流程。
                        b. 事件可能会乱序。这会带来非常 Bug 的事。
                           解决这个问题需要很好地管理一个状态机。
                        c. 事务处理变得复杂。
                           需要使用两阶段提交来做强一致性，或是退缩到最终一致性。        
```

### 弹力设计之“幂等性设计”

```shell
    1. 概念: 一次和多次请求某一个资源应该具有同样的副作用.
    2. 背景: 在我们把系统解耦隔离后，服务间的调用可能会有三个状态，
             一个是成功（Success），一个是失败（Failed），一个是超时（Timeout）. 而针对超时,
```