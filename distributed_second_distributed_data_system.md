# 分布式数据系统

## 概要
```shell
    1. 分布式系统部署目的
        (1). 扩展性，当数据量和负载超过了单机处理上限，需要将负载分散到多台机器上。
        (2). 容错和高可用，单点故障会导致系统不可用，需要多台机器进行冗余。
        (3). 延迟考虑，客户可以访问最近数据中心提供的服务，降低响应的延迟。
    2. 复制和分区
        将数据分布到多个节点的方式有"复制"和"分区"。「复制」是在多个节点保存相同的数据，达到数据冗余，使得系统可用，
        同时也可以提高系统的性能。「分区」将大数据分到不同的节点。
    3. 分布式系统核心的基本问题，节点失效、网络不可靠、副本一致性、持久性、可用性与延迟之间各种细微的权衡
    4. 应用程序开发人员不必担心这么多底层的复制问题，而是假定数据库在“做正确的事情”，这是事务存在的原因，事务是数据库提供更强
       保证的一种方式, 事务比较适用于单节点上的操作，不太适用分布式系统．
```

## 数据复制
```shell
    1. 复制势必涉及到变化数据的同步问题。通常有 3 中方案，第一种主从复制。第二种多主节点复制。第三种无主节点复制。
    2. 复杂过程中的问题。
           (1). 采用同步复制还是异步复制。
           (2). 如何复制失败的副本
    3. 主从复制比较常见，因为它很容易理解，也不需要担心写冲突问题(因为只有一个主节点)。而万一出现节点失效、网络中断或者延迟抖动等情况，
       多主节点和无主节点复制方案会更加可靠，不过背后的代价则是系统的复杂性和弱一致性保证。
```

### 主从复制
```shell
    1. 主从复制的原理
            「第一步」指定一个副本为主副本（主节点），当客户端写数据库时，必须将写请求发生到主副本，主副本将新数据写到自己的本地存储。
            「第二步」其他副本为从副本（从节点），主副本将数据更新到自己的本地存储后，再将数据更改作为复制的日志或者
            更改流发生给其他从副本，从副本根据日志内容进行进行相应的操作，其写入的顺序与主副本要严格保持一致。
            「第三步」当客户端读数据库中数据时，直接去从副本进行读取。只有主副本才能接受写请求。
    2. 主从复制应用范围很广，关系型数据库：PostgreSQL, MySQL. 非关系型数据库：MongoDB,RethinkDB。
       分布式消息队列：Kafka, rabbitmq.
    3. 同步复制与异步复制，同步复制是主副本阻塞等待从副本的更新成功。同步复制的优点：一旦同步复制成功，则主从副本数据一致，
       都是最新的数据，所以客户端从数据库读的都是最新数据（不管是从主副本还是从副本）。同步复制的缺点：如果从副本无法及时完成
       同步（从副本节点崩溃，网络延迟），那么写入就不能视为成功。主副本就一直阻塞导致后续写入操作无法进行。
       所以系统一般不会将所有节点设置为同步复制，所以数据库「同步复制设置」的选项就是半同步模式，只将一个节点作为同步复制，
       其他节点作为异步复制。
    4. 增加新的从节点，保证新的从节点数据与主节点数据保持一致。简单的常规数据文件拷贝会导致不同的节点呈现不同的时间点数据，
       因为在这种拷贝方式过程中有数据写入更新操作。
       正常的逻辑过程：
            「第一步」在某个时间点对主节点的副本数据产生一致性快照。
            「第二步」将该快照拷贝到新的从副本节点上。
            「第三步」从节点连接主节点并请求该节点对应的快照之后的更新数据日志（内部的原理是在创建快照时，
                    快照与系统复制日志的位置保持关联）。
            「第四步」从节点在快照之后根据日志进行数据的更新。这个过程称为追赶。
    5. 处理节点失效情况。
            (1). 从节点失效，使用追赶式恢复。从节点的本地磁盘会保留副本收到的数据变更日志。那么在从节点恢复时就可以根据本地的更新日志
                 向主节点请求故障之后的数据。
            (2). 主节点失效，节点切换。判断主节点是否失效，通常采用超时的机制，各个节点间互发心跳包，如果主节点没有响应，
                 则认为主节点失效了。接下来进行选举（通过超过多数的节点共识），主要在从节点中选举出一个作为新的主节点，
                 该节点最好与旧的主节点数据差异小，同时客户端以后写请求都有路由到新的主节点中（请求路由），
                 其他节点接受来着新的主节点的变更数据。这时如果原来的主节点重新上线，系统要使其降为从节点.
    6. 主节点失效时进行节点切换存在的问题
            (1) 当使用了异步复制，并且在失效之前，新的主节点并没有收到原主节点的所有数据．这时如果原主节点恢复重新
            　　 加入到集群中，新的主节点会收到冲突的写请求，因为原主节点还未意识到角色的变化，还向其他的节点同步
            　　　消息．常见的解决方案是，原主节点上未完成复制的写请求丢弃，这可能会违背数据更新持久化的特性。
            (2) 在某些故障下，可能发生两个节点都自认为是主节点(脑裂)，两个主节点都可能接受写请求，并且没
                有很好解决冲突的办撞（“多主节点复制技术”），最后数据可能会丢失或者破坏
            (3) 如何设置合适的超时时间来判断主节点的失效．超时时间设置太长，如果是主节点真的失效，则整体恢复的时间长．
            　　　如果设置超时时间短，则可能由于突发的峰值导致主节点的响应时间变长甚至超时，或则是网络故障，这些都
            　　　有可能造成不必要的切换，导致结果更糟．
    7. 复制日志的实现(主从复制复制方式)
            (1) 基于语句的复制
                    主节点记录所执行的每个写请求(操作语句)并将该操作语句作为日志发送给从节点，从节点再根据语句执行．优点是
                    传输的数据量少，缺点是执行语句内有非确定性的函数(例如 NOW(). Rand())将会导致每个副本的值都不一样．
                    如果语句中使用自增列，或者依赖于数据库的现有数据，则所有副本必须按照完全相同的顺序执行，否则其执行的结果不同。
                    那么如果有多个同时并发执行的事务会有很大的限制。解决的方案：主节点可以在记录操作语句时将非确定性函数替换为
                    执行之后的确定的结果，这样所有节点直接使用相同的结果值。但是，这里面存在太多边界条件需要考虑，
                    因此目前通常首选的是其他复制实现方案。
            (2) 基于预写日志(WAL)的传输
                    预写日志记录的是存储引擎的磁盘数据结构数据，是底层的数据，如果主从节点采用相同的存储引擎，则可以通过
                    传输存预写日志来建立和主节点内容完全相同的数据副本。
                    应用: PostgreSQL, Oracle
                    缺点: 日志的记录的数据是很底层的(像哪些磁盘块哪些字节发送变化)，使复制方案与存储引擎紧密耦合在一起，
                    　　　如果主从节点的存储引擎不一致，则该复制方案无法工作
            (3) 基于行的逻辑日志复制
                    逻辑日志是区分与物理存储引擎，它与存储引擎进行解耦，更容易保持向后兼容，从而使主从节
                    点能够运行不同版本的软件甚至是不同的存储引擎。关系型数据库的逻辑日志是以行为单位，每一行
                    能够标识数据更删改的有效信息． MySQL 的基于行的复制的 binlog 日志就是这种方式．对于外部
                    程序而言，逻辑日志要更容易解析。如果要将数据库的内容发送到外部系统（如用于离线分析的数据仓库），
                    或构建自定义索引和缓存等，基于逻辑日志的复制更有优势，该技术也被称为变更数据捕获
            (4) 基于触发器的复制
                    比较: 以上 3 种复制方式是由数据库系统实现的，缺乏灵活性，比如数据变更时想复制一部分数据，或则想从
                    　　　一种数据库复制到另一种数据库．那么就可以采用触发器和存储过程(关系数据库支持的功能)
                    原理: 触发器支持注册应用层代码，当数据库系统发生数据更改（写事务）时自动执行上述自定义代码。
                    　　　通过触发器技术，可以将数据更改记录到一个单独的表中，然后外部处理逻辑访问该表，
                    　　　实施必要的自定义应用层逻辑，例如将数据更改复制到另一个系统。
                    应用: Oracle 的 Databus 和 Postgres 的 Bucardo
                    优缺点: 基于触发器的复制比其他复制开销大，更容易出错．
                    
    8. 主从复制的问题
            由于是单个主节点，所以其主节点存在单点故障．
```

### 复制滞后问题
```shell
    1. 由于采用异步复制，会存在主从节点的数据不一致的情况，但最终还是会保持一致。这种叫最终一致性。
    2. 写后读一致性，也称为读写一致性，即当用户对数据库进行写操作后，再进行读操作（读写操作是同一个用户），
       总能实时读取到其最新的数据。而其他用户则可能不能实时读取到最新的数据。
       (0) 解决的问题: 当一个用户更新了写操作，这个用户去读数据时是在从节点上读取，由于复制滞后的问题，导致读不到
       　　　　　　　　　更新的数据．
       (1) 写后读一致方案: 场景 1 用户访问可能会被修改的内容，则从主节点读取，否则在从节点读取．这样要求在实际执行查询
       　　　　　　　　　　 之前，就得知道哪些内容被修改．例如社交网络上，用户自身的首页信息，用户访问自身首页信息用主节点，
       　　　　　　　　　　　其他用户访问该用户的首页信息则在从节点上访问．
                        　场景 2 如果大部分内容都会被所有用户修改，则场景 1 中的方案不适用．需要采用最近最新的时间，
                        　如果更新后几分种内，其访问都从主节点读取，同时还要监控从节点的复制滞后的程度，在几分钟后，
                        　访问就会在从节点上读取数据．但要保证从节点已经在几分钟内完成复制，不在没有完成复制的从节点
                        　上取数据．
       (2) 存在的问题: 
                a. 同一个用户可能会从多个设备(web 端和移动端)访问数据，要保证跨设备的写后读一致性，即用户在某
                  　个设备上输入信息然后在另－台设备上查看，也应该看到刚刚所输入的内容．
                b. 如果副本分布在多数据中心内，则要确保不同设备请求路由到相同的数据中心(方案要求某一场景下必须主节点)
    3. 单调读
            (1) 解决的问题: 当采用异步复制的方式时，由于每个从节点的复制滞后的程度不同，会出现第一次在从节点 1 取到了最新的
            　　　　　　　　　数据(节点 1 完成了复制)，　第二次在节点 2 查询时又查不到数据(节点 2 还没复制完成)，这样会
            　　　　　　　　　出现数据回滚的现象．
            (2) 单调读一致性确保同一用户依次进行多次读取时，不会出现数据回滚(第一次读到新值，第二次读到旧值)．
            　　　主要方法是通过用户的 id 进行哈希每次都定位到同一个副本进行读取．
    4. 前缀一致读
            (0) 按照某个顺序发生的写请求，那么读取这些内容时也应该按照写入的顺序．
            (1) 解决的问题: 分区数据在副本复制时会有不同程度的滞后，导致在不同节点上读取时顺序与写入的顺序不一致．
            (2) 达到前缀一致读的方案
                    a. 任何具有因果关系的写操作都交给一个分区来完成．缺点是效率以及性能有影响．   
    5. 对于主从复制的滞后衡量程度
            由于主节点和从节点上写入都遵从相同的顺序，而每个节点都维护了复制日志执行的当前偏移量。
            通过对比主节点和从节点当前偏移量的差值， 就可以衡量出该从节点落后于主节点的程度。
```

### 多主节点复制
```shell
    1. 多主节点复制(主主复制)，系统中配置多个主节点，处理写的主节点都必须将数据的变更转发到其他所有的节点．每个主节点
    　　同时也是其他主节点的从节点．一个数据中心内部不太适合使用多主节点复制．
    2. 适用场景
          a. 多数据中心
                (0) 采用多数据中心的原则是就近访问．
                (1) 多数据中心，即一个数据中心有一个主节点，各个数据中心的主节点负责同其他数据中心的主节点进行数据的交换，更新．
                (2) 多数据中心下［主从复制］与［主主复制］比较
                        a. 性能，　在主从复制下每次写操作都要经过唯一一个主节点所在的数据中心，延迟高，违背多数据中心设计
                        　　　　　　(就近访问)，而主主复制则只需要写入就近的数据中心的主节点，再由该主节点同步到其他数据中心即可．
                        b.允许数据中心失效．对于主从复制而言，如果主节点所在的数据中心发送故障，则需要切换到另一个数据中心，将
                         　另一个数据中心的从节点变为主节点．而主主复制则允许一个数据中心失效，其恢复后进行数据更新即可．
          b. 离线客户端操作
                即对于应用程序在多种设备中，每一个设备都充当主节点的本地数据库，例如日历应用程序，即使设备断网了，也依然能够
                进行写入操作(增加会议)，只是更新到本地的数据库，在下次联网时进行各个设备之间的联网．
          c. 多人实时协作编辑
    3. 数据库主从复制的工具
        MySQL 的　Tungsten Replicator , PostgreSQL 的 BDR 以及 Oracle 的 GoldenGate
    4. 多主复制存在的问题
            (1) 不同的数据中心存在修改相同的数据，导致写冲突．
            (2) 与其他数据库功能(例如自增主键，触发器和完整性约束等)交互时会出现问题．
    5. 处理写冲突
            (1) 场景：两个用户同时编辑了同一篇文章的标题，用户 1 将标题 A 改为标题 B, 用户 2 将标题 A 改为 C,
                     他们都能在本地的主节点更改成功，但是在主节点之间数据进行异步复制时发生冲突．
            (2) 解决方案：
                    a. 避免冲突，通过应用层对特定记录的写请求总是在同一个主节点上．例如一个用户更新操作总是路由到
                    　　同一个数据中心，并在该数据中心的主节点上进行写操作．其他的用户进行路由到各自的数据中心内．
                    　　这种情况是其事先指定的数据中心都没有问题的情况下，并且用户不会更改位置．
                    b. 收敛于一致状态
                            问题:对于主从复制而言，因为就一个主节点，所以对于字段的值最后更新的结果就是最终的结果，
                                其后每一个从节点都会是一样的值．但对于多主复制而言，写请求先同步到各自的数据中心的
                                主节点，各个主节点之间再各自同步，如果对于同一个字段，则按照最后更新的值为最终值，
                                则数据库的副本最终处于不一致的状态．
                            解决方法:
                                第一种：给每一个写入分配唯一的 ID(可以是时间戳，UUID), 选出 ID 值最高, 将其他写入
                                　　　　丢弃，如果基于时间戳，则是最后写入获胜，这种方法很容易造成数据丢失．
                                第二种: 为每个副本分配一个唯一的 ID ，并制定规则，例如序号高的副本写入始终优先
                                     　于序号低的副本。这种方法也可能会导致数据丢失。
                                第三种: 不选出一个值，以某种方式将这些值合并在一起。例如，按字母顺序排序，然后拼接在一起(
                                       合并的标题可能类似于“ B/C ”)
                                第四种: 利用预定义好的格式来记录和保留冲突相关的所有信息，然后依靠应用层的逻
                                       辑，事后解决冲突（可能会提示用户）
                    c. 自定义冲突解决逻辑
                            解决冲突通过应用层来处理，这里有 2 个时机来执行应用层的冲突处理逻辑，第一个时机［写入时执行］，数据库
                            系统在复制变更日志时检测冲突，就会调用应用层的冲突处理程序．例如 Bucardo 支持编写一段 Perl 代码.
                            第二个时机［读取时执行］，在复制更改日志时，检测到冲突，不进行处理，将所有冲突值暂时保存下来，
                            在下一次读取数据时，会将数据的多个版本读返回给应用层。应用层会提示用户或自动解决冲突， 并将
                            最后的结果返回到数据库。CouchDB 采用这样的处理方式。需要注意的是冲突解决通常用于单行或则文档，
                            而不是整个事务(可能包括多行记录)
            (3) 最后写入者获胜，在并发写的情况下，以一种明确的方法来确定哪一个写入是最新的。例如采用最新的时间戳，
                              在写请求中带有写的时间戳，在处理冲突时，则选出最大的时间戳。「缺点」失去了数据的持久性，
                              虽然对于不同的客户端都是返回写入成功，但系统中只保存了一个数据，而不是保存冲突的多数据，
                              在应用层处理冲突。
                并发的含义，操作没有先后性，不具备因果关系和依赖关系。双方操作都不知道对方是否发生，所以并发不是通常以时间来判断的。
                如果是先后顺序则采用覆盖值的原则，但如果是并发的，则需要规定冲突方案来决定这个值最终结果。
            (4) 确定操作并发性算法
                    第一步: 服务器为每个主键维护一个版本号，每当主键新值写入时递增版本号，并将新版本号与写入的值一起保存。
                    第二步: 当客户端读取取主键时，服务器将返回所有(未被覆盖的)当前值以及最新的版本号。并且要求在写之前， 
                           客户必须先发送读请求。
                    第三步: 客户端写主键， 写请求必须包含之前读到的版本号、读到的值和新值合并后的集
                           合。写请求的响应结果可以像读操作一样， 会返回所有当前值
                    第四步: 当服务器收到带有特定版本号的写入时， 覆盖该版本号或更低版本的所有值（因
                            为知道这些值已经被合并到新传入的值集合中），但必须保存更高版本号的所有值
                            （因为这些值与当前的写操作属于并发）。
                    当写请求包含了前一次读取的版本号时，意味着修改的是基于以前的状态。如果一个写请求没有包含版本号，
                    它将与所有其他写入同时进行，不会覆盖任何已有值，其传入的值将包含在后续读请求的返回值列表当中。
                    问题:
                        合并并发值的合理方式是包含新值和旧值,两个客户端最后的值分别是［牛奶，面粉，鸡蛋，熏肉］ 
                        和［鸡蛋，牛奶，火腿］ 虽然牛奶和鸡蛋只是写入了一次，但它在两个客户端中都有出现。合并的最终值
                        应该是[牛奶，面粉，鸡蛋，熏肉，火腿]，其中去掉重复值。但是在删除操作时则会出现问题,
                        如果合并两个客户端的值，且其中有一个商品被某客户端删除掉， 则被删除的项目会再次出现在合并的终值中,
                        因为另外一个客户端还包含有这个值.
                    解决方法:
                        系统必须保留一个对应的版本号以恰当的标记该项目需要在合并时被剔除
            (5) 版本矢量(无主节点复制)
                    同主从复制的确定操作并发性算法一样,只不过需要为每个副本和每个主键都定义一个版本号。每个副本在处理
                    写入时增加自己的版本号，并且跟踪从其他副本看到的版本号。通过这些信息来指示要覆盖哪些值、该保留哪些并发值。
                    
    6. 多主复制的拓扑结构
            (1) 全部－至－全部(常见的拓扑结构)，每个主节点都将其写入同步到其他主节点．
            (2) 环形拓扑结构(MySQL 默认)，其中的每个主节点接收来自前序主节点的写入，并将这些写入（加上自
                己的写入）转发给后序主节点．
            (3) 星型结构，一个指定的根节点将写入转发给所有其他节点，其根节点接受其他节点的同步，其他节点只与根节点通信．
            
            a. 环形拓扑结构和星型结构中一个写请求同步到所有的副本，需要经过多个节点的转发．
                问题一: 其存在无限循环，解决办法是首先每一个节点都有唯一的标识符，复制日志中的每个写请求都记录了已复制的节点标识符。
                       如果某个节点收到数据更改的请求中带有自身的标识符，说明该请求已经被处理过，忽略此变更请求．
                问题二: 如果某一个节点发生故障，在修复之前，会影响其他节点之间复制日志的转发.解决方案: 只能通过手动重新配置拓扑结构
                　　　　排除故障节点．
            b. 全部－至－全部
                    优点: 排除单点故障，有更好的兼容性．
                    缺点: 由于网络链路的原因(网络速度，拥塞)导致，出现写请求的顺序不一致，原先节点一上先执行插入操作，之后过段时间
                    　　　在节点 3 上执行更新操作，由于网络原因导致，在节点 2 上先执行更新操作．解决方案：版本向量的技术          
```

### 无主节点复制
```shell
    1. 无主节点复制是允许任何副本接受来自客户端的写请求．实际应用有 Dynamo 风格数据库, 如 Riak, Cassandra 和 Voldemort
    2. 节点失效时有写请求
            无主节点写入的机制是，客户端并行的向所有副本发送写请求，这样如果有一个节点失效了也没有关系，当客户端需要读数据时，
            也并行向多个副本进行读数据，其中肯定会有未同步节点的数据，可以采用版本号技术确定哪个值更新．
    3. 无主同步过程
            当一个失效的节点重新上线后，需要同步失效期间的数据，有 2 种方法
            第一种: 读修复，当客户端并行读取多个副本时，可以检测出过期的数据，根据数据的版本号，例如副本 1 和 副本 2 是最新的
            　　　　数据，其版本号为 8, 而　副本 3 是旧值，其版本号为 7, 则在读过程中，就将新值写入到副本 3 中．这个方法适用与
            　　　　读频繁的场景
            第二种: 反熵过程，是后台进程不断查找副本之间数据的差异，将任何缺少的数据从一个副本复制到另一个副本．这个并不能保证
            　　　　　写请求的顺序，同时会有滞后的情况．
    4. 读写 quorum 
       如果有 n 个副本，写入需要 w 个节点确认，读取必须至少查询 r 个节点， 则只要r > n - w，读取的节点中一定会包含最新值.
       满足上述这些 r 、w值的读／写操作称之为法定票数读(或仲裁读)或法定票数写(或仲裁写) .也可以认为 w 和 r 是用于判定读、写是否
       有效的最低票数。
       至于　n, w, r 的配置选择，一个常见的选择是设置 n为某奇数（通常为 3 或 5), w = r = (n + 1) / 2 .
       如果可用节点数小于所需的 w 或 r ，则写入或读取就会返回错误
       quorum 只要成功写入的节点集合和读取的节点集合有重合，这样读取的节点中至少有一个具有最新值
       quorum　局限性
            (1) 如果写操作与读操作同时发生， 写操作可能仅在一部分副本上完成。此时，读取时返回旧值还是新值存在不确定性。
            (2) 如果具有新值的节点后来发生失效，但恢复数据来自某个旧值， 则总的新值副本数会低于 w ，这就打破了之前的判定条件。
            (3) 如果某些副本上已经写入成功，而其他一些副本发生写入失败（例如磁盘已满），且总的成功副本数少于　w ，
            　　 那些已成功的副本上不会做回滚。这意味着尽管这样的写操作被视为失败，后续的读操作仍可能返回新值
       读写 quorum 无法保证　“复制滞后问题”中所罗列的一致性保证(写后读，单调读，前缀一致性读)
    5. sloppy quorum(宽松 quorum)
            如何客户端与选定的结点 n 中很多结点断开了连接，无法满足强 quorum(在这个 n 范围内无法满足写入 w 和读取 r 的有效节点数),
            但在这个集群中(节点数要远大于 n),写入和读取仍然需要 w 和 r 个成功的响应，但包含那些并不在先前指定的 n 个节点,
            可以暂时的进行写入操作,一旦网络问题解决了，临时节点需要把接收到的写入全部发送到原始主节点上(数据回传).
            这种 sloppy quorum 主要针对高可用,低延迟的场景,可以忍受读到的是旧值
    6. 无主节点的写冲突
            客户端 A 和 B 同时向主键 X 发起写请求：
                1. 节点 1 收到来自客户端 A 的写请求，但由于节点失效，没有收到客户端 B 的写请求。
                2. 节点 2 首先收到 A 的写请求，然后是 B 的写请求。
                3. 节点 3 首先收到 B 的写请求，然后是 A 的写请求。
            如果节点每当收到新的写请求时就简单地覆盖原有的主键，那么这些节点将永久无法达成一致,因为除了节点 2 认为最终的结果是 B 外,
            其他节点都认为是 A.
```

## 数据分区
### 概要
```shell
    1. 数据分区(分片)对应与 MongoDB, Elasticsearch 和 SolrCloud 中的 shard, 
                         HBase 的 region, Bigtable 中的 tablet, Cassandra 和 Riak 中的 vnode,
                         以及 Couchbase 中的 vBucket
    2. 数据分区的主要目的提高可扩展性,提高查询的性能,不同的分区存放在不同的节点上,其查询也同样路由到不同的节点上.
    3. 数据分区通常与数据复制一起使用,每个数据分区在多个节点都会有副本,以提高系统的容错性.
    4. 一个节点可能存储多个分区,同时充当某些分区的主副本和其他分区的从副本.
```

### 数据分区的切分方法
```shell
    1. 分区的主要目标是将数据和查询负载均匀分布在所有节点.
    2. 方案一: 随机将记录分配到各个节点上. 优点: 比较均匀将数据分布到各个节点上,避免热点.缺点: 在查询的时候没有定位到是数据存放在
              哪一个节点上,只能同时查询所有节点.
    3. 方案二: 基于关键字区间分区
                   (1) 基本原理: 为每个分区分配一段连续的关键字或者关键宇区间范围（以最小值和最大值来指示), 关键字的区间段
                                不一定是均匀分布的,因为数据本身是不均匀的,例如分区 1 关键字区间段是 A ~ B, 而分区 2 关键字
                                区间段则是 C ~ H, 其根据数据本身分布有关, A ~ B 数据特别多,得保证每个分区内的数据都是均匀分布的.
                                为了更均匀地分布数据，分区边界应该适配数据本身的分布特征。根据区间的分区内可以按照关键字排序保存,
                                这样可以进行区域查询.
                   (2) 缺点: 因为是区间分区,某些访问模式会导致热点,如果关键字是时间戳,那么分区对应于一个时间范围，例如每天一个分区.
                             在数据写入时,都是会集中写到某一个分区(当天的分区),会导致这个分区负载很高,而其他分区空闲.
                   (3) 解决方案: 其关键字的定义在时间戳的基础上再加上其他信息(例如传感器编号等),这样就是传感器编号_时间戳,写入的时候
                                先根据传感器编号,再时间戳,这样分配到节点要均衡.
    4. 方案三: 基于关键字哈希值分区
                    (1) 基本原理: 经过合适的哈希函数得到哈希值其均匀的分配到不同的节点,哈希函数有 Cassandra 和 MongoDB
                                 使用 MD5, 一且找到合适的关键宇哈希函数，就可以为每个分区分配一个哈希范围(而不是直接
                                  使用关键宇范围)，关键宇根据其哈希值的范围划分到不同的分区中.
                    (2) 缺点: 失去了范围查询. 在MongoDB 中，如果启用了基于哈希的分片模式，则区间查询会发送到所有的
                              分区上.
    5. 负载倾斜和热点
            如果存在某个明星的发表的热门事件,那么其数据的写入都是针对唯一的一个关键字,其关键字对应的哈希值都是一样的,所以也会
            存在某个分区负载很高,解决的方案是对关键字前缀和后缀都加上规定的数字(1 ~ 10), 这样写入均匀分布到分区中,但读取就麻烦
            一点,需要重新进行关键字的组装,将取到的数据进行合并.这种方法适用与热点关键字.
                                 
```
### 分区与二级索引
```shell
    1. 基于文档分区的二级索引(本地索引,每个分区维护自己的二级索引)
            假设一个销售二手车的网站, 每个列表都有一个唯一的文档 ID ，用此 ID 对数据库进行分区，例如， ID O ~ 499 归分区0,
            ID 500 ~ 999 划为分区1. 用户需要搜索汽车，可以按汽车颜色和厂商进行过滤，需要在颜色和厂商上设定二级索引(即根据颜色
            对应文档 ID), 每个分区完全独立，各自维护自己的二级索引，且只负责自己分区内的文档而不关心其他分区中数据,
            文档分区索引也被称为本地索引，而不是全局索引，那么在分区 0 上有红色的二级索引,在分区 1 也有红色的二级索引.
            所以对二级索引的查询需要对所有的分区进行查询,查询代价高.
    2. 基于词条的二级索引分区
            (1) 对所有的数据构建全局索引，而不是每个分区维护自己的本地索引,而这个全局索引的数据同样通过分区的方法分布在各个节点,
                全局索引分区策略可以与数据关键字采用不同的方法.
            (2) 这种索引方案称为词条分区，它以待查找的关键字本身作为索引。例如颜色 color: red 
            (3) 优点: 查询更高效,不需要对每个分区都进行查询得到结果,只需要对一个分区进行查询.
            (4) 缺点: 数据写入时,对二级索引的更新复杂,一个记录的写入会对涉及多个二级索引(不同的分类方法),而不同的二级索引是会分布的
                      不同的节点上,需要对这些节点都要操作,往往这种特性,对全局二级索引的更新都是异步的
```
### 分区再平衡
```shell
    1. 分区再平衡的背景
            (1) 随着数据增大,各个分区数据分布不平衡,查询不平衡
            (2) 节点出现故障，需要其他机器来接管失效的节点。
    2. 分区再平衡的要求
            (1) 平衡之后，负载、数据存储、读写请求等均匀地分布
            (2) 再平衡执行过程中，数据库应该继续正常提供读写服务
            (3) 防止不必要的负载迁移,减少网络和磁盘 I/O
    3. 分区再平衡策略
            (1) 固定数量的分区策略
                 a. 背景: 
                        对[关键字取模分区方法]对分区再平衡的影响,每一次分区数量发生改变,所有的数据都重新分配到新的分区上,迁移成本大.
                 b. 使用固定数量的分区是数据库一开始创建固定的逻辑分区,这个分区的数量要大于实际节点的数量,然后按照某个映射关系,将
                    各个分区映射到指定的节点上.如果后续需要加入新的节点,则从原有节点中匀出分区分配给新节点.
            (2) 动态分区
                当一个分区的数据超过配置的阈值时，自动拆分为 2 个。分区内的数据删除到给定阈值，自动合并 2 个分区。
               「优点」分区的数量自动适配数据总量，跟节点数无关。
            (3) 按节点比例分区。分区数与集群节点数成正比，每个节点数包含固定的分区数，在节点数不变情况下，数据量增加，分区内数据量
                也增加。当新的节点加入时，随机选择现有节点将其进行分裂并取走部分数据。             
    4. 请求路由
            请求路由有点像服务发现问题。
            方案一：允许客户端链接任何节点（例如轮询，随机分配），接受请求的节点查看是否对应数据，有则响应。没有则将请求传给目标节点。
                   Cassandra 和 Riak 则采用的是在节点之间使用 gossip 协议来同步群集状态的变化。请求可以发送任何节点，
                   由该节点负责转发给目标节点。
            方案二：构造路由层，由路由层进行分配路由到哪一个分区。例如部分分布式系统利用独立的协调组件（ZooKeeper），
                   跟踪集群范围内数据。每个节点需要ZooKeeper 注册，其维护分区到节点的映射关系，路由层组件向 ZooKeeper 订阅消息，
                   这样关系发生变化则会实时接受到。
            方案三：客户端维护一个映射关系，知道分区和节点的对应关系，有客户端直接向目标节点请求。
                
```

## 事务

### 概要
```shell
    1. 事务简化应用层的编程模型，可以不用考虑内部存在的错误和复杂的并发性，均有数据库处理（安全性保证）. 事务提供的安全性保证是 ACID,
       Atomicity（原子性）,Consistency（一致性）, Isolation(隔离性), Durability(持久性).与 ACID 强相关对应的是 BASE,
       Basically Available(基本可用性), Soft state(软状态), Eventual consistency(最终一致性)
            (1) 原子性, 比如将多个写操作纳入到原子事务中,在写入过程中出错,终止事务,并回滚之前的写操作,即状态是要么是事务前的,要么
                       是事务后的数据状态.
            (2) 一致性, 主要是指对数据有特定的预期状态，任何数据更改必须满足这些状态约束（或者恒等条件）
                       一致性更多的是应用层的属性,由应用层去维护状态的一致性,应用程序在定义事务需要保持一致性.
            (3) 隔离性, 应用与多个客户端对数据库中的同一数据并发操作,将执行的多个事务隔离开来,例如串行化隔离,是一种强隔离就好像
                       单线程一样串行执行,不过这样挺耗性能.实际上采用快照隔离(弱隔离的方式)
            (4) 持久性, 即事务的成功提交,对于单数据库而言是数据成功写入到硬盘中,对于多节点数据库而言持久化即成功复制到其他节点上.
       
       原子性，隔离性和持久性是数据库自身的属性, 而一致性则更多的是应用层的属性.
    2. 通常意义上的事务针对的是多个对象，将多个操作聚合为一个逻辑执行单元。
    3. 单对象写入操作适合单个记录.
    4. 多对象事务,对于文档数据模型，如果待更新的字段都在同一个文档中，则可视为单个对象，但缺少 join 支持的文档数据库进行反规范化,
       当更新这种非规范化数据时，就需要一次更新多个文档。此时多对象事务就可以有效防止非规范化数据之间出现不同步。
```

### 弱隔离级别
```shell
    1. 弱隔离可以防止某些但并不是全部的并发问题,因为强隔离就像串行化隔离,很影响性能.
    2. 读-提交是最基本的事务隔离级别,提供了以下保证 : 防止脏读(读数据库时，只能看到已成功提交的数据)
            和防止脏写(写数据库肘，只会覆盖已成功提交的数据)
            a. 防止脏读, 事务的任何写入只有在成功提交后，才能被其他人读到（并且所有的写全部可见）,如果在事务写入过程中,并没有提交
                        则其他人应该看不到部分数据.
            b. 防止脏写,有 2 个事务,第一个事务先对 A 对象进行写入操作,但事务还没提交,第二个事务中也有对 A 对象操作的需要,则第二个
                       事务需要等待第一个事务提交成功.
                       问题: 防止脏写,无法解决同时对某个值加一的竞争情况,其第一个事务结果相对于第二个事务而言更新丢失.
                       
            (1) 实现读-提交的事务隔离,数据库通常采用行级锁来防止脏写,防止脏读如果也是用锁的形式申请的话,会因为运行时间较长的写事务
                导致许多只读的事务等待太长时间，影响只读事务的响应延迟，且可操作性差.所以大部分做法是对于每个待更新的对
                象，数据库都会维护其旧值和当前持锁事务将要设置的新值两个版本。在事务提交之前，所有其他读操作都读取旧值；
                仅当写事务提交之后，才会切换到读取新值。
            (2) 读-提交的并发问题,存在不可重复读的现象,[场景1]备份场景,备份过程需要很长的时间,在期间过程中,数据可以写入到数据库中,
                 即写入的事务很快,那么备份过程中(时间很长)更新对应的数据,如果下个写数据又对相同的对象进行操作,则备份操作已经过去,
                 备份中没办法再更新新的值.
                这时镜像里可能包含部分旧版本数据和部分新版本数据。如果从这样的备份(在这个时刻)进行恢复，最终导致永久性的不一致.
                [场景2] 分析查询与完整性检查, 像分析检查和完整性检查是需要对整个数据库进行扫描的,需要很长一段时间,其中有数据更新,
                这在不同时间点观察结果不同,没有意义.这些可以采用快照级别隔离
    3. 快照级别隔离
            (1) 主要适用与读场景,，每个事务都从数据库的一致性快照中读取, 事务一开始看到是最近提交的数据, 即使数据随后可能被
                另一个事务更改，但保证每个事务都只看到该特定时间点的旧数据。这对于需要长时间的读有用(分析和备份), 在这一过程中
                数据不会被更改.
            (2) PostgreSQL, MySQL 的 InnoDB 存储引擎, Oracle, SQL Server
            (3) 快照级别隔离的实现, 采用写锁来防止脏写,当读不加锁,是通过读取数据库的一致性快照来进行.
                具体的实现是用多版本控制(Multi-Version Concurrency Control , MVCC).在读-提交级别下，对每一个不同的查询
                单独创建一个快照；而快照级别隔离则是使用一个快照来运行整个事务。
            (4) 可见性规则
                    事务开始时，查看当前所有在执行的事务，如果这些事务还未提交，这他们修改的数据不可见。
                    较晚事务 id 修改的内容不可见，不管该事务是否已经提交。
            (5) MySQL 和 PostgreSQL 的可重复读与一致性隔离性一致。
            (6) 读-提交和一致性隔离主要解决只读事务遇到并发写时看到什么数据。
    4. 防止数据更新丢失(并发写)
            (1) 出现场景: 在并发写的情况下，会存在数据更新丢失情况，
                         情景一是 2 个并发写事务，在读取值（同一个值）时进行累加计算，则 2 个事务完成后，其值有问题。
                         情景二，对同一 json 的部分内容进行修改
            (2) 解决方案:
                    a. 原子写操作，数据库提供独占该对象的功能，可以通过独占锁方式，也可以通过所有原子操作都在单线程中执行。
                    b. 在数据库不支持原子性操作，需要应用程序进行显示加锁。
                    c. 自动检测更新丢失，在不进行原子操作情况下，通过一致性快照操作，当事务管理器检测到有数据更新丢失风险 ，
                       中止事务，并强制回退到"读 - 修改 - 写回"。 PostgreSQL 的可重复读，Oracle 的可串行化支持自动检测更新丢失数据。
                       而 MySQL 的 innodb 可重复读不支持自动检测数据更新。
    5. 
        (1) 冲突解决及复杂，加锁和原子性操作适用于只有一个单副本，对于多主节点和无主节点存在并发写情况，则可以通过保留多版本的冲突，
            通过应用层逻辑来合并冲突。
        (2) 写倾斜，对于多事务同时对多个对象进行操作，而这多个对象存在某种关系，例如医生值班，同一天必须有一个医生值班，
            存在一种情况，2 位医生同时进行请假，如果采用快照级别隔离，对于每个医生来说都有即使请假了，都还有一个医生值班，
            但现实所以医生都请假了。解决方案：采用对事务依赖的行显式加锁（for update）
        (3) 写倾斜的其他例子：1. 会议室预订系统，采用快照隔离导致预定冲突，可以采用串行化隔离
    6. 弱级别隔离虽然性能不错，但容易引发各种边界条件(如更新丢失, 写倾斜, 幻读等)
       
```

### 串行化
```shell
    0. 如果串行化隔离比其他各种弱隔离级别好得多，那么为什么没有广泛使用呢？要回答这个问题，我们需要看看可串行化究竟是什么，
       以及如何执行
    0.1 
        (1) 几乎所有的 OLTP 应用程序都避免在事务执行中等待用户交互,因为事务在等待用户响应时,用户本身不一定很快做出决定,
            这使得事务都被阻塞住,系统大部分时间将处于空闲状态
    1. 实际串行执行，严格按照串行顺序执行，在一个线程中按顺序执行事务,到现在，采用单线程循环来执行事务是可行的,是因为
       第一内存越来越便宜,事务所需的所有数据都可以在内存中.第二一般执行的事务是 OLTP 事务其执行的速度很快(只是简单的读写操作),
       而运行时间较长的分析查询则通常是只读的，可以在一致性快照（使用快照隔离）上运行，而不需要运行在串行主循环里.
       应用:
            Redis 就是采用串行化执事务.
       限制:
            吞吐量上限是单个 CPU 核的吞吐量
            
       (1) 存储过程封装事务
                (a) 背景: 在串行事务的背景下,交互式事务(通过网络进行一次向数据库请求查询),这样的方式每次都要通过网络通信,效率低下,
                          吞吐性能低,这时应用程序可以提交整个事务代码(多语句事务)作为存储过程打包发送到数据库.
                (b) 存储过程缺点:
                        1. 每个数据库厂商存储过程语义不统一,并且语义过时，而且缺乏如今编程语言所常用的函数库
                        2. 在数据库中运行代码难以管理,难以调试,版本控制与部署复杂.
                        3. 影响范围广,数据库实例可能被多个应用服务器共享,需要处理性能更高,如果存储过程设计不好,存在
                           性能问题,则危害大
                (c) 解决方案:
                        1. 最新的存储过程采用现有通用的编程语言,如 Redis 采用 Lua
       (2) 分区
                (a) 背景: 在串行事务的背景下, 对于高写入需求的应用程序,单线程事务处理很容易造成性能瓶颈. 这时候可以采用对
                         数据进行分区,每个事务只在单个分区内读写数据，这样每个分区都可以有自己的事务处理线程且独立运行。
                         那么就相当于为每个 CPU 核分配一个分区.
                (b) 问题: 
                        如果是跨分区的事务,需要对所有涉及到的分区进行协调,那么会造成额外的开销,性能下降.对于简单的
                        键 - 值 数据很容易划分到单分区下,并索引到该分区.但是如果是二级索引数据则可以存在跨分区处理.
       (3) 小结:(可以进行串行化隔离的条件)
                (a) 事务必须简短而高效，否则一个缓慢的事务会影响到所有其他事务的执行性能。
                (b) 仅限于活动数据集完全可以加载到内存的场景。因为有些很少访问的数据可能会被移
                    到磁盘，但万一单线程事务需要访问它，就会严重拖累性能
                (c) 写入吞吐量必须足够低，才能在单个 CPU 核上处理；否则就需要采用分区，最好
                    没有跨分区事务。
                (d) 跨分区事务虽然也可以支持，但是占比必须很小。
                
                
            
    2. 两阶段锁定(唯一可行,广泛应用)
            (1) 概念: 两阶段加锁(two-phase locking, 2PL), 多个事务可以同时读取同一对象，其他情况则需要独占加锁
                     (只要出现任何写操作(包括修改或删除)), "两阶段”的来由在第一阶段即事务执行之前要获取锁,
                     第二阶段(即事务结束时）则释放锁.
                     例如:
                        (a) 如果事务 A 已经读取了某个对象，此时事务 B 想要写入该对象，那么 B 必须等到 A
                            提交或中止之才能继续
                        (b) 如果事务 A 已经修改了对象, 此时事务 B 想要读取该对象, 则 B 必须等到 A 提交或
                            中止之后才能继续
                            
                     两阶段加锁是一种典型的悲观井发控制机制。它基于这样的设计原则： 如果某些操作可能出错
                     (例如与其他并发事务发生了锁冲突), 那么直接放弃，采用等待方式直到绝对安全。这和多线程编程中互斥锁是一致的。
                            
            (2) 具体实现:包括 MySQL(InnoDB 存储引擎)对每个对象通过读写锁来隔离读写操作,这个读写锁有 2 种模式,第一种
                        共享模式(适用多读)和独占模式(用于改)
                        (a) 如果事务要读取对象，必须先以共享模式获得锁。多个事务可以同时获得一个
                            对象的共享锁，但是如果某个事务已经获得了对象的独占锁，则所有其他事务必须等待。
                        (b) 如果事务要修改对象，必须以独占模式获取锁。不允许多个事务同时持有读写锁(包括共享或独占模式),
                            同时,如果对象上已被加锁(不管是共享还是独占), 修改事务必须等待.
            (3) 问题:
                    (a) 主要考虑到性能问题, 两阶段锁定中一个事务如果占用多个对象的锁,则导致响应时间变慢,同时存在性能的
                        不确定性,因为你不知道在什么时候有等待多久,同时发生死锁的情况更频繁.
                    (b) 无法扩展（由于串行执行）
            (4) 谓词锁(精准匹配,实际开销大)
                    它并不属于某个特定的对象(如表的某一行), 而是作用于满足某些搜索条件的所有查询对象.谓词锁会限制如下访问：
                    [第一种情况]如果事务 A 想要读取某些满足匹配条件的对象，例如采用 SELECT 查询，
                    它必须以共享模式获得查询条件的谓词锁。 如果另一个事务 B 正持有任何一个匹配对象的互斥锁, 
                    那么 A 必须等到 B 释放锁之后才能继续执行查询。
                    [第二种情况]如果事务 A 想要插入、更新或删除任何对象，则必须首先检查所有旧值和新值是否与现有的任何谓词锁
                    匹配（即冲突）。如果事务 B 持有这样的谓词锁，那么 A 必须等到 B 完成提交（或中止）后才能继续。
                    
                    谓词锁甚至可以保护数据库中那些尚不存在但可能马上会被插入的对象（幻读）。将两阶段加锁与谓词锁结合使用，
                    数据库可以防止所有形式的写倾斜以及其他竞争条件.
                    
                    问题: 谓词锁性能不好,如果一个事务存在大量的锁,检测匹配这些锁很耗时,可以用索引区间锁,其对谓词的简化.
            (5) 索引区间锁(大部分数据库采用折衷的方式)
                    简化谓词锁的方式是将其保护的对象扩大化(针对范围), 当对某一对象进行操作时近似对该对象某一维度的扩大化,
                    如查询条件的近似值都附加到某个索引上, 如果另一个事务想要插入、更新或删除同一个房间或重叠时间段的预订，
                    则肯定需要更新这些索引, 一定就会与共享锁冲突，因此会自动处于等待状态直到共享锁释放.这样就有效防止了写倾斜
                    和幻读问题
   
    3. 乐观并发控制技术，例如可串行化的快照隔离(Serializable Snapshot Isolation)
            (1) 概念: 可串行化的快照隔离是一种乐观并发控制, 如果可能发生潜在冲突, 事务会继续执行而不是中止，乐观希望没有问题：
                      而当事务提交时(只有可串行化的事务被允许提交), 数据库会检查是否确实发生了冲突(即违反了隔离性原则),
                      如果是的话，中止事务并接下来重试.在系统还有足够的性能提升空间，且如果事务之间的竞争不大，乐观并发控
                      制会比悲观方式高效很多
            (2) 问题:
                    乐观并发控制技术如果冲突很多, 则性能不佳(因为许多事务试图访问相同的对象), 大量的事务必
                    须中止. 如果系统已接近其最大吞吐量，反复重试事务会使系统性能变得更差。
            (3) 基于过期的条件做决定
                    (a) 检测是否读取了过期的 MVCC 对象: 数据库需要跟踪那些由于 MVCC 可见性规则而被忽略的写操作。当
                        事务提交时, 数据库会检查是否存在一些当初被忽略的写操作现在已经完成了提交，
                        如果是则必须中止当前事务
```

